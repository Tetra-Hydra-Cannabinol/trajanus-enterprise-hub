# Research Finding #22

**Date:** 2025-12-17 08:57
**Topic:** text-embedding-3-small optimal parameters
**Score:** 0.99943846

---

## Exploring Text-Embedding-3-Large: A Comprehensive Guide to the ...

**URL:** https://www.datacamp.com/tutorial/exploring-text-embedding-3-large-new-openai-embeddings
**Published:** Unknown date

---

## Content

The text-embedding-3-small is optimized for latency and storage. On the other hand, text-embedding-3-large is a good option for higher accuracy, and we can also take advantage of the new dimensions parameter to keep the embedding at 1536 instead of the native size of 3072 without impacting the overall performance.

### Benchmarking analysis [...] These applications showcase how text-embedding-3-large and text-embedding-3-small can be optimally deployed in various sectors, aligning their strengths with the specific needs of each application for enhanced performance, user experience, and cost efficiency.

A Step-By-Step Guide to Using the New OpenAI Embeddings

We now have all the tools we need to proceed with the implementation of both text-embedding-3-large, text-embedding-3-small, and ada-v2 in a scenario of document similarity. [...] _Top 3 most similar documents using each embedding model_

#### Observation of the result

The "text-embedding-3-small" model shows moderate similarity scores around 0.54, while the "text-embedding-3-large" has slightly higher scores, indicating a better capture of similarity.

The "text-embedding-ada-002" model shows significantly higher similarity scores, with the top score close to 0.85, suggesting a very strong similarity with the chosen document.

---

*Source: Research Agent v2.0 | Search Provider: Tavily AI | Retrieved: 2025-12-17 08:57:13*
