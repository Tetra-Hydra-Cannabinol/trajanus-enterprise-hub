# Research Finding #24

**Date:** 2025-12-17 08:57
**Topic:** text-embedding-3-small optimal parameters
**Score:** 0.99916387

---

## Embeddings performance difference between small vs large at 1536 ...

**URL:** https://community.openai.com/t/embeddings-performance-difference-between-small-vs-large-at-1536-dimensions/618069
**Published:** Unknown date

---

## Content

embeddings-benchmark/mteb: MTEB: Massive Text Embedding Benchmark) evaluation, while the `text-embedding-3-small` model has a performance of 62.3%. Therefore, the `text-embedding-3-large` model performs slightly better than the `text-embedding-3-small` model. [...] Possible Answer: Yes, there is a performance difference between the two models. According to the documentation (), the `text-embedding-3-large` model is the most capable embedding model for both English and non-English tasks, while the `text-embedding-3-small` model offers increased performance over the second-generation ada embedding model. In terms of specific performance metrics, the `text-embedding-3-large` model has an example performance of 64.6% on the MTEB (GitHub - [...] For the following text, summarize the idea, extract meaningful questions and give possible answers.

```
Is there a performance difference between text-embedding-3-small @ 1536 length and text-embedding-3-large @ 1536 length?

```

Reply

Idea Summary: The user is inquiring about the performance difference between two of OpenAIâ€™s third-generation embedding models: `text-embedding-3-small` and `text-embedding-3-large` . Both models have an output dimension of 1536.

---

*Source: Research Agent v2.0 | Search Provider: Tavily AI | Retrieved: 2025-12-17 08:57:13*
