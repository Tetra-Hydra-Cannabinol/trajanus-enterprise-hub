Title: LangGraph Complete Course for Beginners â€“ Complex AI Agents with Python
Channel: freeCodeCamp.org
Video ID: jGg_1h0qzaM
URL: https://www.youtube.com/watch?v=jGg_1h0qzaM
Duration: 3:09:51
Level: INTERMEDIATE
Application: LangGraph
Topics: LangGraph, Python, AI Agents, Conversational AI, Graph-based Workflows, Type Annotations, RAG Agent, LangChain
Ingested: 2025-12-21
Source: Playwright Browser Extraction
==============================================================================

0:00 Welcome to this video course on Langraph, the powerful Python library for building advanced conversational AI\n0:07 workflows. In this course, Vbeca will teach you how to design, implement, and\n0:12 manage complex dialogue systems using a graph-based approach. By the end, you'll\n0:18 be equipped to build robust, scalable, conversational applications that leverage the full potential of large\n0:25 language models. Hey guys, my name is Vava and I'm a robotics and AI student.\n0:30 In this course, we're going to be learning all about the fundamentals of Langraph. Now, I assume you've heard of\n0:36 Langraph before, hence why you clicked on this course. But I'm also going to assume you have never coded in Langraph\n0:43 before. Now, because of this assumption, I have explained every single thing in as much detail as I possibly can. Now,\n0:51 also this might mean that I might be going slow at times. So if you want you can always speed me up. Now what are we\n0:58 going to be learning in this course? Well to start we're going to be building a lot of graphs, a lot of AI agents.\n1:05 We're going to be learning a lot about the theory and I've also provided exercises throughout the course in which\n1:11 all of the answers will be provided on the GitHub. With that being said, if you're\n1:16 ready to start on this journey with me, let's go to our first section\n1:21 then. All right people. So welcome to the first section of this course. Now in\n1:26 this section we'll be covering something called as type annotations. Now admittedly this is going to be a\n1:32 completely theoretical section but it will be short and brief. I promise. The reason I've kept this specific section\n1:38 in the course is because when we do eventually go on to code uh our AI agents, our graphs and langraph, these\n1:45 will start popping up everywhere. And I don't really want you to look start coding without ever having seen these\n1:51 before or really not knowing what these actually are. So that's why I've kept it here. But I promise this will be short\n1:57 and brief. Cool. Okay. Let's begin with dictionaries. Now dictionaries are a\n2:02 data structure. Yes, but there's a reason I've kept it here. So let's see\n2:07 how a dictionary is described in Python. You should already know this. So in this case, I've described a very simple\n2:13 dictionary called uh movie. and it has two keys, the name and the year. And it\n2:18 has two values, Avengers Endgame and 2019. Now, dictionaries are awesome, don't get me wrong. They're they allow\n2:25 for efficient data retrieval based on their unique keys. They're flexible and easy to implement, but there's a\n2:30 potential problem with them. See, it's a challenge to ensure that the data is a particular structure. And this could be\n2:38 a huge problem in larger projects. So to put things in simple words, it doesn't\n2:43 really check if the data is the correct type data type or structure and that could be the source of a lot of logical\n2:50 errors in your project. And if your project is really really large, then this could be quite a headache to\n2:56 identify, right? Cuz it's quite a small detail. So what is the solution for this? Well, it's something called a type\n3:03 dictionary. Now, here is an example on how you create a type dictionary in Python. And I just want to uh emphasize\n3:10 that this type annotation is used extensively in langraph. This will be used to define states. Now don't worry\n3:18 you we haven't covered states yet. We will cover that in the next section. But just be mindful that this is quite\n3:23 important. So a type dictionary is quite easy to implement. You implement it as a\n3:28 class. In this case, I've implemented the same um example I uh uh showed you\n3:34 in the previous section where I described the movie is the same exact keys and values. So, it still has the\n3:40 name and the year. But notice in this class, I have defined the actual uh data\n3:46 type of what that key should be. So, for example, the name is a string and the year is an integer, right? And to\n3:53 initialize a dictionary uh I have done the exact same thing. to have engineet game in 2019. So now there are two main\n4:01 uh benefits of using a type dictionary it's type safety because we've explicitly defined what should be in\n4:08 this data structure and so this will really reduce the runtime errors and obviously the readability is enhanced as\n4:14 well and this will make debugging easier if something goes wrong within this type dictionary. Cool. So we've covered type\n4:22 dictionary now. Now we move on to another type of annotation which is union. Now you might have seen these\n4:29 future these later uh types annotations before if you coded in Python but again I'm just giving you a highle overview\n4:35 what these are. So union take a look at this example. So I've created a very simple function which takes in a value\n4:42 and it squares it. Now in this case the uh input x could be either an integer or\n4:48 float and union basically says that whatever value you have can be these\n4:54 data types only. So in this case x can only be integer or float. So if I pass in five or 1.23 4 this would be\n5:01 completely fine. It would square the number and everything. But if I passed in a string like I am a string it would\n5:06 completely fail. Now admittedly yes this function is quite easy. If I passed in\n5:12 I'm a string, it would have failed anyway. But in more complicated applications, hopefully you can see how\n5:17 this actually is useful. In fact, the makers of Lang Chain and Langraph used Union quite extensively throughout u\n5:24 making the actual library. So again, it's flexible and it's easy to code and\n5:30 it allows for type safety. So because it can provide hints to uh help catch\n5:35 incorrect usage. Now something similar to union is another type annotation which is optional. Now optional is quite\n5:42 similar and in this case I've described another function nice message. So you\n5:48 pass in a name. If you pass in a name it will say hi there name. So for example let the name be Bob. If I pass in Bob to\n5:56 this uh function it would say hi there Bob. But what if I don't pass in\n6:01 anything? Now if I don't pass anything optional because I've used optional says that the name parameter could either be\n6:08 a string or a none value. Now if I pass in nothing it will go in this if\n6:13 statement and say hey random person. But this is also important to emphasize that it cannot be anything else. It can't be\n6:20 an integer or or a boolean or a float or anything like that. It has to be either a string or a none value because that's\n6:27 what I've defined here. Cool. Now comes another type annotation called any. And\n6:33 any is really the easiest one to understand. It literally means this value could be anything. It could be any\n6:40 data structure. So in this case I've created a simple um function called\n6:45 print value where it takes in something and it prints that. And for example I\n6:51 passed in this string and it prints it and anything and everything is allowed.\n6:56 Cool. one last type annotation I promise and it's the lambda function. So lambda\n7:02 functions are quite useful. For example, in this I'll give you two examples now. So the first example is this really\n7:10 simple uh example. Now we've already I already created a square function before, right? Where it takes in a\n7:16 value, it takes in a number and it squares it. So for example, if I passed in square 10, it would give me 100.\n7:23 Quite an easy example. Now let me give you a second example. this. So if you've come from a\n7:29 leaf code background, then you've probably seen you've either used lambda before and you've definitely used math\n7:35 before cuz it's quite efficient. So for example, if I pass in 1 2 3 4, what this piece of code is saying is that it\n7:42 squares each number in nums. So this map function maps each value uh and performs\n7:49 this function to it. So x * x. So 1 4 9 16 and then converts that back into a\n7:55 list. Now lambda functions really are just a shortcut to writing small functions and they make everything quite\n8:02 efficient. Now obviously this could have been done in one line as well but for example this a beginner programmer could\n8:09 have might have used a for loop but a more advanced programmer could have used this and this is obviously much more\n8:16 efficient. Right? So hopefully you can start to see what how powerful these type annotations are and these will be\n8:23 coming up. So again, no need to memorize this. Just need to have a highle overview what they are. Okay, cool. So\n8:29 now I'll see you in the next section. See you there. All right, perfect. So let's\n8:36 continue on. In this section, we will look at the different elements in Langraph. So let's begin with our first\n8:44 element, one of the most fundamental elements in all of Langraph, the state.\n8:49 So what is a state? Well, it's a shared data structure that holds the current\n8:54 information or context of the entire application. In simpler terms, it is like the application's memory where it\n9:01 keeps track of the variables, the data that nodes can access and modify as they execute. Now, don't worry if you don't\n9:08 understand what a node is yet. That is what we will be talking in the next slide about. But as a good analogy,\n9:15 think of the whiteboard in a meeting room analogy. Now imagine you're in a meeting room and\n9:20 there are different participants as well and every time you come up with something new or you want to record some new uh information or update some\n9:27 information you write it on the whiteboard. In this case the whiteboard acts as your state and the participants\n9:34 act as a node. So the state shows us the updated\n9:40 content/in information of your entire application. Hopefully that made a bit of sense.\n9:47 So let's move on to the node another fundamental element in lang graph. So\n9:52 these are just individual functions or operations that perform specific tasks within the graph. So each of these node\n9:59 receives an input which is often just the current state of your application. It processes it and then produces an\n10:05 output or an updated state. So here's a good analogy of this.\n10:12 The assembly line station analogy. Now look at this image. Each of these\n10:17 station does one specific job. It could be attaching a part. It could be painting it. It could be inspecting the\n10:24 quality and so on and so on. The point is each of these stations represent a\n10:30 node because they do one specific task. So how do you actually connect\n10:36 these different nodes together? Well, before we go into that, I think it's important we understand the most\n10:42 important element of them all, the graph. It is so important that it's even\n10:48 in the name Langraph. So, the graph is just the overarching structure and it\n10:54 maps out how different tasks aka nodes are connected and executed. So it\n11:01 visually represents the workflow showing the sequence and the conditional parts\n11:06 between various operations. Now a graph is quite self-explanatory but you can think of it\n11:11 as a road map. On a road map you can see it display the different routes\n11:16 connecting cities with the different intersections offering choices on which path to take next.\n11:22 Now, here's a great image of what a graph is, and these are the individual nodes, but you'll see they're connected\n11:28 somehow. So, how are these connected? That brings us to the next element,\n11:35 edges. So, edges are just the connection between nodes and these determine the\n11:40 flow of execution. So, they tell us or tell the application which node should be\n11:45 executed next after the current one completes its task. A really good analogy of this is imagining a train\n11:52 track. So this is the train track and think of it as an edge and think of it\n11:57 as connecting two stations one here and one here which represent nodes together\n12:03 in a specific direction. Now the train which will go on the train track that acts as your\n12:10 state. So the state gets updated from one station to another.\n12:16 But there is another type of an edge and it's called a conditional edge. So this is still not very\n12:24 complicated. It's quite simple to understand. These are just specialized connections that decide the next node to\n12:30 be executed based on the specific condition or logic applied to the current state. Now a really good analogy\n12:37 for this is the traffic light analogy. So green could mean to go one way, red\n12:42 could mean to stop. yellow could mean to slow down. The point I'm trying to make here is that the condition, in this case\n12:49 the light color, it decides the next step. If you want to think even more\n12:54 simply, you could think about an if else statement. So that being said, we move\n13:01 on to the next element, the start point. So the start point or the node, the\n13:06 start node is a virtual entry point in langraph and this marks where the workflow begins. Now it's important to\n13:12 note that it doesn't perform any operations itself but it serves as the designated starting position for the\n13:18 graph's execution. Now in terms of analogy it is quite simple to understand but if you\n13:25 really want think of it as the starting line of race. Now if you have a start point well\n13:32 you need an end point as well and that's where the end element comes in. So the\n13:37 end nodes just signifies the conclusion of the workflow in Langraph. So when the\n13:42 application reaches this node, the graph's execution completely stops and it indicates that all intended processes\n13:49 have been completed. And again, a good analogy for this is just the finish line in a\n13:55 race. So nothing too hard yet. But now let's look at\n14:01 tools. So tools are specialized functions or utilities that nodes can\n14:06 utilize to perform specific tasks. For example, it could be fetching data from an API. They basically enhance the\n14:14 capabilities of these nodes by providing additional functionalities. Now, one common\n14:19 question could be, well, what's the difference between a tool and a node? The node is just the part of the graph\n14:25 structure. Whereas the tools, these guys are functionalities used within the\n14:31 nodes. Now, a really good analogy for this is just tools in a toolbox. So\n14:36 imagine a hammer for the nails, a screwdriver for the screws, etc. The\n14:41 point is each tool has a distinct purpose. Again, don't worry. You will understand the differentiation between\n14:48 tools and nodes in a lot more detail later when we code this, but this is just for a general\n14:53 overview. Now, another question you could be asking is, is there a middleman between a tool and a node? Short answer\n15:01 is yes. That's where tool node comes in. So a tool node is just a special kind of\n15:07 a node whose main job is to run a tool. So for example, a tool node could\n15:14 be a node where its only job is to use a tool and that tool's job is to fetch\n15:21 some data from an API. So it connects the tools output back into the state so other nodes can\n15:28 use that information. So think about this analogy going back to the assembly line. In this case,\n15:36 imagine the operator as the tool node and it controls the machine which is the tool and then sends all of these results\n15:43 back into this assembly line. Now if we progress further, let's\n15:50 look at the state graph. So this is quite an important element as well. This will be one of the first elements you\n15:56 actually interact with and its main purpose is to build and compile the graph structure. So it's quite\n16:02 important. It manages the nodes, the edges, the overall state and it makes\n16:08 sure that the workflow operates in a unified way and all of the data flows correctly between components. So again\n16:15 it's quite an important element. You can think about it as a blueprint of a building. So just as a blueprint\n16:22 outlines the design and the connections within a building, the state graph does\n16:28 exactly that, but it just defines the structure and the flow of your workflow or\n16:35 application. Now here's where the runnable comes in. Now some of you will be coming from a lang chain background\n16:41 and runnable is quite common there and it's quite similar in langraph as well.\n16:46 A runnable in langraph is just the standardized executable component that performs a specific task within an AI\n16:53 workflow. It basically acts as a fundamental building block allowing for us to create these modular\n17:00 systems. Now a question you could have right now is well what's the difference between a runnable and a node?\n17:07 Short answer is a runnable can represent various operations whereas a node in\n17:13 lang lang graph typically receives a state performs an action on them and\n17:18 then updates the state. Now don't worry if you didn't 100% get that when we go\n17:24 into the coding section you will get it a lot better. But a good analogy is a\n17:29 Lego brick. So just as how Lego bricks can be snapped together to build these complicated structures, runnables can be\n17:37 combined to create sophisticated AI workflows. So now let's move on to the\n17:42 different types of messages. Now again, if you come from a lang chain background, you'll be quite\n17:48 familiar with these. If you haven't, don't worry. We will look at the five most common message types in Langraph.\n17:57 So to start off, there's the human message which represents the input from a user. The AI message which represents\n18:03 responses generated by AI models. The system message which is used to provide\n18:08 instructions or context to the model. Tool message which is similar to the function message but specific to\n18:14 tool usage. And the function message represents the tool of a function call.\n18:20 If you've used an API like a large language model API before, such as OpenAI's API, a lot of these will be\n18:26 quite familiar, especially the system message, the AI message, and the human message. And that concludes this\n18:33 section. So, I will see you in the next section. Awesome. So, now this is quite\n18:41 exciting. We're actually about to start coding in Langra for the very first time. Now that we've covered all the theory, admittedly the boring section,\n18:49 we're now actually going to code up some graphs. And we're about to code up our very first graph in this sub section.\n18:55 But um for this overall section, I have a slight confession to make, which is\n19:01 we're not going to be building any AI agents in this section. Why? because I thought that one\n19:08 we haven't really even seen uh how to actually code in Langraph and combining all of these LLMs APIs and tools and all\n19:15 of that stuff which comes with it combining them together would be quite messy and it could be quite confusing at\n19:21 times especially the fact that we have never coded in Langraph before again like I said at the beginning of the\n19:27 course this course is supposed to be beginner friendly detailed and comprehensive and we're going to go in\n19:33 steps like little by little so hopefully understand but don't worry we will be coding AI agents soon we're just going\n19:39 to be building a couple of graphs right now uh understand lang graph better the syntax better and how to actually code\n19:46 up graphs and get confident with it and then we will actually build AI agents okay cool so what is the graph which\n19:53 we're going to be building together in this section I call it the uh hello world graph mainly because it's the most\n19:59 basic form of graph we can actually code in lang graph so the objectives are\n20:04 these So we're going to be understanding and defining the agent state structure and\n20:11 don't worry you'll understand what that is in a few minutes and we're going to be creating simple node functions nodes\n20:17 like we discussed in the previous section uh and we're going to be processing them and updating the state.\n20:23 We're going to be building the first ever basic langraph structure and we will understand how to compile it,\n20:29 invoke it, process it, everything. And really the main goal of this section is\n20:35 to really understand how data flows through a single node in langraph. Now just to give you a bit of a heads up as\n20:42 to what we'll actually be covering uh what we're going to be building I should say is this graph. Again like I said\n20:49 this is the most basic form of graph you can build in langraph. It has a start point and an end point and this node\n20:56 sandwiched in between them. All right cool. So hopefully you've understood what the objectives are. It's quite\n21:02 basic and yeah, I'll see you at the\n21:08 code. Okay, cool. Now let's actually code this very first graph. So I've\n21:13 imported three main things here. The dict, the type dict and the state graph. The dict and type dict is obviously\n21:20 dictionary and type dictionary but um and state graph. These three are\n21:25 elements which we covered in the previous section. So I would highly recommend you going back there if these\n21:30 are completely unfamiliar. But again you don't need to memorize what these are. Okay. But just to refresh your memory\n21:36 I've written in the comment here what the state graph is. So think of the state graph as a framework that helps\n21:43 you design and manage the flow of the tasks in your application. Um again that\n21:48 might sound a bit complicated but it's not. Once we actually start coding you\n21:53 will it'll make more sense. So now the first thing we're going to do after importing everything is create the state\n22:00 of our agent and let's call it agent state. And just to refresh your memory\n22:06 again what the state is. Think of the state as a shared data structure. And\n22:11 this keeps track of the your all of the information as the application runs. All right cool. So now let's build the agent\n22:18 state. And the way we do this in Langraph is through a class. So let's build class agent state and in this in\n22:26 these parenthesis we will try to the the state needs to be in the form of a typed\n22:32 dictionary. So that's why we specify type dictionary here. Now let's keep\n22:38 this very very fundamental and basic. Let's just pass in one input. Let's call\n22:44 it something like message and obviously we put colon and\n22:51 the we specify the data type of that uh attribute. Now obviously the data type\n22:57 of message will be string right so that's why we specify strl again this is\n23:02 just normal python so once we've done that we are now going to be coding our\n23:08 very first node again another very fundamental element in langraph so how\n23:14 do we actually define a node it's quite simple it's just a normal standard\n23:19 python function and this is how you do it so let's say let's first try to find\n23:24 The objective um let's say we are trying to let's a greeting message a simple\n23:31 greeting message. So we'll write def greeting node and we need to pass in an\n23:38 input and pass what the output type should be. Now the input type of a node\n23:44 needs to be the state and the output type also has to be the state because\n23:49 remember the state keeps track of all of the information in your application\n23:54 right so obviously you need to pass that as an input and you need to pass out the or return the updated state. So here's\n24:01 how you do it. You pass in state and what is the state of our application? Well, it's the agent state which we\n24:08 defined earlier, right? And the output is going to be agent state cuz we need\n24:14 to output the updated state. And our updated state will again just be the agent state once we've done all of the\n24:21 um all of the mechanics we do in this function, the actions we perform in this function. All right. Okay. So now we\n24:28 need to do something very very important and it gets annoying sometimes but um\n24:34 it's really a key habit which I want you to form and it is dog strings. Now dock\n24:39 strings and lang graph is quite important. Why? Because dock strings is what will tell your AI agents when we\n24:46 actually build the AI agents your LLMs what that function actually does what that function's actions are what it\n24:52 performs. So in this case uh by the way to create a dock string is just three quotation marks three pairs of quotation\n24:59 marks. Uh let's call the dock string in this case let's just write simple node\n25:05 that adds a greeting message to the state. Perfect. So now how do we\n25:14 actually refer to this message? Well again this is just normal Python code.\n25:19 So we will pass in state and we will type in message.\n25:25 Now this specific part allows us to actually update the state or the message\n25:31 part of the state. And let's say let's come up with something like hey\n25:37 plus state message. Um we can also add something\n25:42 like how is your day going something basic. Now what's the last thing which I\n25:48 need to do in this function? Think about it. Okay. So now remember in uh a few\n25:56 moments ago I said we have to return the state or the updated state. Well the updated state we've already done we've\n26:02 just manipulated the state here. So all we have to do is just simply return the state. Cool. And yeah that runs without\n26:10 any errors. Okay. Now let's actually build the graph uh which is again\n26:16 obviously very important. So how do we build the graph? Remember here I said state graph is a framework that helps us\n26:23 design and manage the flow of tasks as a graph. Well that's exactly what we're about to do now. So hopefully it clicks\n26:29 now. So to create a graph in lang graph you use the state graph attribute and\n26:35 you pass in your state. You can see the state schema which VS code has uh asked for what uh the description of what the\n26:42 parameters are. So our state schema in this case is just the agent state which we define right. So we pass an agent\n26:49 state. I will actually also write here our state\n26:54 schema. So uh you can physically see what it is.\n26:59 Okay. And let's store this in a variable called graph or something. Okay. Now now\n27:07 here comes a very important method. How do we actually add a node to this graph? Cuz this graph is completely like\n27:13 nothing right now. So to add a node we use the inbuilt function graph add node\n27:18 and it requires two main parameters. Now what VS code is suggesting is a god I\n27:25 don't even know what that all of all of that is right it's very confusing. So to put things simply you require really two\n27:33 uh parameters the name of your node and what action it will perform. So let's go\n27:39 with the name. The name could be absolutely anything sensible of course. Um let's call something like\n27:45 greeter. Cool. And you can see VS Code has also asked us to um input an action.\n27:53 Now what's the action going to be? Well, the action will just be whatever your node will actually perform. And what\n28:00 action or mechanics will this node actually perform? Well, all of that is defined by this function, right? The\n28:07 greeting node function. So we simply just put that the name of the greeting node function here and that's it. We've\n28:14 successfully added the greeting node to our function to our graph and it will be\n28:21 named as greater. So remember this\n28:27 diagram in this diagram there is supposed to be a start and an end point. We've done the node which is sandwiched\n28:33 in between these but we haven't really added the start and the end point yet. So, how do we do that? Well, there's\n28:39 actually multiple ways to do that. In this subsection, in this graph, I'm going to teach you one way. Further down\n28:45 the line, I'll teach you another way. So, but they're both they're quite easy. So, you simply just call the inbuilt\n28:51 function set entry point and as the parameter is just one\n28:56 parameter which is the key. Now, the key is the name of your node which you want the start node to connect to. Again,\n29:04 visualize it. The start the start point is here and the node is here. Obviously you need to reference a node for it to\n29:11 create like an edge right. So we simply pass greater and similarly graph dot set\n29:17 finish point. We will again pass greater here as well. Why? Because imagine again\n29:24 the node is here and your finish point is here and you need to connect some sort of connection between these two right and that's why we use uh greater\n29:30 in this case. Don't worry, you will solidify this once you complete the exercises and as we go down building\n29:36 more graphs. All right. And one last thing which we need to do is actually compile this graph. So graph compile\n29:43 using the inbuilt uh graph using the inbuilt compile function. And let's just store this in a\n29:48 variable. Cool. So that run without any errors. But just a word of caution here.\n29:54 Just because the graph compiles without any error doesn't mean it will successfully run. I mean, God knows once\n30:00 we build like more complicated graphs, there could be so many logical errors. So, that's just an important thing to\n30:06 know. So, don't get too happy once it compiles cuz there might be logical errors. Trust me, I know. Okay.\n30:15 So, I want to write some code which will actually help you visualize this. And\n30:20 you can use the IPython library. So, you can use this uh this um piece of code\n30:26 here. This code is awfully familiar with the first ever graph I showed you, right? I\n30:33 I'll put a picture somewhere here for you to compare. The only difference is really the name of the node which we've\n30:39 set. In this case, it's greater. Why is it greater? Because that's the name we gave to this node, right? Cool. So\n30:47 that's looks pretty good. Let's actually run this. So to run you use the inbuilt\n30:54 method invoke. Um so let's pass in the message\n31:00 as something like Bob or something and let's actually store this result in a\n31:09 variable. Okay. Now how can we actually specify uh how can we actually get the\n31:15 value of result? So result we need to actually reference\n31:22 a certain attribute. Now the only attribute we have in uh the entire graph is message right. So we simply just put\n31:29 message and perfect you we get the final answer which is hey Bob how's your day going now why is it like this because\n31:36 this is exactly how we set our act how we set our function to be what action it performs it says hey then concatenates\n31:44 the uh input message in this case it's just the name and it says how's your day\n31:49 going now I could have changed this to absolutely anything else right uh what goes here like these functions are\n31:56 almost endless but That's the whole flow of how everything works. So hopefully\n32:03 you understood how to build this very first hello world graph. It's quite\n32:08 simple. But um don't worry if you didn't fully 100% understand this. I'm now\n32:14 going to show you what exercise you need to complete uh to be able to solidify this. All right. All right. I'll see you\n32:20 at the exercise. Okay. So time for your very first exercise. So the exercise for this\n32:27 graph is quite similar to what we just did, but I want you to create a personalized compliment agent. So you\n32:35 should pass in your name as like something like Bob or something and then output something like Bob, you're doing\n32:42 an amazing job learning langraph. And to give you a hint as to what you need to do again, you again have to concatenate\n32:48 the state, not replace it. All right, it's very similar to what we just did and it's quite basic. You should be able\n32:55 to do this, but um this is really just to get your hands dirty. All right. Okay. Once you've completed this\n33:01 exercise, join me when we build the second graph. I'll see you\n33:06 there. Okay. So now we're about to build our second graph as you can see here.\n33:12 And it's again quite similar to the first graph we built except now we're\n33:17 going to be able to pass multiple inputs as you can see here. So again, what are the objectives which you will be\n33:23 learning in this? Well, we're going to build a more complicated agent state.\n33:28 Uh, and we're going to be creating a processing node that performs operations on list data. So now we're about to see\n33:34 how we can really work with different data types apart from just string. And\n33:39 we're going to set up the entire graph that processes and outputs these and computes these results. And we're going\n33:45 to be able to invoke the graph with the structured inputs and retrieve the outputs. But the main goal which uh I\n33:53 want you to be able to learn in this specific subsection is really how to handle multiple inputs. All right. Okay.\n34:00 Let's code this. Okay. So now let's actually code the second graph up the second\n34:07 application up. So again I've just imported the same things again the type dictionary and the state graph. And I've\n34:13 also imported the list this time. But list is just a simple data structure which you should know already. So if you\n34:19 remember from the previous graph we made we are supposed to uh implement the state schema first right. So how do we\n34:26 do that? Again we use the class agent state uh type\n34:32 dictionary. Okay before I continue just a heads up I could have named the state schema anything I want. I could have\n34:39 named it uh something arbitrary completely like a bottle for example. In this case I've just said agent state\n34:45 because one that's how I learned it. It's like a habit for me now. But it also really tells you what it actually\n34:52 is. It's the state of your agent, right? So that's why I've just kept it like that. But again, just a heads up, you\n34:57 could have named this whatever you want. Cool. Okay. So now let's the if you\n35:02 remember the main goal for this graph for this uh building this graph was to be able to handle and process multiple\n35:09 different inputs, right? So how do we actually assign and I really do that?\n35:17 Well, the answer is in the state which is here's what uh which is what we're about to do now. So you really cuz\n35:24 remember this is just a type dictionary. So you basically have multiple keys now\n35:30 you uh create that. So let's say something like values list integers.\n35:37 So let's say one of our input is a list of integers and let's also pass in a\n35:43 name which will obviously be in a string and let's have the result in a string\n35:50 something completely random. But now you can see we're now operating on two different types of data structures uh a\n35:56 a list of integers and a string. And we're handling three different uh different uh uh inputs values name\n36:04 result. Okay cool. So let's run this. Perfect. So now let's actually build our\n36:10 node because in again in this uh graph we're just going to have a single node to keep things easy. Remember step by\n36:17 step. So let's call let's write dev process values and again what was what\n36:24 needs to be here? Yeah. So we need to pass in the state and we need to return the updated\n36:31 state. So how do we do that? Well, we write state agent state and we pass out\n36:37 the agent state. Cool. Now, again, building healthy habits. I know it's\n36:43 annoying. We have to write the dog string. So, let's just write something like this\n36:50 function process handles multiple different value in multiple different\n36:57 inputs. Cool. Again, I'm not being super specific here because one, uh, I don't\n37:03 want to spend too long on writing doctrines and everything, and two, there's no AI or LLM here, right? So that's why it doesn't really matter. I'm\n37:09 just doing this to build healthy habits. Okay, so now let's do something like whatever values we pass the list of\n37:16 integers. Let's sum them up. And let's also concatenate the name as well and\n37:21 store it in the result. Sound cool? Okay, so how do we do that? We pass in\n37:27 state result cuz that's what we are uh the action we're performing is on result\n37:32 uh the attribute result and let's say something like hi there and then we refer to the name\n37:41 um cool and your sum is equal to and let's just use the inbuilt Python\n37:46 function sum and we pass state values cool and lastly we obviously\n37:54 return the Okay, perfect. And that's that done.\n38:00 Okay, so now we actually create the graph. Again, this is going to be very very similar to what we did in the\n38:07 previous section because again there's just a node, there's a start point and an endpoint. So like last time, we use\n38:14 the state graph to initialize a graph and we pass in our state schema. So agent state and let's store this in the\n38:21 variable graph. Okay. Uh let's add our node. So graph add\n38:27 node and again remember it requires two parameters. It requires the name and the\n38:32 action. So in this case the name will be let's call it processor for example. Again this could be anything you want\n38:40 and your action will be performed by this function right process values. So we can just add that. Okay. Now I've\n38:48 already told you how to uh how to initialize a start point and an end point and this is just given by that\n38:54 code. So you attach your entry point to your node. In this case it's just one node which is the processor node and\n39:00 again same goes with finish and you compile it using\n39:05 graph.compile. Perfect. So take a moment now. How do you think this graph will\n39:10 look like? That again like I said very very\n39:18 similar on how the graph actually looks like but the only difference now is the\n39:24 name of the uh node which we've kept this as processor. Okay. So now let's\n39:30 actually test this. Let's actually invoke this graph. So how do we do that? Well, we use the invoke function. Now\n39:37 here's another important part which is quite a common mistake especially like I have done this many times. Make sure to\n39:44 store your compiled graph in a variable cuz if you invoke the graph i.e. if you\n39:50 write something like graph.invoke that won't make sense cuz you haven't compiled the graph. That's why you need\n39:56 to uh invoke using app. That's why I've also done app here. If I did graph get\n40:03 graph. Oh, it's completely messed up. Right? It says state graph object has no attribute because your graph hasn't been\n40:09 compiled yet. That's why when I do appget graph the uh process works. Cool.\n40:16 So now let's again store this in uh let's store something like answers is\n40:21 equal to app.invoke. Cool. Let's pass in some values. Let's say something like\n40:29 values and let's have a list of integers. 1 2 3 4. Again, I'm just\n40:35 trying to prove a point. I'm not trying to make a very complicated um graph yet. And let's pass the name as something\n40:42 like Steve something. Okay. Uh cool. And\n40:48 let's print let's print answers. Let's see what happens. Perfect. So now you can see\n40:55 your values is 1 2 3 4. Your name is Steve. And your result is Hi there\n41:00 Steve. Your sum is equal to 10. Again, why? because that's exactly what we uh\n41:05 asked the node the action to perform. Hi there, your name which in this case is Steve. Your sum is equal to the sum of\n41:12 the values and 1 + 2 + 3 + 4 is 10. Right? And that's how you get this\n41:18 answer. Now what if I wanted to just access result? I didn't want any of this\n41:24 other uh nonsense. Well to do that you can again just specify result and you will get it\n41:31 in a more clean manner. Cool. Okay. Now I want to try one more\n41:38 thing just to build your understanding a bit more. Uh let's put some print\n41:43 statements here. So let's have a print state\n41:49 here. Then we perform the action and then we print the state here. This is\n41:55 really just to show you how the state gets updated and it should be easy like\n42:00 interpretable cuz this is quite a basic piece of code. Again, print stated before the action and print state after.\n42:06 So there cool and here you go. So value is equal\n42:12 to 1 2 3 4 name is equal to Steve and these are the inputs we passed. Now notice I didn't pass results as an input\n42:19 as well. I could have uh done that but Langraph automatically sets that as like\n42:25 a a none value in this case if you don't pass an input. Now here's where you need to be\n42:33 cautious. If I had actually used state result here as well to uh update state\n42:39 result like I used state result to update either itself or something else\n42:44 then you would run into a problem because your state result has been initialized as none because you didn't pass it as an input. So be mindful of\n42:52 that. But in this case it worked because we're only assigning state result. We're not using it to assign something. It's\n42:59 getting assigned. Cool. And you can see after the action has been performed uh\n43:05 your operation has been performed and the thing has been concatenated. You can see result is here and that was exactly\n43:12 what we were getting before we cleaned this up. Cool. So hopefully you understood that. Again it should have\n43:18 been quite intuitive and interpretable but um to solidify your understanding even more complete the exercise. So I'll\n43:25 see you at the exercise then. Okay. Welcome to the exercise,\n43:30 your second ever exercise. And for this exercise, I want you to create a graph\n43:37 which passes in a single list of integers along with a name and uh an\n43:42 operation this time. And if the operation is a plus, you add the\n43:47 elements. And if a well times, you multiply all the elements all within the\n43:54 same node. So don't create an extra node yet. So for example your input should\n43:59 could be jack sparrow your values 1 2 3 4 again and then your operation uh uh\n44:04 multiplication and your output should be in the format of hi jack sparrow your answer is 24 so just to give you a hint\n44:11 as to how you would perform something like this uh you would need an if statement in your node so slightly more\n44:17 complicated but the whole concept is the same so once you've completed this exercise I will see you in when where we\n44:25 build this third graph All right, see you there. Okay, welcome to your third\n44:33 graph. So, what are we going to do this time? Well, enough processing multiple\n44:39 values and everything. Let's actually get the graph more complicated. So, that's why we're going to be building a\n44:44 sequential graph. So, all it all that basically means is we're going to be\n44:49 creating and handling multiple nodes that can sequentially process and update different parts of the state. So we will\n44:56 learn how to connect nodes together in a graph through edges of course and we're going to invoke the graph and really see\n45:02 how the state gets transformed as we uh progress through our graphs step by step. So again your main goal is should\n45:10 be to understand how to create and handle multiple nodes in langraph.\n45:15 Sounds cool. Okay I'll see you at the code. Cool. So now we're about to code\n45:22 up the third graph. Uh, and we're making quite fast progress. So well done on that. So again, the imports are the\n45:30 same. State graph and type dictionary. Perfect. And like we've done in the previous two\n45:37 graphs, we're going to be coding the uh the state schema or the agent state first. So let's have class agent state.\n45:46 And again, it needs to be in the form of a typed dictionary, right? And in this case, let's have the three attributes as\n45:53 all strings because we've already we already know how to handle multiple data types, right? So, let's keep it simple.\n45:59 Name string, age string, and final string.\n46:06 Okay. Now, here's what we're going to build. Now, we're about to build our two\n46:11 node functions, uh, which are again the actions. Okay. So again you simply write first well\n46:19 I'll name it first node in this case and like I mentioned before we pass in the\n46:26 state and we return the updated state. Okay. So again healthy habits doc string\n46:34 again. So this is the first node of our\n46:39 sequence. Okay. And what do we want to do in this specific node? Well, I really\n46:44 just want to manipulate uh the final part. So, let's say something like\n46:51 state final is equal to state or let's\n46:56 have an f string\n47:02 f state name. Let's say something like\n47:08 hi that. Cool. And we'll just return the state. Perfect. And now again we create\n47:16 a new node. So state agent state. Return\n47:21 that. Perfect. And I'm just going to copy this dock string and just change it. This is the\n47:27 second nerf. Perfect. Okay. To speed things up. And in this case I also want\n47:34 to have state final is equal to you are\n47:43 state age years old. Again quite a simple\n47:50 example easy to follow. That's why I've kept it as quite a basic graph. I mean\n47:55 it's not going to solve the world's problems or anything but it will help you understand.\n48:00 There is one logical error which I've put deliberately here. I want you to try\n48:07 to identify it. Okay. So the logical error in this\n48:15 case is the that once we've built our graph and everything what would have\n48:20 happened is we would have said hi to whoever uh we pass in let's say Charlie\n48:26 or something. So, hi Charlie. And we store that in the final uh attribute in the state, which is what we want. But\n48:33 here's where things get like start to be well logically incorrect. Once we\n48:39 finally get to our second node, again, we're updating state final, which you can do. You can repeat, you can um\n48:46 interact with these attributes at in in any node possible in all of the nodes.\n48:52 And you can do it as many times as you want. But notice this part. What's\n48:58 happening here is we've completely replaced all of the content we had before. So remember how we had hi\n49:03 Charlie? We've just completely replaced it with you are age years old. But we\n49:10 want both of them both of those stuff, right? So how do we get both of them?\n49:15 Well, again we just concatenate them. So we can have something like state\n49:21 plus state file. And there we go. Logical error should be now solved,\n49:27 right? Cuz now we have concatenated state final. Uh we're essentially just like adding on to uh we're preserving\n49:35 what we had before, right? Okay. Now let's get to the fun part. How do we\n49:41 actually build this graph? And really it's quite similar to the previous two\n49:46 graphs except there is one new thing which you're about to learn. So like always we use state graph to start the\n49:53 framework. So agent state and let's store it in graph. Again I could have had this name\n50:00 the width variable into anything. I've just kept it graph cuz it makes intuitive sense. Okay. Now we add our\n50:07 nodes. So we do graph add node. And for simplicity sake I'm just going to have\n50:13 the name as the same name as the uh function. Okay. So that way it'll just\n50:19 be easy to follow. So graph add node and second\n50:27 node. Second node. Cool. Okay. Now that we've added both nodes, we need to\n50:34 obviously s uh add the entry point and the end point, right? So we set the\n50:40 entry point like this. Again, quite self-explanatory because we wanted to connect to the first node, not the\n50:45 second node, right? So it should be start uh first node, second node, end\n50:51 point. How do we connect the first node and the second node together\n50:59 though? Hopefully you had an answer for that. Uh if you remember or recall from\n51:04 the previous section, theory section, there was an element in Langro called the edge. That's exactly what we're\n51:10 about to do right now. We're about to use edge and that was the new thing which I was talking about a few moments ago which you're about to learn. So how\n51:17 do we use it? Well you use graph edge add edge and if we can hi perfect. So\n51:25 again it's quite simple you use a start key and end key. So sim similar to entry point where but your in this case you\n51:33 need to pass two parameters. So the edge we want is between the first node and the second node right? Well that's\n51:40 exactly what we pass here. So first node and second node and like before we will\n51:48 just set the finish point at second node and we will compile this. Now how will\n51:53 this graph look like? Take a moment to try to think of how it will look\n52:02 like like that. Start point end point and these two notes are sandwiched in\n52:07 between. But now there is a edge. It should be called a directed\n52:12 edge if I'm being like quite picky. But yes, a directed edge cuz the flow of\n52:18 data or your flow of your state updates is from the first node to your second node. Right? Cool. So now that we've\n52:24 built that, let's again invoke this. So I've got this code ready here. Uh let's\n52:30 invoke it. Let's pass the parameter as Charlie and let's pass the age as 20.\n52:37 Cool. Print result. Perfect. Apart from the uh\n52:43 misalignment here which I can just change right now. Perfect. Okay. So now you can see\n52:49 it says hi Charlie you are 20 years old. Now obviously we could have performed all of this in one single node which we\n52:56 have been doing in the previous subsection but the obviously the aim was to be able to create multiple nodes\n53:03 right and handle um the state how the state progresses. So yes you one\n53:08 important thing which you've learned is obviously how to use the add edge method but another concept which you have\n53:15 solidified here is you can uh change these at these keys of your state at in\n53:22 at any point in time like as long as as however many times you want cuz remember\n53:29 here we've passed in state final um we implemented state final here we implemented state final in the second\n53:35 node if we had more nodes in the sequence. We could have done that again and again and again. And we also learned\n53:41 how to like one key logical error is sometimes a lot of people just accidentally replace uh their content in\n53:48 one of the attributes and that leads to a lot of logical errors. So always be mindful of that. And yeah, that again\n53:55 was quite simple, not too hard and hopefully the exercise which I'm about to give you solidifies this. Cool. So I\n54:03 will see you at the exercise then. Awesome. So now we will move on to the\n54:09 exercise for this third graph. And what I want you to do is really build on top\n54:15 of what we just covered. Instead of two nodes, I want you to build three nodes. Again, in a sequence, don't need to go\n54:22 too fancy yet. We will again three nodes in a sequence. And we will have you will\n54:29 need to accept the user's name, their age, and a list of their skills. So the first node will be specifically for\n54:35 personalizing the name field with a greeting. The second node will be describing the user's age. The third\n54:42 node will be listing all of the user skill in a formatted string. And then you'll need to combine this and uh store\n54:49 it in a result field and output that. And this should be a combined message. And the format I would like you to\n54:55 output is something like this. So let's say the name was Linda. And let's say Linda welcome to the system. You are 31\n55:03 years old and you have skills in Python, machine learning and langraph. Okay. And\n55:09 just as a hint for this exercise, I would you'll need to use the add edge\n55:14 method twice. So this will really solidify your understanding on how to build graphs in general. All right,\n55:22 cool. So once you've done that, again, answers will be on GitHub for all of the exercises. Once you have uh cross\n55:28 referenced and checked that you've done it right, I will see you in the next section where we build our fourth graph.\n55:34 All right, see you there. Welcome, welcome, welcome. Okay, I'm particularly excited for uh teaching\n55:41 you this graph, graph 4. Why? Because we're about to learn how to build a conditional graph. So for the very first\n55:49 time, we're about to implement conditional logic. And obviously we've\n55:54 done it in a previous exercise before but that was within a single node. This is how to implement conditional logic in\n56:00 the overall graph structure. And so we will be implementing conditional logic to route the uh flow of data to\n56:07 different nodes. We will be using the start and the end nodes to manage entry and exit points. We will be designing\n56:14 again using multiple nodes to perform different operations such as addition and subtraction. And we will be able to\n56:20 create a router node to handle decision-m and control the graph flow. So the main goal is really to you how we\n56:28 can use this inbuilt function which uh allows you to create conditional edges in langraph. All right, exciting stuff.\n56:35 I'll see you at the code. Okay, so let's actually code this\n56:41 up now and you'll see the imports are slightly modified this time. Again, type\n56:47 dictionary and state graph is there. But now I've also imported start and end point. Again, if you remember a few\n56:54 subsections ago, I told you there are multiple ways to be able to initialize the start and the end point. And this is\n56:59 another way you could. Arguably, this is the easier way, but um whatever. I don't\n57:06 really have a preference, but I'll teach you both ways regardless. Okay, let's import these. Successful. Okay. like\n57:13 standard procedure we will design we will um code up the uh the schema the\n57:19 state schema so class agent state and let's again type dictionary in this case\n57:27 uh uh I want to be able to pass in two numbers and pass in an operation so a\n57:33 plus operation and a minus operation one of those two operations now obviously I\n57:38 could have handled uh all of this within one single node But that's not the point\n57:43 here. I've kept it deliberately very very simple. So the main concept which you learn is how to uh implement\n57:50 conditional logic. Okay. So let's code the different uh keys\n57:56 which we require. So number one will be an integer. Operation will be in the string a plus or a minus. Uh number two\n58:05 will be an integer and final number will be an integer. the final number will be the result of either adding or\n58:11 subtracting the two numbers. Easy enough. We've done this multiple times now. Okay. Now, here's\n58:18 where things get interesting. Now, just a heads up. Initially, this won't make\n58:24 sense. But when we look at it from a bird's eye view and we look back at all the code in this subsection again, uh\n58:32 everything will start to click. So again, it won't make sense initially, but it will once we look at it. Uh\n58:38 again, don't worry. All right. So let's create our first node function. Let's call it adder. And it's again still a\n58:46 node. And we input the state schema. And we return the updated state schema and\n58:53 dock string again. But uh this time I'm just going to copy it from here. Uh it's\n58:59 tells exactly what it does. This node adds the two numbers. Uh and easy enough, we just do state final number is\n59:06 equal to state uh number one plus state number two. Okay. And we just\n59:14 return the state. Quite simple, right? And just\n59:20 like what we did with the addition, we need a node for subtraction as well. So def subtractor. Now uh I already\n59:29 implemented it to uh don't to not waste time but this node subtracts the two\n59:34 numbers. It's very similar to the previous uh node function. Uh it just\n59:39 subtracts these two numbers. Again yes you could be saying what if number one is uh smaller than number two it'll give\n59:46 you a negative result. It that doesn't matter. The main aim again was to implement the conditional logic not the\n59:53 um inner workings of each node. Okay. Okay. Now we built another type of node.\n1:00:00 Uh and we initialize it the same way but this time let's call this node decide\n1:00:06 next node. Let's actually give it a name which actually says what it does. Right.\n1:00:11 So again we use state agent state and we pass like this. Perfect. Okay. Now the\n1:00:19 dock string will be something like so. So this node will select the next phase\n1:00:25 of the graph or well next node of the graph I should say. Okay. Now we use an if statement and\n1:00:33 before I code something let's just try to map how this will work. This specific\n1:00:39 node will be at the start of our uh graph. So we will have the start node. We will have this uh this specific node\n1:00:46 we'll call it the router. and this router because it routes uh the next uh\n1:00:52 to the next node depending on what the state schema is at that point. So we will have the uh I will put an image up\n1:01:00 right now so you kind of get what I'm trying to say but we essentially will\n1:01:05 have the router decide whether we uh add the two numbers and subtract the two numbers and obviously this will be\n1:01:11 decided with the operation uh attribute right which you should see from here.\n1:01:16 Okay, let's code this up now. So this is not the hard part. If state operation,\n1:01:24 if I can spell if state operation is equal to equal to\n1:01:31 plus. Okay, if state operation is equal to equal to plus, we need to do a certain thing to\n1:01:38 pass it to the next node. Okay, now here's well your first guess could be\n1:01:45 okay. Well, we guess I guess just call this function, right? Not exactly. Not in langraph. You actually return\n1:01:54 uh return the edge. Now, we haven't described the edge yet, right? But for\n1:02:00 now, I will just say the edg's name is addition operation. So, addition operation. Similarly, if it's\n1:02:07 subtraction, we will do this like so. So just to reiterate we will uh you we will\n1:02:15 see what the um value is at the operation in the state schema. If it's a plus we call we will return the edge\n1:02:23 addition operation and if it's a subtraction we will use the subtraction operation edge. Again we haven't\n1:02:30 described or defined these two edges yet. That's what I was saying earlier. When we look at it from the bird's eye\n1:02:36 view later on in a few moments once we've built everything it will make much more sense. So stick with me for now.\n1:02:42 Okay. And runs perfect. Now we build the graph. And now here's the exciting part.\n1:02:50 So we again like normal standard procedure we use state graph to create\n1:02:56 the graph framework. So graph is equal to that. And let's add these nodes uh to\n1:03:02 the uh to our graph. So graph add\n1:03:08 node and let's say router. Okay. And again we will pass\n1:03:15 this decide next node. Perfect.\n1:03:21 Okay. Now I have another confession to make. Lots of conventions. I know this\n1:03:26 won't work. I know I haven't built the rest of the graph yet but this eventually will not work. And there is a\n1:03:34 subtle reason why this won't work. You know, it's mainly in this line. Add node\n1:03:40 router decide next node. The problem is with decide next node cuz oh, you can\n1:03:47 see that the dock string appears once we press uh the decide next node. But the\n1:03:52 reason this won't work is look closely at these three functions. What are we\n1:03:57 doing in these two functions that we're not doing in this? I'll give you a moment to try to analyze\n1:04:10 this. Okay. So, doesn't matter if don't worry if you didn't get that. The\n1:04:16 correct answer is we are returning this updated state in this one and this one.\n1:04:21 But in this node, we're not. We're just returning the edge. Subtle difference I\n1:04:28 know but that's how Lang graph works and you will see why they do it like that\n1:04:35 uh right now. So how do we deal with this? Now I obviously could have built this graph and then I would have shown\n1:04:41 you the error but then things would have just gotten messy. That's why from the get- go I have told you why this wouldn't work. So now that you know why\n1:04:48 this won't work, how do you fix this? Simple. You use this code lambda\n1:04:54 state. Now, if you have used lambda functions before, this is quite easy to understand. If you haven't, don't worry.\n1:05:00 All this is saying is your input state will be your output state. That's it. In\n1:05:07 even more simpler words, think of this as a pass through function. So, what it's saying is your\n1:05:14 input state will be passed, your state will be inputed and your output will be\n1:05:21 the exact same state. Now, why is it the exact same state? because you're not changing the state at all. You're\n1:05:28 comparing stuff here, but you're not assigning anything. There's a difference between comparison and um and\n1:05:34 assignment. Right? Again, even in this one, you're just comparing to see whether the operation is a minus, but no\n1:05:41 assignments been made at all. In fact, there's been no changes to this state\n1:05:47 whatsoever. That's why we can use this as a pass through function. Now, hopefully that made\n1:05:53 sense. Okay, let's continue. Again, we will get a lot more practice. Don't worry, this\n1:05:59 is the first time you're seeing this. Okay, so now we will add the edge. And\n1:06:05 this is just the normal edge we did last time. So, we will need the start key. And now here's how you initialize\n1:06:11 differently. Remember how we used to do set entry point and set finish point? We don't do that anymore. Uh we use start\n1:06:19 the keyword cuz that's what we imported. Make sure to import it if you do it this way. uh you use start and end. So your\n1:06:26 start will be a start point and your what do you want the start to be connected to? Well, we want it to be\n1:06:32 connected to the router. If I put this in quotation marks, perfect. Now, why not add node or\n1:06:38 subtract node? Well, think again. Refer back to that diagram which I'll show in\n1:06:43 right here. We if we connected the start point to\n1:06:48 the the add node or the subtract node, well then what's the point of the router in the first place, right? The whole\n1:06:54 point was the router decides what the inputs are and then from there it branches off to the correct node. So\n1:07:01 that's why the router needs to be the first node we uh connect our start point to. Cool.\n1:07:07 Okay. Perfect. Now we add the we now implement the main the new thing which\n1:07:14 we are going to learn in this section is graph dot add conditional edge. So graph\n1:07:21 dot add conditional edges. Now again wow looks really\n1:07:26 confusing but it's actually much more simpler than it looks like. So the first uh part is your\n1:07:33 source which you can see here as well. So the source will just simply be the name of the node. And what's the name of\n1:07:40 the node which we want the conditional edge to be? It's the router node, right? So that's going to be the source part.\n1:07:47 Perfect. Now if you look here, it's asking for a path. What's the path you would like it to do? Now before we\n1:07:54 implement the path, we obviously need to per uh imple uh tell it what action what\n1:07:59 what action it needs to do. And that's where this node will come in the decide next node part. So we pass that as the\n1:08:04 second parameter. So that's the path. And now we implement something\n1:08:10 called the path map which you should have briefly saw\n1:08:15 here. Uh there path map. So we've implemented the source which is the\n1:08:21 router. We've implemented the path which is your uh decide next node function. Uh\n1:08:27 again don't need to worry about hashable runnable any and all of this stuff. Okay, it's you don't need to over\n1:08:33 complicate it. Now it's time for the path map. Okay, so now your path map will be in a form of a dictionary. And\n1:08:40 remember how I said earlier that we had implemented addition operation and subtraction operation. These were edges.\n1:08:46 So now we're about to implement those only. So we're about to create two new\n1:08:52 edges here. Let me just write this code up for you and then it will make sense.\n1:08:57 Give me one second. Okay, so there we go. Now what is this\n1:09:05 code actually saying? Well, this is in a format of edge and\n1:09:12 node. Now the starting point of this edge will obviously be this router node and it's telling us where it will\n1:09:18 connect to. This uh visualization will be it will be it'll be much easier to\n1:09:24 visualize when I actually show you the graph. Don't worry. But for now, addition operation and subtraction operation is the edge. And the two nodes\n1:09:31 are add node and subtract node. Right? Okay. Uh lastly, we now we're now at the\n1:09:38 point where we need to create the end point. But obviously, we if you look back at this diagram which I've shown on\n1:09:44 the screen right now, you can see that the we need two edges to connect to the\n1:09:51 end point, right? We need to we need an edge from the and node and we need an edge from the subtract node. So we can\n1:09:58 add two edges like this. graph edge. Uh we uh start at the add node and\n1:10:05 then we end at the endpoint. Again similar subtract node and endpoint. And then we just compile this. So app is\n1:10:11 equal to graph.compile. Cool. No errors. Okay.\n1:10:18 Now here comes the most exciting part. Again try to visualize what this graph\n1:10:23 will actually look like. Okay. So it should look something\n1:10:29 like that. Probably slightly different to what you initially anticipated but\n1:10:36 that's okay. We again have a start point. We have the router and we have the our two nodes add node subtract\n1:10:42 node. And notice remember when I said addition operation and subtraction operation are the edges names. Well,\n1:10:48 here it is. Addition operation and subtraction operation. It's telling us uh what the which direction to go into.\n1:10:55 Do we go how do we go to add node? Well, we use the addition operation. How do we go to subtract node? Well, we go to the\n1:11:01 subtract operation. And then obviously we create these two edges, these two to connect to the\n1:11:10 endpoint. Awesome. So, we will once again look at it from a bird's eye view. But let's actually invoke this graph to\n1:11:16 see what happens. So let's use this piece of code. So what\n1:11:23 it's saying is it's defining number one as 10, operation as minus and number two as five. So because we've used\n1:11:30 subtraction, the final number should be 10 - 5 which is five. And we've printed\n1:11:36 the results and the answer is like such. Uh number one is equal to 10, operation\n1:11:41 is equal to minus, number two is equal to 5 and final number is uh five. Obviously the way I've invoked it is\n1:11:47 slightly different to what I have done before. Again, this is another way you can invoke. Okay, so not too hard. But let's\n1:11:56 just go through everything one more time to solidify everything. Okay, so we\n1:12:02 imported everything. We created the state schema using agent state and a type dictionary. Then we created our\n1:12:07 three different nodes which is the add node, subtract node and the decide next node. And this is in within the decide\n1:12:15 next node. You can see that if the operation is a plus, it goes to the addition operation edge which is this\n1:12:22 edge. And if it's subtraction operation, it goes to this side. And this is how we\n1:12:28 built the graph. We added the nodes. We added the edge from the start point uh to the router. And then we added the\n1:12:34 conditional edge. the new thing which we've learned in this section uh which is we uh reference router and we use the\n1:12:40 edge node format. So the edge will be addition operation uh to add node then\n1:12:47 it will be subtraction operation to subtract node. Visually speaking it will be addition operation to add node\n1:12:53 subtraction operation to subtract node. Now, I know this will be quite confusing at first and don't worry, it took me\n1:12:59 quite a while to understand this myself as well, but hopefully the exercise I've given you will really be able to help\n1:13:05 you understand this much better. Okay, so I will see you at the exercise\n1:13:11 then. Awesome. So, let's actually find out what the exercise is for this graph. So, you need to make this monstrosity.\n1:13:20 Now at first glance it looks terrifying but if you analyze it a little bit closer all it is is what we just coded\n1:13:27 twice. So we coded this and we need to replicate it once more. So in essence\n1:13:33 you need to actually input four numbers and two operations and you need to output their final results. For example\n1:13:39 number one, number two, number three, number four and the respective operation and the respective results. Right? So in\n1:13:44 this case we would have to do 10 - 5 which is 5 and 7 + 7 + 2 aka 9 and those\n1:13:51 two numbers should be outputed. Now the reason I gave you this exercise to do is because this will really solidify your\n1:13:57 understanding about conditional edges which will really be important for the next few next graph and the next AI\n1:14:04 agents we make. Okay. So once you have uh completed it by looking and cross\n1:14:09 referencing the answer on GitHub, I will see you in the next graph.\n1:14:15 Okay. All right. Well done. We're almost at the end of this section and we're about to build our final graph aka graph\n1:14:22 5. Now we've learned quite a lot about Langraph and its internal mechanisms. And this will really help us in the next\n1:14:29 section where we finally build the AI agents you were looking for. Now in this\n1:14:34 section in this subsection sorry we're going to be learning an important concept. There's still one more concept\n1:14:39 we haven't learned and that's about looping. So we're going to be creating well a simple looping graph. Now I kept\n1:14:45 the objectives to be quite small here. There aren't that many objectives. It's essentially implementing logic uh which\n1:14:52 involves looping uh to route the flow of data back to the nodes. And we're going to be creating a single conditional edge\n1:14:58 which you know how to do in the previous section. Regarding the previous section, however, I know the exercise. Please do\n1:15:05 complete that exercise. That exercise will be probably the hardest exercise you would have done until this point.\n1:15:12 So, don't worry if you didn't get it. If you did, great job. You're doing really, really well. But if you didn't get it,\n1:15:18 look at the GitHub. Try to compare where you went wrong. Remember, in Langraph, there's more than one way of building\n1:15:24 the graphs. Make sure the graphs are well built and it actually functions.\n1:15:29 And if you want an extension, try to make it even more robust than it is. All right, but back to this now. Final\n1:15:35 graph, I promise. The main goal really is to code up the looping logic. So,\n1:15:40 with that out of the way, let's build a final code for this section. See you\n1:15:46 there. Awesome. So, final code we have to build for this section. And here we\n1:15:52 go. So, graph 5 squ. Now, I'm going to take a slightly different approach this time. And I'm actually going to show you\n1:15:58 the graph we want to end up building from the get- go. And there's a reason I'm going to start that from now so we\n1:16:04 get in good practice. The reason is once you finish this course and actually\n1:16:09 start either making your own AI agentic systems for someone else, for your clients or for yourself like make your\n1:16:15 own JavaS system or whatever. You obviously need to plan how it works, right? You need to see okay, what nodes\n1:16:22 do I need? What edges do I need? Does is this does this need to be a conditional edge? where's the start point going to go, end point going to go etc etc and\n1:16:29 you can either do that via pen and paper or software like I've used but point is you need some sort of blueprint and\n1:16:38 that's how really it works in the industry as well um you can you will obviously have a blueprint and then from\n1:16:44 there you will code up the graph similar to how a UI designer for example uh renders um their UI designs and then\n1:16:52 sends that off to a software developer who uh well develops the application forwards. Right? So that's the habit I\n1:17:00 want to start uh creating with you. All right. So this is the graph I want to\n1:17:07 build in this section. So there's obviously going to be a start and end point. And this really should be mostly\n1:17:13 familiar except for this loop. So there we're going to create a simple greeting node and another node which is called\n1:17:18 the random node. So in the greeting note I essentially want the user to have uh\n1:17:24 stated their name and it should output a simple hi there your name and then the\n1:17:31 graph progresses to the random node and in the random node I essentially want to\n1:17:36 generate five random numbers. Okay, now just as a heads up, yes, this graph in\n1:17:44 industry would be completely useless. I know, but I've deliberately kept it simple again so you know the\n1:17:49 fundamentals. Like this loop is could have easily been avoided and transferred\n1:17:55 into a for loop for example, right? Like I could have had a for loop within this node and ran it five times to generate\n1:18:02 the numbers. I get it. But this is again kept deliberately simple so you actually understand the concept. Okay, cool. So\n1:18:09 let's the usual inputs and the only difference is this time I've also imported random but if you have used\n1:18:15 Python before quite a lot you would have come across this library right okay so\n1:18:20 let's start with our agent state so class agent state type\n1:18:26 dictionary and what's the first thing we're going to need well let's see we\n1:18:31 have the start point do we need anything any keys that no for greeting note what did I say I want uh I wanted the user to\n1:18:38 be able to input their name. So, we need a name attribute or a key. And then for\n1:18:43 the random number, a random node, we need some form of um a list to like\n1:18:51 actually store the numbers. So, we have number and list\n1:18:56 int. Okay, cool. And one more thing, look at this loop. How will we actually\n1:19:02 know when to stop? We need some form of counter, right? So, counter int.\n1:19:08 Perfect. Now, obviously, just as a heads up, when you do go on to make your AI agents and everything, you're not going\n1:19:15 to know what attributes you need right from the get- go, unless if you planned it like extremely extremely well. But\n1:19:22 chances are you won't get it. But don't worry, iteratively well, you'll obviously be better at speculating what\n1:19:29 attributes you need through practice. But you can obviously do iterative development as well, right? Okay, cool.\n1:19:35 So now let's actually build these nodes. Okay. So let's start off with the\n1:19:40 uh greeting node. So how we normally define uh a function. So def greeting\n1:19:46 node, we obviously need the agent states like such. Perfect. And the dock\n1:19:55 string. But uh luckily for me, I've already got that here. So I don't need to do it again. I know it's boring, but\n1:20:01 habits. Now let's update update the uh name uh key. So how do we do that? Well,\n1:20:10 you should know by now state name is equal to let's say something like hi\n1:20:16 there. State name. Perfect. So what will this do? I input a\n1:20:22 name and it'll replace that name with a string of hi there this person. Now\n1:20:27 let's also initialize the counter variable here. Now why am I doing that?\n1:20:32 Let me just first write it and think about this. Okay. Now, obviously I'm changing I'm\n1:20:40 setting like the value. So, I will need to have passed in like an valid integer\n1:20:45 when I am passing the uh value when I'm invoking the graph, right? But here's\n1:20:52 the thing. What if I pass in minus2 for example? Well, as the counter value, as the\n1:20:58 initial counter value, if this line wasn't there, well, it would have just kept on incrementing until it got got to\n1:21:05 five cuz I want to have five numbers. But if it starts at minus2, well, it would end up giving me seven numbers.\n1:21:12 Now, that's not robust, right? So, this basically wipes out whatever rubbish\n1:21:18 integer the user even inputs. If they had put zero, well, okay, we replaced it to zero. If they put like minus 20\n1:21:25 because they're greedy or something, then we have made sure to like set that back to zero. So, so just a way to make\n1:21:31 it robust. That's all. Uh, return state. Okay, cool. So, now let's create our\n1:21:38 second node which is a random node. So, we can say random node state agent state\n1:21:46 agent state. Perfect. Dog string. Again the dog strings will be useful. I\n1:21:52 promise in the next section they will. So this generates a number random number\n1:21:57 from 0 to 10. Now this piece of code here\n1:22:03 essentially appends the appends the randomly generated number to the number\n1:22:09 list. Okay, that's all it does. And what else do we need to do in this node? Well, we need to increment the counter\n1:22:15 value, right? So C uh plus equals to one. So this will\n1:22:22 increment uh the value by one and then we just return the state. Okay, cool. Now here's where\n1:22:31 we're how we're going to implement the looping logic. Now just a warning here and please listen to this. Like in any\n1:22:37 software development uh program or programming language G2, there's more\n1:22:42 than one way of coding up an application, right? Same goes with Langraph as well. There is multiple multiple different ways of coding like a\n1:22:50 looping code like this graph. I'm going to be showing you one of them. I obviously can't show you all of them cuz\n1:22:56 there it's just time constraint, right? But obviously the more you practice the\n1:23:01 uh uh better ways you'll more efficient ways you'll find, right? But the way I'm going to show you is pretty efficient as\n1:23:07 well. Don't worry. Okay. Now, you might have speculated that I'm going to create\n1:23:12 like a router node. It's close. I'm not going to create another router node. You\n1:23:18 can see in the graph the uh the client let's say the client wants this graph. The client doesn't want another router\n1:23:24 node here. So how do we go about that? Well, we could create a conditional edge. How do we do that? Okay, let's\n1:23:31 begin that. So let's write a new function say defaf should continue uh state agent\n1:23:38 state agent state and um let's create this block\n1:23:44 string um function to decide what to do\n1:23:49 next something like that. Okay cool now here's where we set our looping logic\n1:23:55 and this should look quite familiar to you\n1:24:00 now. Perfect. So let's run that. Okay. So what have I written here? Well, if\n1:24:05 the counter value is less than five because we're starting with zero, right? So 0 1 2 3 4. That'll be five values. Um\n1:24:12 I've also written a print statement so like we can keep track of um um the\n1:24:18 progress. Also whenever I'm writing the code as well when you're uh coding with me or doing the exercise, it's really\n1:24:24 helpful to print uh statements uh like put in print statements everywhere. Or\n1:24:29 you could also use break points as well. So you know uh where to where the code failed if it\n1:24:36 fails. Okay. So here we return the loop a loop edge and the exit edge. So\n1:24:44 obviously we have the loop edge and this will be the exit edge. So everything is going to plan so far but um so far is\n1:24:50 the key. You never know, right? Okay. Uh just as a heads up though, I want to\n1:24:55 show you this. So this is how the trajectory should follow. We start at the greeting node. Why? Cuz we obviously\n1:25:02 go from the start to the greeting node. And then we enter the random node. And we enter the random node and exit it\n1:25:08 five times. So 1 2 3 4 5. Why five times? Because we want five random\n1:25:14 numbers, right? By then this if statement will uh well it won't work. It will fail. So we will go to the else\n1:25:20 statement and return exit. And if we return to exit, we'll go to the end node. Uh okay. endpoint. Okay, so that's\n1:25:28 how the general gist is. Okay, let's quickly make this graph. So you should know how to initialize a graph agent\n1:25:35 graph and let's just add these nodes. So we have our two nodes which are\n1:25:43 here greeting and random which is exactly what we wanted, right? Greeting node and random node. Perfect. Okay. And\n1:25:50 now we're going to add an edge between greeting and random. Uh why? Because\n1:25:56 well I've created this edge. You see this edge greeting node and random node. This edge that's the edge I've created.\n1:26:03 Okay. Now I'm going to create the um the conditional\n1:26:08 edges which is done through here and I've written some comments here\n1:26:14 as well. So uh there will be the source node which is the random. So where I\n1:26:21 want the conditional edge to start from and then the routing function or this tree I should have really written action\n1:26:27 here because is the action I want to perform the underlying mechanism or function which is going to which we're\n1:26:33 going to um determine which edge to use and that's uh implemented by the should continue function right and notice how\n1:26:40 again these two edges are the same edges here. So if the loop is uh the one which\n1:26:47 um uh is outputed then we need to go back into its random the random node\n1:26:54 which we've generate uh which we put there and if it doesn't we go to the end part. Okay and then obviously we set the\n1:27:01 entry point. Okay. So again you don't have to\n1:27:07 set the exit point here uh or the finish point because we've already done it using end here. Okay, perfect. And then\n1:27:14 we just compile the graph app is equal to\n1:27:20 graph.compile and okay, it compiled. That's a good sign. But let's see if we\n1:27:26 have got our graph to be the exact same. Now I'll put the graph image here\n1:27:32 so I don't keep scrolling back and forth. But you can see we have the start point and the end point. We have the greeting and the random. And then we\n1:27:39 have our two condition edges. So we have the loop going back into the random node\n1:27:45 as we wanted and the exit which you can see. So take a moment and you can see compare and contrast. Okay, let's\n1:27:54 continue. Okay, now I have this code. So I've given a name my name uh a\n1:28:01 r um a completely brand new list and I've set counter to minus one. And as you can see it enters loop\n1:28:08 one, loop two, loop three, loop four because these are print statements we printed. Uh it says hi there v which is\n1:28:15 my name. Uh number 10 21026 just randomly generated and you can see the counter value is five. Now remember what\n1:28:23 I was saying over the counter. We set the counter value to zero here to make it more robust. If we had not done that\n1:28:28 well it would have generated six times. And now I can set this to minus 100. it will still obviously give me different\n1:28:35 random values but um the code is largely the same. So that's really the way which\n1:28:42 I personally use to create loops in langraph it's pretty easy right but um\n1:28:49 obviously with practice you might even find some other ways if you do find other ways like obviously uh do let me\n1:28:55 know uh there's more than one way again you can send me a message on LinkedIn or Instagram or whatever but um yeah so\n1:29:03 this is finally finally uh we have implemented the code for our final graph\n1:29:09 of the section So just complete the graph 5 exercise please and yeah we should be good to go\n1:29:16 to make AI agents. So I'll see you at this codes exercise. Okay\n1:29:22 cool. Okay good job on that. Now for the exercise for this last graph uh you need\n1:29:28 to implement this graph on the right. So you need to implement an automatic higher or lower gain. So for context,\n1:29:36 you need to set the bounce which we can guess between 1 to 20 integers of course and the graph has to keep guessing where\n1:29:43 the max number of guesses is 7 where if the guess is correct it stops but if not\n1:29:49 we keep looping until we hit the max limit of seven. Now please note we don't have to pass any inputs the actual graph\n1:29:57 should automatically guess by itself. So there should be no human in the loop human intervention at all. So each time\n1:30:03 a number is guessed the hint node aka this node should say either higher or\n1:30:08 lower and the graph should account for this information and guess the next guess according accordingly. So for\n1:30:15 example the input should be something like the player name student. The guess should just be an empty list cuz we're\n1:30:20 initializing the list. Attempts should be set to zero and the lower bound and upper bound should be 1 to 20. Now the\n1:30:27 reason I've also passed these as inputs is because uh if you wanted to expand\n1:30:32 this to maybe 1 to 50 numbers or whatever you can. It's quite easy to do that. So just as a hint uh it will need\n1:30:40 to adjust it its bounds after every guess based on the hint provided by the hint though. So once you've completed\n1:30:47 this exercise you would have fully reinforced uh your understanding about loops in langraph. So once you've\n1:30:54 completed this, cross reference it. Cross reference the answers on GitHub. I will see you in the next section where\n1:31:00 we finally begin AI agents. See you there. Okay people. So welcome back to\n1:31:08 this brand new section where we actually start learning about AI agents. Now we\n1:31:13 finally are upgrading our ability in Langro. I even upgraded my clothing sense. Not really. But this is exciting\n1:31:21 times cuz we actually finally build AI agents. So, we're going to build a lot of AI agents in this section. And\n1:31:28 starting off with the first agent. Well, technically it's not really an agent, but I just named it that because it\n1:31:34 sounds cool. But um technically it's not though. But let's see what we're going\n1:31:40 to actually learn in this section in this subsection. So, we're going to build a simple bot. That's it. And these\n1:31:46 are the objectives. So we're going to define a state variable uh state structure which we're going to have a\n1:31:52 list of human message objects and I briefly uh me uh mentioned what a human\n1:31:58 message was uh a long time ago in the course. Uh what it is it's well it's in the name it's a message prompt which is\n1:32:05 given by the human aka us to the AI. Uh we're going to initialize the GPD40\n1:32:12 model for this uh using lang chain's chat open AAI uh uh library. Uh we're\n1:32:17 going to send and handle different types of messages. We're going to build and compile the graph of the agent. But the main goal really is how we can integrate\n1:32:25 LLMs into our graphs. So what is this sort of graph we actually going to end\n1:32:31 up building? Now it's very very simple. It's going to look like this. And yes, this looks exactly like the graph we\n1:32:38 made in the uh first ever graph we actually ever made. But um the functionality will obviously be\n1:32:44 different cuz now we're actually integrating LM. So exciting stuff people. Uh okay, I will see you at the\n1:32:50 code then. All right, coding time. So now we first code our well we code up our very\n1:32:58 first AI agent aka the simple what and um I've already imported all the\n1:33:03 necessary libraries we'll need uh to not waste time. So while you're uh coding these up as well and copying these I'll\n1:33:10 also briefly explain what these are so we're at the same level. Okay, so we've already imported type dictionary and\n1:33:17 list many times before but um these two we haven't sorry these two the lang\n1:33:23 chain codon messages import human message so I briefly mentioned this in the intro of this section of the\n1:33:30 subsection what a human message is right and this is the library we get it from and similarly we're going to be using\n1:33:37 openai's lms so that's why we're going to use chat openai from the lang chain open aai uh library uh the\n1:33:44 langraph.graph. Uh these we were familiar with and this is the env. Now\n1:33:50 just a few points. You could have been saying okay wait hold on I thought we\n1:33:55 were about to do a langraph stuff. Why is the lang chain stuff here? Now you must know that langraph is built on top\n1:34:01 of lang chain and lang chain already has the sophisticated libraries right so why\n1:34:07 not actually use them that's how langraph is designed it's designed to use the robust sophisticated libraries\n1:34:14 which lang chain offers right so no I'm not a trader we're still doing langraph stuff but we're also using leveraging\n1:34:21 lang chain strengths as well okay and um now this env file now it's okay if you\n1:34:27 haven't ever um encountered av file before. Essentially, it's just a file used to store secret stuff like API keys\n1:34:34 or configuration values. So, it's really there for security purposes. Now, I have\n1:34:40 my own um file stored in my folder structure uh\n1:34:45 so that you don't see my API key uh because if you do then I would go bankrupt. So, that's why. Now, you might\n1:34:53 also be wondering why do we need an API key here? We need the API key because\n1:34:58 we're doing calls to an external LLM. If we were using our own LLM like through\n1:35:05 OAMA, then we would um not have an API key, right? We would just use like the\n1:35:10 Olama library integration with lang chain. So because we're using charges,\n1:35:16 we need an API to communicate with the LLM in their cloud servers. Cool. So how\n1:35:21 do we actually load this? So to load our um API, we just use a simple Python uh\n1:35:28 code load. Env. All right. So now that we're at the same level, let's actually code up our AI agent. Cool. So let's\n1:35:36 define the state like we always do. So this time class agent state type\n1:35:42 dictionary. Perfect. Okay. Now what are the attributes we need in this section\n1:35:48 uh in this uh state? Well really just one the messages part right so messages but what form will it be well it will be\n1:35:55 in the form of a a list of human messages right so we'll have list human\n1:36:01 message why because we when we invoke the graph we're inputting human messages\n1:36:07 right so to tell the large language model that this is a human message I i.e\n1:36:12 Uh this is a message from me the user aka human right. Um we need to actually\n1:36:18 mention human message that it's a human message type. Cool. Okay. So now we\n1:36:24 actually initial initialize the large language model. So we just write lm is equal to chat openai. And now we specify\n1:36:32 what model we want. Now I'm going for GPD4er. Now yes there's also chat uh\n1:36:39 anthropic. I think there's chat oama. Um there's a lot of like in-built um\n1:36:45 libraries which lang chain offers which is great. Personally I've used chat openai a lot. I've also used chat\n1:36:52 anthropic a lot as well. Uh personally I like chat openai cuz it's just really simple to use. I've also used tried well\n1:36:59 tried to use chat oama before but really there's some difficulty in integrating\n1:37:05 it with lang. So that's why I've opted for openi. And if you're worried about financial cost, don't worry, it's\n1:37:11 extremely cheap. Uh if you want, you could also go for the GPD 40 mini model as well if that's a concern. But trust\n1:37:18 me, it's extremely cheap. Like the input tokens, output tokens is like in like\n1:37:24 tens of pennies for like a,000 tokens. So really, really cheap. Okay. So now\n1:37:29 let's actually define our node through our function. So process and we obviously define the\n1:37:36 state and then return the state like so. Perfect. Now\n1:37:42 how do we actually call the lm? Now lang chain and the langraph team really like\n1:37:48 using the word invoke. You might have noticed that to call a graph or like to make the graph run we've used invoke.\n1:37:54 Similarly to run the lm we use invoke as well. So we okay let's store the\n1:38:00 response we get in a variable. So uh lm.invoke and what do we invoke? Well,\n1:38:06 you can see from the uh hints here that it requires an input of language model input. What's that basically saying is\n1:38:13 what what what do you want the LM to do? Right? What's your question? Now what is our question? Well, that's in the\n1:38:19 messages. So we write state messages. So what will happen here is as soon as I've\n1:38:24 written state messages, let's say I have written hi or whatever uh we will pass\n1:38:30 this to the LLM through the invoke method. The LLM will then generate a response from its cloud server through\n1:38:37 our API and it'll get it will give us back the um its response and then we'll\n1:38:43 store it in the response section uh the response variable. Cool. And um let's\n1:38:48 actually print this like so and return the state like\n1:38:55 such. Okay, done. Now we obviously need to create the graph like such.\n1:39:02 Okay. So uh what is it saying? Well, it's saying that there is we've created\n1:39:08 a node process which is that which where the action is the process function. The\n1:39:14 add we've added an edge. We've added an edit from the start to the end node end point and we've compiled the graph.\n1:39:20 Okay. Um yeah. So let's now ask the for\n1:39:25 the user input. So user input is equal to input. We'll say enter\n1:39:32 something. And now we will invoke the agent cuz we need to invoke the agent of\n1:39:39 course because we're creating a graph, right? And the graph is well like agent\n1:39:44 in this case. Cool. Let's actually run this code now. So, Python\n1:39:50 agentbot. py and perfect. So, enter. Let's say\n1:39:57 hi. The AI message was hello, how can I assist you today? Now, I can reassure\n1:40:03 you I did not pre-code this or hardcode this. This is the actual LM. Let's run it uh one more time.\n1:40:10 Let's come up with a different message like who are\n1:40:15 you and it'll say I'm an AI language model created by open AAI called chat GBT. So you can this basically pretty\n1:40:22 much confirms that yes this is GBT uh in the background. Okay, but\n1:40:27 um why why just stick to one message, right? Why not uh be able to run\n1:40:33 multiple message like asking multiple messages kind of like a chatbot, right? So this is the code which does this and\n1:40:39 I'll walk you through this what's happening here as well. So uh like before we input our query and now we\n1:40:47 basically say keep iterating through and as soon as the user has said like exit\n1:40:52 or something then uh well you exit the while loop and that basically signifies that well you don't want to talk to the\n1:40:59 ailm anymore. So let's have get run this. So python agentbot\n1:41:05 py. Okay let's say hi again. Hello how are you? But now we can run it again.\n1:41:11 It's just a simple y loop. It's nothing groundbreaking. So like who made you? Okay, perfect. What is 2 + 2? 2 + 2\n1:41:20 equals 4. Okay. Uh let's say now, hi, I\n1:41:25 am Bob. Okay, now watch this carefully. I'm\n1:41:32 about to ask what did I just well or I should say what is my\n1:41:39 name? I'm sorry, but I don't have the ability to know your name or any personal\n1:41:45 information about you. Why is that? Why didn't it know what my name\n1:41:52 is? Well, even though I clearly specified it. So, let's quickly\n1:41:57 exit. Okay, now this is important. Nowhere in the code have we actually\n1:42:02 created some sort of memory. That's why I called this subsection simple bot. And that's why I\n1:42:09 kept on saying AI agent because it's not even an agent yet. Uh it's just a simple\n1:42:14 like the most basic LLM wrapper you can possibly have. But at least now you know\n1:42:20 how to actually integrate um LLMs in your graphs, right? And it's\n1:42:26 pretty straightforward. You just you um you just uh embed them within your functions and then your functions\n1:42:33 obviously act as the actions in your notes. And that's it. It's quite an easy piece of code. Like it's only what 29\n1:42:40 lines or 25 lines give or take. Uh but yeah, pretty simple. Um I don't think\n1:42:46 there'll be any exercise for this cuz well there really isn't much to do with this. So I will see you in the\n1:42:53 introduction for the second AI agent we're going to build. Okay. So I'll see you\n1:42:58 there. Cool. Cool. Cool. Okay. So now we're going to build our second AI system. And we're going to try to fix\n1:43:05 the problems we faced in the last uh AI system we built. And what was the\n1:43:11 problem? Well, the problem was it doesn't remember what we in what we had said before, right? Why? Cuz we were\n1:43:18 calling separate API calls. So now we're going to try to create a chatbot with some sort of memory. That's why I\n1:43:24 included the brain emoji here. So let me walk through the objectives for this uh subsection. So, we're going to use\n1:43:30 different message types in particular in particular the human message and the AI message. We're going to maintain a full\n1:43:37 conversation history using both of these message types. We're going to particularly use the GPD4 model again\n1:43:44 using the lang chains uh chat open AI library and overall we're going to\n1:43:49 create a sophisticated conversation loop. So, what is the main goal goal of this um subsection? It's really to\n1:43:56 create a form of memory for our agent. So if you're ready, let's go to the\n1:44:02 code. All right, awesome people. So let's begin coding our simple chatbot\n1:44:07 then. Okay, so like last time, I've already imported all of the uh necessary\n1:44:12 libraries and it's largely this exact same except now I've added two more uh\n1:44:17 stuff. So the first is the AI message and I explained this in the introduction of this subsection why we need the AI\n1:44:25 message. And I've also imported the union type annotation. Now the union\n1:44:30 type annotation is something we covered in the first chapter. So if you if this is the first time you are looking at it\n1:44:35 or hearing about it, I would recommend you going to the first chapter really understanding and watching the first two\n1:44:41 chapters. They're quite short to be honest and then coming back. Okay. Now\n1:44:47 that being said, let's actually begin the uh coding then. Okay. So like always, we define the state. So class\n1:44:55 agent state uh typed dictionary. Perfect. Now last\n1:45:00 time what did we define this as? Again we're only going to have messages again but uh last time we had list human\n1:45:08 message. Okay so that was what we had defined as our agent state\n1:45:16 previously. Now this time we also want to include the AI message as well. We're building a more sophisticated chatbot.\n1:45:23 So how do we do that? Well, one way or the naive way is to really have it as\n1:45:30 messages AI list AI message or something like\n1:45:35 that. Something like that. And don't get me wrong, this is still a valid approach. You can still build your graph\n1:45:41 and everything like that, but um I think it's a bit longer. So let me tell you\n1:45:47 another way which would actually be better. So remove this. Instead, let's\n1:45:53 use the type annotation union like this. So, union like so. And let's include AI\n1:46:02 message. Now, what has this done? Essentially, let me first tell you about a bit about human message and AI\n1:46:09 message. Human message and AI messages and like all of these like different structures are actually data types in\n1:46:14 Langraph and Langchain. That's what the developers of these libraries have got them to be. And um when I write union\n1:46:23 human message AI message then that basically allows me to store uh either\n1:46:29 human messages or or AI messages in this uh key in the state the messages. So\n1:46:35 that's what that literally means in a nutshell. Now, one important thing which I want to mention is this. All of these\n1:46:42 AI agentic libraries like Langchain, Langraph, Crew AI, Autogen, they're all\n1:46:48 great, but um you really can make your own AI agentic system by writing just\n1:46:55 Python functions. You don't even need to use a library. Now that being said, I\n1:47:01 would still recommend using these libraries, especially Langraph because Langraph, well, because it's a personal\n1:47:07 favorite, no bias at all, but um it's Langraph really allows you to control\n1:47:14 much more than other libraries would. Obviously, not as much control as if you\n1:47:19 were writing the Python functions yourself and everything, but I think it's a good balance of how much control you have and how much uh unnecessary\n1:47:26 jargon you need to write. Because think about it, think about how much of um this unnecessary code which you would\n1:47:32 have had to write else otherwise uh langraph and lang chain support. So that's why I highly recommend using\n1:47:39 these libraries and everything. So again human message and AI message are data types inbuilt data types within uh lang\n1:47:46 lang graph and lang chain. Cool. Okay. Now let's again initialize the large\n1:47:52 language model as we did last time. And again we're only we're using GP4. Okay, now we're going to create our\n1:47:58 node. Again, it's going to be the exact same graph structure, by the way. So,\n1:48:03 state agent state, but obviously the actions we perform will be slightly\n1:48:08 different. Now, um let's write a dock string. This node will\n1:48:15 um this node will uh do solve the request you input\n1:48:23 something. Dog strings aren't really needed for this AI agent or this subsection because we're not going to\n1:48:29 use them. But um again, good habit. Okay, cool. Let's invoke\n1:48:36 this. So what have I done here? This is exactly the same code which we did in the previous subsection. The l we invoke\n1:48:42 the lm uh with the state messages. And what are the state messages? Well, it's could be either human message or an AI\n1:48:49 message. It's a list of those. Awesome. So now we write this piece of\n1:48:56 code. Okay. State messages.appen AI message content equal to\n1:49:02 response.content. What on earth is happening there? Okay. Let's break this down. Response. Well, that's just\n1:49:08 extracting only the content part of the response aka the response being the answer or the result after we make the\n1:49:15 uh API call from the large language model. And it only extracts the content. So it only extracts like the important\n1:49:21 stuff, right? It removes all the unnecessary jargon which comes with it like the amount of tokens you use and\n1:49:26 all that. It removes that and that's uh gets stored in that gets converted to to\n1:49:32 an AI message and that's appended to our state messages um in the state. Simple.\n1:49:39 Okay. Uh now obviously to make it look pretty in the terminal we're going to\n1:49:45 print this and then we're going to return the state. That's it. That's how simple it was.\n1:49:52 Okay, so now we're going to create this exact same graph. And that's why I've just copied and pasted it because it's a\n1:49:58 time waste of me rewriting the code in front of you again and again. So we can just reuse the same code because it's\n1:50:04 the exact same graph uh graph structure as the previous subsection. Cool. Okay,\n1:50:09 now we're going to now here's where it actually starts working differently.\n1:50:14 See, last time we didn't have this the conversation history. really this is\n1:50:20 what's going to be our memory in in um this uh setup. Okay, so we have now in\n1:50:26 initialized conversation history. Now again we're going to ask the user what they want, right? What's their request?\n1:50:35 So now we use this Y loop and this Y loop was the exact same loop we had in\n1:50:40 the previous subsection as well. uh it only exits unless if the user has uh\n1:50:46 inputed well exit obviously but now look at this the conversation history is\n1:50:52 appended with the human message and the human message is obviously the user input the reason I've kept on writing\n1:50:59 content is because well that's the parameter in human message as you can see here okay cool uh and we've invoked the\n1:51:08 agent what is the agent well the agent is the compiled version of the graph the compiled graph uh with uh the entire\n1:51:15 conversation history. Now this is important. The entire conversation\n1:51:20 history is sent, not just the current human message. So uh this will make more\n1:51:26 sense. Don't worry, I'm um trying my best to explain it right now, but obviously it will make much much more\n1:51:33 sense as soon as I start running it. Okay? So bear with me if you didn't fully understand that. Don't worry.\n1:51:38 Let's remove that for now. Uh, and then we replace the conversation history completely like wipe it with the\n1:51:46 result messages. Why? Don't worry, it's going to make sense as soon as I run it.\n1:51:51 And I think yeah, we should be able to run this now. So, let's write python memory agent.py, which is\n1:51:59 the name of the file. Cool. Okay, let me just quickly write a hi just to see if the API is\n1:52:04 working. It is perfect. Okay. Hello. How can I assist you today? Uh, now I'll say\n1:52:10 like, \"Hi, my name is\n1:52:17 Steve.\" Hi Steve, it's great to meet you. How can I help you today? Okay, now\n1:52:22 remember from last time. Last time if I asked it, hey, who am I? It didn't know.\n1:52:27 Do you think it will know now? Think about\n1:52:34 it. It does. you are Steve or at least that's the name you've chosen to share with me. Uh and the rest is yes\n1:52:42 whatever. So it does know about what I have said but just looking at this code\n1:52:49 I guess you can try to like pick out okay how does it work and everything like why everything works like that but\n1:52:57 um I think we can add print statements and everything. So let's try to add print statements now and see well how\n1:53:05 this is actually working. So let's exit the program. Okay. Uh let's add a print statement\n1:53:13 here. Let me include this. Cool. So what is this saying? So this print statement\n1:53:20 actually kind think of it like a snapshot of what the current state is. So as soon as it goes into a process\n1:53:27 note as just before it's about to finish by returning the state, we also print the current state as well. And this will\n1:53:34 literally just output whatever is stored in the messages attribute within our state. Okay. So let's clear. There we\n1:53:43 go. Let's run this again. So hi, nice to meet you.\n1:53:49 Something like that. Now take a look at the current state. See it outputed hello, nice to\n1:53:56 meet you. How can I see you today? Why did it output that? Well, because in our process\n1:54:01 function it we've asked it we formatted it in a way so it says hey AI which is\n1:54:07 this part and the response or content is this part. Okay. Now this response or\n1:54:13 content is also what was stored remember how I said it's stored in the um in a\n1:54:18 nice manner and was appended to our state messages. Now was it appended to the state messages? Yes. How do you know\n1:54:25 that? Because look at the human message. The human message was what I wrote which was hi nice to meet you. Uh forget the\n1:54:31 additional keyword arguments and response metadata cuz I didn't provide any. Uh you don't need to worry about that. The main part is this part the\n1:54:37 content. And then look at the AI message part. Uh it's the content is equals to\n1:54:42 hello nice to meet you. How can I see you today? Notice how it's the exact same thing as it was\n1:54:50 here. Okay. Now, now we're going to go one step ahead and I'm going to ask it\n1:54:56 to say my name is Steve again. Now, think\n1:55:03 about how will this current state change? Pause the video and try to think\n1:55:08 about this like that. Okay. So, now the second\n1:55:16 uh message I sent was my name is Steve. Its response for the second message was hi Steve. How can I help you today? Now\n1:55:24 look at the current state. It still begins with hi, nice to meet you, which was the first ever message I inputed\n1:55:30 into this conversation and then its respective AI message. And then that gets uh appended. Why appended? Well,\n1:55:37 because we had appended the AI message and appended the human message. So that's why. Okay. And you\n1:55:45 can see the human message is my name is Steve which is the most recent uh message which I put and then the AI\n1:55:51 message which is hi Steve how can I help you today? Perfect. And we can just keep\n1:55:56 going and going and going. But uh for now I'll exit. Now here's the thing. This works\n1:56:03 well relatively well, right? We've got it like as a chatbot which is what we\n1:56:08 wanted. it has some recollection of memory or or like of what we what we are who we are and everything. But there's\n1:56:15 two big problems here. Let's start with the first uh massive problem which is\n1:56:21 this. You know how I've exited the program right now. Yeah. Okay. I'm going\n1:56:28 to run the exact same program again. Now I told it that my name is\n1:56:34 Steve. What is my name?\n1:56:40 and it says uh I'm sorry I don't have access to\n1:56:45 your personal data. Okay. And look at the current state completely wiped out. Again, that's pretty self-explanatory as\n1:56:51 to why you exited the program and that's why obviously all the var the data was stored in the variables, right? The\n1:56:57 state was stored in the variables completely got wiped away. So what is the solution? Think about it.\n1:57:06 Well, obviously one potential solution would be to store it in a database, like a large database, right? Or a vector\n1:57:12 database if you're trying to do some ragged applications. For now, I'm just going to store it in a very simple text\n1:57:18 file. Why? Cuz it's really easy. And I've got the code as well. And usually, honestly, I just store it in a text file\n1:57:24 when I'm prototyping. Now, yes, obviously, storing it in a vector database or a database is much more robust and sophisticated, and that is\n1:57:31 what you should do. But when you're prototyping and you want to really see uh try to build it quickly and fast, uh\n1:57:38 I just tend to use a text file. It still works uh still works great and everything. So what is the code for the\n1:57:44 text file? Uh it's here.\n1:57:50 Okay. So what is this code saying? Well, essentially it's saying create me a text\n1:57:55 file called logging as a as a text file you see in write mode and a file. Write\n1:58:00 your conversation log. This is just to like make it look better and more aesthetic. But this is the main part of the code which um you should actually\n1:58:07 try and understand for every single message in the conversation history. Okay. Now note the conversation history\n1:58:14 was this variable which we had like initialized the conversation history uh stores the AI messages and the human\n1:58:20 messages. So that's where all of the um the information outside the graph\n1:58:26 actually is. Right? the state is locked in within the graph now and uh the\n1:58:33 conversation history is just another I guess you can say a duplicate version of the state right because we've you we've\n1:58:40 appended the exact same human messages and AI messages and kept on updating it\n1:58:45 through this line cool so what it says is that for every single message in the\n1:58:51 conversation history by the way a conversation is the duration between my first message and the last message I\n1:58:58 sent that entire thing is a conversation. A conversation isn't just a single API call. It's the entire\n1:59:04 length. Okay? So, just to be mindful of that. So, uh it first checks if it's a\n1:59:10 human message, it writes that as you and then extracts that content and if it's the AI message, it uh puts it under the\n1:59:16 AI stuff. So, let's run this again. So, let's exit this. Clear this. Okay.\n1:59:25 Who? Okay, let's say hi, I am Steve. Again, I'm using Steve because a\n1:59:31 Minecraft movie just came out, so that's why. Okay, now I'm going to intentionally make a spelling mistake\n1:59:37 here. Good morning. It should obviously morning should have been spelled, right? But I'm doing that for a reason. It gets\n1:59:44 no problem. Let's say tell me a joke. Just another random thing. Sure. Why\n1:59:49 don't skeletons fight each other? They don't have the guts. Um, really rubbish. My point is it\n1:59:57 works. Now I'll exit the program. And now it says conversation saved to login.xt. Now look at\n2:00:04 this. Remove that. Let me remove that. Okay, perfect. So this is the conversation log. The first message I\n2:00:10 ever sent was, \"Hi, I'm Steve.\" There, it's response. Now, good morning. Now, why did I spell it like wrong? Why did I\n2:00:17 do that? Because I wanted to show you that this is the actual human message, my message being stored unaltered. So\n2:00:25 whatever I pass in the state as a human message that stays there. So it's unaltered. The AI message cannot or or\n2:00:34 anything can really change the previous human messages at all. Right? So that's\n2:00:39 why. And you can see tell me a joke. Sure. It's it's a rubbish joke is after that. And that's the end of the login.xt\n2:00:46 file. So that's a really fast efficient way, not the most robust way of course,\n2:00:52 but it is a fast efficient way to be able to store your data outside um the\n2:00:57 application if it stops. Perfect. Now, what was the second problem that I was mentioning? It's\n2:01:03 this. Look at how I initially I say, \"Hi, I'm Steve.\" I don't know why I\n2:01:09 printed twice there. Weird, but whatever. Look at the current state length.\n2:01:15 Okay. Then I pass in another message, it becomes longer. I pass in another\n2:01:20 message, uh it gets longer. It keeps getting longer and longer and\n2:01:25 longer. That's a problem because think about it, you will use these uh library\n2:01:31 uh you'll use these like large language models whether it's for your own AI agentic startup or your own mini Javas\n2:01:36 or your own projects or whatever it is. You would obviously want to minimize cost, right? But using so many tokens uh\n2:01:45 using so many tokens like input tokens especially will really eat away uh your\n2:01:51 uh the amount of money you will uh spend like it will drastically increase it and\n2:01:57 that's a huge problem right we want to try to be conservative a bit about our money and our financial our finances so\n2:02:04 what is one what is a way to solve this think about\n2:02:10 that Well, right off the bat, I can give you an easy solution to implement which is within the code, write it, write some\n2:02:17 code where if the number of human messages exceeds five or something like\n2:02:23 that, then you remove the first human message in your uh history. Why remove\n2:02:29 the first and not the latest? Well, because the latest is most likely to be more relevant, right? The first message\n2:02:35 could is most likely to be the one where um the one which is well not needed or\n2:02:42 it could have been like it can it has more of a chance to be like a bit more less of an impact to have been removed.\n2:02:51 So why did I pick five? Well, five is just a random number I thought of. You could do 10, 15, 20, 25, three,\n2:02:58 whatever. But that's a really easy solution to do. Okay, so we learned\n2:03:04 quite a lot there. We learned how to integrate human message and AI message within a thing. And now we've created a\n2:03:11 somewhat of a sophisticated chatbot, right? It has a memory. It still talks to us. We if we define uh if we write\n2:03:19 who we are, it remembers that and everything and it works great. Obviously, it has its flaws, but for now, it's pretty good. Okay, so now\n2:03:26 we're going to build our third AI agent. And this is going to be a special type of an AI agent.\n2:03:32 The technical term for this type of agent is called a react agent and react\n2:03:37 stands for reasoning and acting. So this is a quite a common type of AI agent\n2:03:43 which you will build. So how does it look like? Well, it looks something like this. So it's quite simple. There's a\n2:03:51 start point and then it's an end point obviously. Then you have your agent and then we use a loop where we attach it to\n2:03:58 tools. Now, this could be one tool, two tools, a lot of tools. And it's the agent's job or the LLM in the background\n2:04:06 to be able to decide which tool to select. But not only that, it's all it's also its job to be able to decide when\n2:04:13 there's no more tool calling left to do. And when that happens, it goes to the end part. So that's the general gist of\n2:04:20 what a React agent is. It's a very very common and famous type of agent to make in Langraph. And that's exactly what\n2:04:26 we're going to be building in this subsection. So what are the objectives? So to build a react agent, the\n2:04:32 objectives are learn how to really create tools in langraph. We're going to be creating a react graph. Of course,\n2:04:39 we're going to be working with different types of messages such as tool messages. See, last subsection we've we covered AI\n2:04:46 messages, human messages, but now we're going to look at a lot more types of messages. for example, tool messages,\n2:04:52 system messages, base messages, and we're obviously going to test our robustness um of our graph. So, the main\n2:04:58 goal is to create a robust React agent. So, if you're excited, I'll see you at\n2:05:04 the code. Okay, people. So, now we're going to code up the React agent. And just a\n2:05:11 heads up, this is going to be quite a long subsection. So, get ready. You can see it's going to be long because of how\n2:05:17 many imports I've done. But because I've done so many new imports, I actually want to take some time off and really\n2:05:22 explain each line so that we're all on the same page. Okay, let's go. So the first line is from typing import\n2:05:29 annotated sequence and type dictionary. Now we obviously know what a type dictionary is, but we haven't come\n2:05:35 across annotated or sequence yet. So these are also type annotations. And I'll start off by explaining what an\n2:05:41 annotated is. So annotated is a type annotation which provides additional\n2:05:47 context to your uh variable or your key without actually affecting the type\n2:05:52 itself, the data type itself. Now what exactly does that mean? Well, I'll give\n2:05:57 you an example. Let's say I am trying to create a type dictionary where there is\n2:06:02 an email key in it. Okay? Now, obviously an email is string. So if I was to create a type dictionary, I would have\n2:06:09 written email colon string, right? Sl. That's how we've been doing it. But here's the thing with certain keys like\n2:06:16 email, they have to be a certain uh format. But like for example, it has to\n2:06:22 be like abcgmail.com for example. But if I pass in\n2:06:28 abcd-gmail.com or something like that, that's not a valid email format anymore, but it's still a string technically. So\n2:06:34 it would pass through. So how do we resolve that? Well, that's where annotated comes in. And I'll give you an\n2:06:40 example here. Let's say email is equal to annotated. I'm not going to create the whole type dictionary to save time.\n2:06:46 But for uh the example itself, you first pass in what data type you want it to\n2:06:51 be. So we want email to be a string, right? That's not changing. But here in quotation marks, I provide some more\n2:06:56 additional information, additional context. And this is basically adding onto the metadata of this key or\n2:07:04 variable. For example, uh let's say this has to be\n2:07:09 a valid email format. Now, obviously, I should do it\n2:07:15 in more detail, but um that's how uh for now, that's fine. So, how how can I\n2:07:22 actually see the metadata? So, if I want to, I would write print email metadata\n2:07:29 uh like that. And then I would press run. And here we go. You can see this\n2:07:35 has to be a valid email format. That's the exact same thing which is which we wrote here. So that's annotated done.\n2:07:42 But what about sequence? What does sequence mean? Well, sequence is also a type annotation. And the way I've\n2:07:48 described it is here. It basically automatically handles the state updates for sequences such as by adding new\n2:07:54 messages to a chat history. Now what does that mean? Well, it's really just\n2:08:00 there to avoid any list manipulation to the graph nodes. Obviously, like when we're using graphs and nodes and all all\n2:08:07 of that stuff and updating the states, there's a lot of uh list manipulations which we'll have to do. Sequence really\n2:08:12 handles a lot of that. So, that's really what it's there for. You don't really need to uh worry about it too much.\n2:08:18 Okay. Now, if we continue, we have env uh from import loadenv. From last time,\n2:08:26 we know that this is just to store our API keys and I've done that here. That will load the API keys. But you'll see\n2:08:32 now these three uh imports. We're importing some new message types here.\n2:08:37 So we're importing base message, tool message, and system message. I'll start off with the tool message. So it's\n2:08:43 essentially a type of message where where the data is passed back to the LM\n2:08:48 after the tool has been called and like the information which is passed is like the content itself, the tool call ID. Uh\n2:08:56 that's what tool messages. It's pretty self-explanatory. Now for a system message, it's the it's a message for\n2:09:02 providing instructions to the LLM. So like for example, if you've used uh LLM\n2:09:07 APIs before, you might have written you are a helpful assistant. That's exactly what a system message is. And don't\n2:09:13 worry, we're going to code this up as well. So you'll actually see what they are. Now what's a base message? So in\n2:09:19 the comments, you can see that I've written the foundational class for all message types in Langraph. Now here's\n2:09:25 how this works. Think about the class hierarchy. So you know how you have a parent class and then you have child\n2:09:31 classes as well. Well the base message would be the parent class and these uh\n2:09:37 AI message, human message, tool message, system message and all these other types of message will be like the child\n2:09:42 classes and they will inherit all the properties of the base message cuz that's the parent one. I guess you can\n2:09:48 say the uh all father or something but the AI message, human message and all\n2:09:53 these child uh classes obviously they'll have their own properties, right? For example, the tool message has its own\n2:09:58 content and tool call ID and all that stuff. So that's what the base message is. It's really the foundational class\n2:10:04 for all the message types in Langraph. Cool. Okay. So now if we\n2:10:10 continue, you can see we've imported chat, openAI. Uh we've done state graph and M. These we've come across. We know\n2:10:16 what they are. And we've imported tool and tool nodes which we cover in the second chapter or second section of this\n2:10:23 course. uh these are different elements which we're going to be uh using in langraph. Now what about this line from\n2:10:29 langraph dossage import add messages. Now what does that mean? So this is a\n2:10:34 little bit um different. This add messages is a reducer function. Now if\n2:10:41 this is the first time you're hearing that don't panic. It's not that hard. So let's let me copy this one second. Okay.\n2:10:49 So a reducer function is essentially just a rule that controls how updates from nodes are combined with the\n2:10:56 existing state. In simpler words, it really just tells us how to merge new data into the current state. Now here's\n2:11:03 the thing. If we didn't have some sort of a reducer function, uh updates would have just replaced the existing value or\n2:11:09 state entirely. And I'll give you an example for this.\n2:11:15 So let's say I had a state where it was just high. I had one attribute messages\n2:11:21 and high. Now obviously I should have created the type dictionary and everything and formalize it but just for\n2:11:26 simpler um for times saving purposes I've done it like this. Now what if I\n2:11:32 had an update which says nice to meet you. If I didn't have a reducer function that would completely overwrite it. Now\n2:11:38 in the previous uh graphs and agents we've made we've appended it but now that we're using so many different\n2:11:45 messages and calls and tool calling and what whatever we can't really always append\n2:11:50 everything like it will get far too complicated. So that's why we need to leverage reducer function. So if we\n2:11:56 didn't use a reducer function it would just overwrite it completely. But if we did like hi nice to meet you it would\n2:12:03 append it. That's the key. So in a nutshell, the reducer function really\n2:12:08 just aggregates the uh data in the state. This reducer function uh and the reducer function which I'm talking about\n2:12:13 is add messages. So once again, add messages is a reducer function that will\n2:12:19 really just allow us to append everything into the state without any overring happening cuz so we want to\n2:12:26 preserve the state. Okay, cool. So now let's actually code this uh react agent.\n2:12:32 Okay. All right. Okay. Okay, I've cleared the screen now and let's actually begin like we how we always\n2:12:38 begin with the uh creation of our state of our agent. So, type dictionary like\n2:12:44 such. Okay. And now we we'll only have one key in this uh in this example which\n2:12:52 is just messages. And now let's use the new type annotations we've learned. So,\n2:12:58 sequence base message and reducer function add messages. So again this\n2:13:05 piece of code is saying to preserve the state by actually appending it rather\n2:13:10 than overwriting. That's what this reducer function does. Okay. All right.\n2:13:15 Okay. Oh, and the sequence of base messages is the data type and this\n2:13:20 provides the metadata. That's why we have the annotated keyword here. That's really it. Okay. Uh now let's create our\n2:13:28 first ever tool. Now how do we do this? Some of you who have a um who have come\n2:13:33 from lang chain might know how to do this already. We use a decorator and we\n2:13:39 define like this. Now this decorator basically tells Python that this function is quite is special. It does\n2:13:45 something and well it is special because it's a tool which we're going to use. So let's define our tool as def. Let's\n2:13:52 create a simple addition tool. Okay. So we'll say a integer b integer.\n2:13:59 It's basically going to add two numbers. And this is where doc strings actually come now. And I'll show you how important they are. For now, let's say\n2:14:06 uh this is an addition function that adds two numbers together.\n2:14:15 Okay. All right. And we just return a plus b. Simple. Now, how can we actually\n2:14:23 infuse these tools to our large language model? Well, first let's create a list.\n2:14:30 Add like such. Now, yes, at this current moment, I only have one tool, but in a\n2:14:36 few moments, we'll have multiple tools. That's why I'm adding this uh list for now. And let's actually create our\n2:14:41 model. So, model is equal to chat openai. Model is equal to\n2:14:48 GPT40. Again, I'm using GPD40 because I've never had a problem with it to be honest. So how can we tell our GPD40\n2:14:56 large language model that these are the tools you can use? Well, we can use this inbuilt Python um inbuilt function\n2:15:03 called bind tools. Bind tools like that. And we pass in the list of tools we\n2:15:08 have. So that's tools. Pretty simple, right? Okay. So now large language model\n2:15:14 will have access to all of our tools. Okay. So now we need to create a\n2:15:19 node which actually acts as the agent within our graph. So how do we do that?\n2:15:24 Let me create just a simple function like def model call. We pass in the state agent state. Again it needs to\n2:15:31 return the agent state. Okay. Now I'm going to quickly copy this\n2:15:37 piece of code. Give me a\n2:15:42 second. Okay. So what is this code doing? uh you can see that we're invoking the\n2:15:49 model aka running the model and this is the system message which we are asking.\n2:15:54 So we're explicitly saying the large language model that you are my a system please answer my query to the best of\n2:16:01 your ability. So that's what the large language model's task is to do. Now if\n2:16:07 we want to get technical here, you could have written it in a slightly different way and that way is through\n2:16:15 this. So remove this. We could have said system\n2:16:22 prompt. Okay. So what's going on here? Remember how I said system message is also something which we imported. Uh so\n2:16:29 the system message like I said is this line of uh is this line. You are my AS system. Please answer my query to the\n2:16:35 best of your ability. Now, either way would have worked if we if I had just straight up\n2:16:40 passed this string into here. That would have worked as well. Personally, I think this way is better. Even though they\n2:16:46 achieve the exact same thing, I think this way is better cuz it's more readable. Okay? And you're only adding\n2:16:51 just one more import. Okay? So, I would prefer you to I would really recommend\n2:16:56 you doing like uh like this so even the large language model knows that this is a system message. Okay, cool. And this\n2:17:04 is uh just another way of writing like the updated state. You know how we've been writing state uh brackets messages\n2:17:12 is equal to something something something. Well, this is a more compact way of updating the state as well. So\n2:17:17 return messages response. So we update the messages with the response. No plus\n2:17:22 equal to this this this or adding something we just we can simply just write it with the updated state. Why?\n2:17:29 because the add messages aka the reducer function handles the appending uh for us. It doesn't overwrite it. Now, if I\n2:17:37 ran this code and I built the graph and everything, would it work? No. Why it wouldn't work? Because\n2:17:45 think about it, the response when we've invoked the model and we store it in the response when we actually invoked it, we\n2:17:52 didn't actually pass in the query. How do we pass in the query? Think about it.\n2:17:58 All I passed is my system message. Where does the query go? So to be able to add\n2:18:03 the query, I actually have to add like this. So state messages. The query it\n2:18:10 will be in the form of a human message. And the human message will be stored in the messages attribute, right? And now\n2:18:16 that we've passed that into our model as well and we can invoke it. And now this\n2:18:21 should work. Okay. Okay. Okay, so now we define the\n2:18:28 conditional edge. Now why do we need the conditional edge here? I'll put the picture of the react agent. Again here\n2:18:34 you can see that the looping part even like in the last one in the graph when we made the loops for the first time you\n2:18:40 saw that was it was a conditional edge which we had to use and now that's actually going to come in play here.\n2:18:46 That's why I took so time to build those graphs because now the concept is coming. So how do we define the\n2:18:53 conditional edge def should\n2:18:59 continue. Okay. So again like always we pass in the state and let's do it like\n2:19:09 this like such else\n2:19:14 return continue. Okay. So as you know as you um might have guessed end and\n2:19:21 continue will be edges which I'll define later in the graph. But what is going on here? Well essentially when I'll pass in\n2:19:28 the query uh when we've invoked the actual model you will know that we'll create a list of tools right so what\n2:19:36 we're going to be doing is we're going to be uh getting the last message and we're going to see if there's any more\n2:19:42 tools needed to be ran. If there are then we'll go into the continue edge aka\n2:19:48 we'll go to the tool node and we'll select the tool and we'll do all this uh actions and then come back. If there's\n2:19:54 no more tool calling left we will just end and we'll just exit the uh graph and\n2:19:59 that'll be the case. You'll get uh uh you'll understand more what I what I mean when we've actually test we're\n2:20:05 testing and running the graph. Okay. Now let's just define the graph. So like\n2:20:11 always we create the graph we initialize the graph through the state graph and let's call the node R agent. So the\n2:20:17 action will be the model call aka the underlying function will be this. Okay. Now we create something called a\n2:20:25 tool node which is also what we covered in the previous uh in the second section\n2:20:30 or second chapter in this course. The tool node essentially is just a singular\n2:20:35 node which contains all of the different tools. So we only have one tool. If you see what this variable is tools, we only\n2:20:41 have one tool which is add. Don't worry, we'll add some more tools like subtracts and multiply in a bit. But I just want\n2:20:47 to uh like really solidify your concept of how we can add these tools and how the graph will work. Okay. Now we\n2:20:55 obviously set our entry point and point it to the R agent. Now let's add our conditional\n2:21:01 edge. So remember remember how I said there's two edges, continue and end. again continue and end and if it goes to\n2:21:09 the end we end it. If it goes to tools then we go to tool node which is tools. Okay. Okay. So yeah this is\n2:21:17 pretty straightforward still. Right now we also need to add an edge which goes back from our tool to our agent cuz\n2:21:24 that's how we're going to create a circular connection. Right? You can see that the conditional\n2:21:30 edge only provides a one-way directed edge from the from either the agent to\n2:21:36 the tool node or the agent to the endpoint. But we need another edge which will go back from the uh tool node back\n2:21:43 to the agent. And that's what this um that's what this edge does. And lastly, we need to uh obviously compile it. So\n2:21:50 we'll just say app is equal to graph dompile. Perfect. That's it. Now I've\n2:21:57 just created a a new helper function here which this isn't part of langraph.\n2:22:03 I've just written this code because it will make every like the tool calling and everything uh like output in a much\n2:22:09 better way. So you'll see what I mean in just one second. Okay. So now we\n2:22:16 actually can begin. So let's say the input is uh something like this.\n2:22:24 Let's say I want to add 3 + 4. Okay, simple. And this line of code basically\n2:22:31 streams the data. That's all it does. So, let's actually run this. Clear. And\n2:22:36 let's do it. Okay. So, remember we wrote add\n2:22:41 3+4. Wow, look at that. So, we've added 3+4. It calls the tool and it even knows\n2:22:47 what tool to pick. Add. Um, and it gives us the result. The tool message as you\n2:22:52 can see is seven and the AI message the final AI message is the sum of three and four is seven. That's it. Let's try\n2:23:00 something harder now. Let's write add 34 + 21. So if we run\n2:23:08 this you can see 55 cuz 34 + 21 is 55. And you can also see again all the tool\n2:23:14 calls and everything that's done right. I want to show you one two more things actually before we add some more tools\n2:23:20 which is this. If I remove this dock string here by commenting out for\n2:23:25 now. Let's clear and let's run that\n2:23:30 again. Error. Why? Because the function must have a dock string if description\n2:23:36 is not provided. The dock string is necessary. That's why included otherwise the graph won't work. It's remember it\n2:23:43 tells the LM what that tool is for. Okay. So now that we've have uh we've\n2:23:49 got that there, let's try this as well. Add uh 3+ 4. Again, this time I want both of\n2:23:58 them to be executed. So clear now. Do you think this will work? Let's\n2:24:05 see. Add 34 + 21. Add 3+ 4. Perfect. Brilliant. Okay. So you can see the\n2:24:11 result of adding 34 + 21 is 55. The result of adding 3+ 4 is 7. You can see how the tool was called twice this time\n2:24:18 and that's the power of the loop which we created. Remember we created the conditional edge and then we also\n2:24:24 created that directed edge back from the tool node to the agent. Let's let's try to make it even uh give more um\n2:24:31 complicated stuff. Let's say add add 12 + 12 something. So let me\n2:24:38 clear this. Clear. Let's see what happens.\n2:24:46 Wow, look at this. If I press enter, sorry, I messed up there. But you can\n2:24:53 see the results of the addition as well as 34 + 21 is 55 7 24 or and you can\n2:24:58 also see that I called the tool the sorry the AI called the tool three times.\n2:25:04 Now these tool calls is also an indication that the LLM didn't use its own like information inbuilt information\n2:25:11 which it was trained on to come up with an answer. Right? Remember an LLM doesn't know how to do maths. It just\n2:25:16 guesses the next output like through probability. But through this we were\n2:25:21 able to actually add the two numbers. So an important concept here is\n2:25:27 the LLM actually decides what should be passed as the arguments to each tool. So\n2:25:33 3 + 4 like if I said add 3 + 4 it will actually uh create it will actually uh\n2:25:39 input the numbers 3 and four and then this tool will handle the uh information return it and it will go back to the\n2:25:44 agent and then the AI agent will decide what's the answer and everything. So that's how it works. Awesome. Okay. Now\n2:25:50 let's make this even more complicated. Let's add some more tools. Let's add\n2:25:58 subtract and multiply. Okay. And the only re change we have to do is instead\n2:26:05 of this one line we just now include subtract and multiply as well. That's\n2:26:11 it. Otherwise this line this code largely stays the same. Now let's\n2:26:16 actually run this same command and see if it gets confused with the different\n2:26:21 um different tools we have it has access to. Now let's see. Okay.\n2:26:29 You can see again that 55 724. Okay, it didn't get confused. Perfect. Let's now give it a\n2:26:36 different command. Let's say something like this. One\n2:26:44 second. Add 40 + 12 and then multiply the result by 6. So now it has to make\n2:26:49 use of two different tools. Let's see if it gets that.\n2:26:55 Okay. Wow. Brilliant. So it first used the add tool and then used the multiplication tool and you can see all\n2:27:02 the queries or all the tool called and everything and the final answer is 312. So 52 * 6 yes it is 312. Okay. Wow that\n2:27:10 works like brilliantly. So now that we know that this is robust what about if I\n2:27:16 add this let's say also tell me a joke\n2:27:22 please. What do you think will happen? Do you think this will break? Let's see.\n2:27:28 If I play this and run this. Let's\n2:27:37 see. Wow. Look at this. The result of 40 adding 14 and 12\n2:27:43 is 52 multiplying that is by 6 is 312. And here's a joke for you. Why don't skeletons fight each other? They don't\n2:27:49 have the gun. I swear to God, it's always the same dead joke. But you get the point. This is so robust. It can\n2:27:55 handle even queries where it doesn't even need a tool and that ladies and gentlemen is the power of langraph. So\n2:28:01 it's it's so robust even if we don't need to use a tool it will still give us an answer and the reason it was able to\n2:28:09 do that is once all the tool calling is done it passes it to the agent the agent checks again oh I need to tell it I need\n2:28:16 to tell the user a joke as well and adds that to the final information and then ends it that's the power of\n2:28:22 lang okay so after all of that we finally now know how to create a react\n2:28:27 agent yes it was a simple react agent but the concepts the same. You can create your own external tools from now\n2:28:33 onwards and you can create your own graph. And that was the whole point of this course, right? For you to actually\n2:28:38 understand how we can uh create these um how we can use different tools and then the rest is up to you. It's up to your\n2:28:45 imagination. Okay, perfect. So now I will see you at the next subsection. All\n2:28:51 right, see you there. Okay, people. So we've made great progress so far. So\n2:28:57 well done on that. But now we make a fourth AI agent. And this time we'll do\n2:29:02 things again slightly differently. Well, this time we're going to be making a mini project together. So the project's\n2:29:10 name is going to be called Drafter. And you'll see why in a minute. So picture\n2:29:15 this. Me and you are working in a company together. And our boss comes up\n2:29:20 to us and she has a problem and some orders for us. So the problem is this.\n2:29:26 Our company is not working efficiently. We spend way too much time drafting documents and this needs to be fixed.\n2:29:33 Again, a valid problem. So, what are her orders? She says you need to create an\n2:29:38 AI agentic system that can speed up drafting documents, emails, etc. The AI\n2:29:44 agentic system should have human AI collaboration, meaning the human should be able to provide continuous feedback\n2:29:49 and the AI agent should stop when the human is happy with the draft. The system should also be fast and be\n2:29:56 able to save the drafts. Okay. So then me and you start discussing and we are\n2:30:02 going to use land graph obviously and we come up with a sketch. Now the sketch of\n2:30:08 our graph is something like this. It obviously is going to have a start and an end point and it's going to have our\n2:30:14 agent and the agent will have access to tools aka the tool node. Now this looks\n2:30:20 similar to a react agent which we covered in the last subsection. But there's a reason we don't we haven't\n2:30:26 chosen to do that. See we realize that one of the tools is the save tool. It\n2:30:31 will save the draft, right? That was one of our requirements. But obviously when we once we've saved it, the process\n2:30:37 should end, right? But if you remember from a React agent, the tools always goes back to the AI agent, not directly\n2:30:45 to the endpoint. And we don't want that anymore. So that's why as soon as the save tool is used because the save tool\n2:30:52 will be within tools right it ends. So that is the structure we have chosen to\n2:30:58 go with. So the only thing left is to actually code this graph. So let's code\n2:31:04 this together then. Okay. So let's actually code up this drafter project then. So you can\n2:31:11 see I've already done all the imports and I've loaded up my env file. Now all of these imports are imports which\n2:31:17 you've already uh encountered before. So there's no point in looking at them again. But the first thing which I'm\n2:31:23 going to do is I'm going to be defining the a global variable. Now this global variable yes it's a bit\n2:31:31 odd defining global variables and there's a reason which I've done it and this will become more apparent as I go\n2:31:37 through the code but just as a heads up the reason I've defined a global variable in this case is to actually\n2:31:44 pass in a state in tools the the correct way to do it in langraph is through\n2:31:50 something called injected state now injected state is beyond the scope of this uh course so the workound on that\n2:31:58 is to use a global variable and what will happen is our tools will uh\n2:32:04 whatever updates are made uh we'll update the global variable and then when we go on to save it uh the save tool\n2:32:12 will use the contents in this global variable and save that into a text file.\n2:32:17 So that's why this is included. Okay. So now let's define our agent state again.\n2:32:23 And the way that's done is the exact same way we did last time. Uh class\n2:32:28 agent state messages annotated sequence base message add message as the reducer function. So now we define the tools and\n2:32:37 there will be two tools for this. The first tool will be the update tool and the second tool will be the save tool.\n2:32:42 So let's start off with the uh update tool and I will obviously use the decorator and then create def\n2:32:50 update and then we need to pass in\n2:32:55 uh pass in a parameter content. Now just as a refresher whatever parameters you\n2:33:01 pass or you request who actually gets those parameters? Well, the LLM or your\n2:33:08 model in the background that's uh what will automatically pass the parameters\n2:33:13 for this model uh for this tool. So, uh in this case the content parameter will be uh that will be provided by the lm in\n2:33:21 the background. So, you don't need to worry about that. Okay. So, now we need the dock string obviously and I've just\n2:33:27 created a simple dock string which just updates the document with the provided content because that is exactly what it does.\n2:33:33 So now we define to interact with the global variable in Python, you obviously need to uh define it uh you need to code\n2:33:40 it like this and then you need to update your document content aka the global\n2:33:47 variable with your current content and then you just return again a statement\n2:33:53 to the like the large language model telling it that we have successfully updated it. So I've written document has\n2:33:58 been updated successfully. The current content is this which is the content which we store in the thing. Okay. So\n2:34:07 now we define our second tool which is the save tool. So again same decorator we use uh like\n2:34:14 this. And now we request the llm to give us a file name as well. So it will it\n2:34:22 should give us a suitable file name uh which will be a suitable file name for the text file and uh it will and now\n2:34:28 this save tool will automatically handle all the save logic. So uh as a dock\n2:34:35 string I pass like this. So saves the current document to a text file and finishes the process. And the arguments\n2:34:42 are file name which is the name for the text file. Now, I've specifically mentioned that we're going to be using a\n2:34:48 text file so that the uh uh the LLM knows that the file name which it needs\n2:34:54 to pass has to have a txt in the end of it. Now, if it doesn't uh by any means\n2:35:01 to make the uh graph to make the entire code more robust, I've also written this if statement such that if this file name\n2:35:07 doesn't end with a txt, just put a txt there just uh as robust as measure. Now\n2:35:13 again we need to uh call the global variable again. So global document\n2:35:19 content. Okay. Now this next bit of code that's this is not langraph. This is just uh whatever you put in the tool. Uh\n2:35:26 it it doesn't have to it's not going to be langraph related. Right. So this piece of code is just uh some code which\n2:35:34 allows you to save the uh contents a the the content store in in the global\n2:35:40 variable under the file name uh and as a text file and I've also added this\n2:35:45 exception uh which is a good thing for debugging purposes where it if there's\n2:35:51 an error it will tell me exactly what the error is and then we can fix it. Okay. So hopefully there won't be any\n2:35:57 errors. Now we create a list of tools which uh again will be update and save\n2:36:04 because we only have two tools. And now we actually call the uh model and how do\n2:36:10 we call the model like such? Now let me ask you a question. Is this it for the model definition or do\n2:36:18 we need something else? Well, there's a reason I asked that question, right? We forgotten to do\n2:36:24 bind tools. So bind tools and tools. So that will do. Okay. Now we actually\n2:36:31 initialize the agent itself or the function which will cuz remember the agent will be a node in our graph. And\n2:36:39 what will be the function behind that? It will be this function which we're about to define. So let's write this as\n2:36:46 def r agent. And again we need to pass in the state the agent state and it'll\n2:36:51 return the agent state. And okay so now this doc uh not doc\n2:36:58 string this we need to pass in a system message to our llm right now this llm\n2:37:03 this system prompt will be quite large so get ready uh like such so in this system prompt I\n2:37:11 have specifically said this is a system message and the content is this you are drafter a helpful writing assistant\n2:37:18 you're going to help the user aka us to update and modify documents and I've also written some more stuff about what\n2:37:25 the uh update or what what to do if the user wants to update. We use the update tool. Uh we need to use the save tool to\n2:37:33 save it and to always show the current document say after modifications and all that stuff. Cool.\n2:37:40 Okay. So, oops. There we go. And now it's time for some robustness\n2:37:48 measures. So when we're first initializing the graph like when it's the first message we're writing\n2:37:54 obviously we're not going to straight up say uh how would you like to change the document right because we haven't passed in a document yet. So if messages uh\n2:38:03 this part if that if there's nothing in it we will have to say something like an\n2:38:08 introduction message right. So this is how you can do that. So we can\n2:38:15 say if not state messages aka if there's nothing in the state messages then we\n2:38:20 can say uh I'm ready to help you update a document. What would you like to create? and then it collects the user\n2:38:26 input and passes it as a put stores it as a a human message in this user\n2:38:32 message variable. Now what if I've already passed it uh passed in a message\n2:38:37 or like we are on the process of updating our draft or drafting it. Well to do that we need this else statement\n2:38:45 and what does this say? Well it says what would you like to do with the document? So this assume this says that\n2:38:50 there's already stuff in the messages uh state a messages key in the state how do you want to update it further and then\n2:38:57 we also print it uh under this emoji uh in the terminal so the user can also see\n2:39:03 what they've inputed and then this is also stored in the user message. All right. Okay.\n2:39:10 Now we combine all of this uh all messages aka the system prompt which was\n2:39:16 the system message uh and we create a list of uh list of the uh state messages\n2:39:22 and the user message the new message which we want the aka the update and\n2:39:27 then we just invoke the model and how do we invoke the model you just use the uh\n2:39:33 model invoke okay so pretty basic code so far there's nothing hard or nothing\n2:39:39 uh extraordinary or something we haven't seen before. All of this we have seen before. And now the rest of this\n2:39:47 function is just a print statement which I've included. This print statement is\n2:39:52 just for uh um making things look prettier on the terminal. That's all it is. You can see the true print\n2:39:58 statements. There's the AI response which will be printed and then there'll be the tools uh whatever the tool\n2:40:04 messages are that's also printed. So that's the whole point of it. there's nothing like to really like talk about\n2:40:09 it here. Uh and then we also need to obviously return the updated state. Now remember\n2:40:16 last time I showed you that this is also a really convenient concise way to uh\n2:40:22 update the states. So from now onwards we're only going to update the states like this. Okay. Now we create our\n2:40:29 conditional edge function or the function behind the conditional edge cuz remember let me open this up. So the\n2:40:36 conditional edge which I'm talking about will be this this this conditional edge.\n2:40:42 So there from tools there will be either the select the uh the choice of going to\n2:40:47 back to the agent or the choice of ending it. So we need to create the underlying function behind that. So\n2:40:54 let's create that now uh under this. So should continue. We've\n2:41:02 done this many times before. it det will determine if we should continue or end the conversation and remember continue\n2:41:08 or end the conversation. Okay, makes total sense. Okay, so\n2:41:16 now we do this. So we get the messages and if there's nothing in the messages,\n2:41:22 well obviously we'll need to continue, right? It won't go to the end part. Uh\n2:41:28 and this is just as like a robustness measure to be honest. Okay. So now this piece of code\n2:41:35 is basically saying look at the most recent tool message or the uh recent\n2:41:41 tool we've used and we need to check if this tool uh has used the save tool. Now\n2:41:48 why remember how we have two tools we have either the uh update tool or the\n2:41:54 save tool. If we use the update tool, well, we will obviously need to use the continue branch, right? But if we use\n2:42:01 the uh save tool, well, after you saved it, there's nothing else to do, right?\n2:42:07 You finished your draft, you finished everything, so might as well end the program. That's why this end tool. So,\n2:42:14 for the continue, uh if to go to the continue um through the continue edge,\n2:42:19 we have to use the update tool. And to go to the end uh edge you need to use the uh the save tool. So should make\n2:42:28 sense now but don't worry if it doesn't we will do some more print statements so you see the workflow. Don't worry. And\n2:42:35 lastly we need to obviously return continue because by default it's checked here that it's used\n2:42:42 the save tool. The only other tool left is the right tool and uh sorry the\n2:42:47 update tool. And the update tool means that we have to go to the continue edge, right? Okay. And that's that uh function\n2:42:54 done as well. So pretty easy still. Now this next function is again I only coded\n2:43:01 this just to make the print statements in a more readable message format uh\n2:43:06 when we printed on the terminal. So you will see where this comes in play when we actually start uh invoking the graph\n2:43:12 and seeing how our process is going. Okay, cool. Okay. So now we actually\n2:43:19 init uh create the graph. So how do we create the graph? We've done this many times. We will initialize it through a\n2:43:26 state graph. And now we will add the nodes. So agent and tools. And the tools\n2:43:33 will be a tool node. And again if you notice back we had one node, two node,\n2:43:38 the agent node and the tools node. I'm keep I'm like reflecting back and forth between this diagram and the code\n2:43:45 so I can show you exactly what we're coding. Okay. So again agent and tools node uh we've\n2:43:51 done now we will set the entry point at agent which is the start point aka this\n2:43:57 part right and now we're going to add an edge\n2:44:02 between agent and tools. Now we need to obviously create this edge because the agent needs to go to the tools right and\n2:44:08 then this edge this directed edge and this conditional edge creates the loop\n2:44:14 uh which will allow for the human AI collaboration. All right. Okay. So now\n2:44:20 we add the conditional edge and that's the conditional edge which I was talking about the continue at the end aka this\n2:44:27 condition this conditional edge from tools. Okay. And now the last thing we need to do is\n2:44:35 just compile it because we've finished the graph completely, right? There's nothing left. We've done the start point, we've done the end point, the\n2:44:41 end, this conditional edges done, the nodes done, and then this directed edge is done and the start point is obviously\n2:44:47 done because we've uh created a directed. So you can see the entire graph we have created just like that. So\n2:44:53 again, nothing too hard. Cool. Okay. So now we actually run\n2:44:59 the program. And to run it, I have just written this um function so that\n2:45:04 everything is in a more compact way. This is just to invoke the graph. Okay.\n2:45:09 And let's do that. So that was the entire code. And this code will allow\n2:45:15 for human AI collaboration. Now, yes, we used a global variable. And again, there\n2:45:21 is nothing wrong with using a global variable. I know some of you might frown upon it, but um again, there's nothing\n2:45:27 wrong with it. If we wanted to use more complicated uh form uh complicated uh\n2:45:32 stuff from langraph like the injected state or even using something like commands and interrupts uh we would have\n2:45:39 to write the code slightly differently but because this is a beginner level course uh we've just disregarded that\n2:45:46 completely and we found another way of performing human AI collaboration. Awesome. So let's actually run this now.\n2:45:53 So let's write python draft. py and you should be able to see all of\n2:46:00 the things. I made my face cam slightly smaller so you can hopefully see everything. Perfect. So you currently\n2:46:05 have an empty document. Could you let me know what you like to add or create in the document? So what would you like? So\n2:46:11 let's say we are writing an email to our colleague Tom saying that we can't make\n2:46:16 it to the meeting. So let's say write me an email. Let's say uh write me an email\n2:46:22 to Tom saying we I cannot make it to the\n2:46:28 meeting. Let's see what it says. So it says\n2:46:34 uh hi Tom I hope this message find you well. Please let me know. Okay let's now\n2:46:40 give it some feedback on how we how we can improve. So and also you can also see that it's used the update tool as\n2:46:46 well. Perfect. So, let's say um make sure to also have specified that\n2:46:56 the meeting was supposed to be at 1000 a.m. at some random negation.\n2:47:05 Canary Wolf. Okay. Okay. Let's see the updated thing.\n2:47:11 Hi, Tom. Uh you can see message meeting at 10. Uh, can I wolf due to unforeseen\n2:47:18 circumstances? Uh, let's I don't like this uh your name part though. So, let's say my name is\n2:47:26 V and it will update that as you can see. Perfect. Uh, what do what else do\n2:47:32 we want to change? We can also say something like uh let's say but tell him\n2:47:40 that I can make it at 12 p.m. in\n2:47:47 um New York, some random location. Okay, I'm making this up, but you you get the\n2:47:53 uh plan. Uh the next day. So, let's\n2:47:59 see. And perfect. It's updated it. However, I am available to meet at 12:00\n2:48:04 p.m. in New York the next day. Obviously, it's complete like rubbish like the timings of the location I've written. But you can see how we can just\n2:48:13 uh use human AI collaboration here. Uh one more thing which I don't like is\n2:48:18 this part. I don't like the fact that it's not a new line. So, I mean I'm being a bit picky here. We can say\n2:48:24 something like uh put the II hope this message finds you\n2:48:36 well. Awesome. And as you can see that's done as well. So now let's say I like it. Save it please. And what\n2:48:45 happens? You can see that uh it used the save tool. The tool results is document\n2:48:52 has been updated successfully. The current content is this and the document has been saved to unable to attend\n2:48:58 meeting email. Now remember we never passed in the file name at all. That was all generated by the by the agent\n2:49:05 itself. And to check we need to go on unable to attend meeting. So let's see\n2:49:10 here it is. And you can see it's the exact same\n2:49:15 meeting uh exact same email we said. So, subject, oops, best regards me. All the\n2:49:22 exact same content. Perfect. And we don't even need to uh make it so that\n2:49:27 we're drafting emails. We can even drop short stories. We can drop whatever we want. In fact, we can also pass in uh a\n2:49:35 previous message. So, the reason it started off like with nothing is because\n2:49:40 we pass in an empty list. But if you wanted to, we could have written something over here uh with our pre with\n2:49:48 a already existing email or already existing document and then it could the model the agentic system would know that\n2:49:55 this is what the content is the current content how would you like to uh change that and that is exactly how uh we will\n2:50:02 be able to operate on our existing ones. So you can see that this is quite a robust thing. If we want another\n2:50:09 example, for example, uh let's say python drafter.\n2:50:16 py. Okay, now watch this as well. Look how robust this is. If I say something\n2:50:22 like write an email, it actually gives back questions.\n2:50:28 So sure, what would you like the email to say? D. So remember, it didn't even go through any tool here. uh using\n2:50:35 langraph we can really make the agents quite robust and that's the thing which I wanted to show you it doesn't always\n2:50:42 have to pick a tool its own like LLM like the agent itself cuz remember the\n2:50:47 agent node has an LLM in the background back end the bind tools function allows\n2:50:52 it allows it scope like it increases the scope of it uh by providing some tools\n2:50:57 but that doesn't mean it has to use those tools if it doesn't feel like the need to use the tools it won't and in\n2:51:04 this case it wanted to ask us more questions about it. So it would say show what would you like this email to say\n2:51:10 because to be fair I only wrote three words. Uh but that was what I was trying to show you. So let's just clear this\n2:51:16 now cuz we don't need to. And yeah you can see perfectly works human AI\n2:51:21 collaboration in langraph and this is actually somewhat useful as well. Now yes of course you can use GPT4 canvas\n2:51:29 and all of that stuff of course but um this is how you would do it in Lagraph. All right. So, if you would like an\n2:51:36 extension to this, what you could do is add a voice feature as well. So, maybe\n2:51:42 you could add use OpenAI whisper for uh speech to text conversion or add 11 laps\n2:51:48 for text to speech conversion and maybe you can make it voice based cuz right now I'm giving it I'm how am I\n2:51:55 communicating it with text mode? What about voice mode? You could also include a GUI to this. There's a lot of stuff\n2:52:02 which you can do on you can even have your own knowledge base as well and include that. So a lot of potential with\n2:52:08 this if you want a homework for this uh specific project that there you go. All right. Okay. Cool. So that's the end of\n2:52:16 this subsection. Awesome. So now let's build our fifth AI agent. And some of you\n2:52:22 might have been looking forward to this. It's retrieval augmented generation rag.\n2:52:27 So what will the graph look like? It will look something like this. Again,\n2:52:32 start point, end point, really similar to what a react agent was, right? But uh\n2:52:38 we have two agents in this case. We have a retriever agent and we have our main agent LLM, right? So, and it will have\n2:52:44 obviously a conditional edge, a loop, and everything. Again, we're bringing everything we've learned so far and\n2:52:49 merging them into one. And we're also going to be learning about a little bit about rag. Now, I'll assume you know\n2:52:55 what rag is. I'm not going to go too much in detail into like the nitty-gritty of it. But again, in the\n2:53:01 surface level, I will obviously explain what rag is about and everything. Okay. So, if you're excited, let's uh let's\n2:53:08 jump to the code. Okay. So, now you can see that I've already done all of the imports\n2:53:13 which we'll need. But you'll notice how there are these four imports which we haven't come across yet. Now, rather\n2:53:20 than explain them from the get- go, I will explain them as they come because it'll make more sense. uh it'll make\n2:53:25 more intuitive sense that way. Okay. So now I'm going to be loading our uh ENV\n2:53:31 file which contains all the API keys. And this time I'm going to be\n2:53:37 initializing our LLM differently. Well, slightly differently. It's the same LLM, but why did I say differently? Because\n2:53:44 I've passed in a new parameter called temperature. Now for those of you who do not know what temperature is, it's\n2:53:49 essentially a parameter which depicts how stochastic the model outputs how\n2:53:54 stoastic you want the model outputs to be. So because I've set it to be zero, temperature equal to zero makes the\n2:54:00 model output more deterministic. Similarly, if I had set the temperature to be one, the model output would have\n2:54:07 been more stochastic. Okay. So now we create the embedding\n2:54:13 model. And the embedding model uh is what's going to convert our text into vector embeddings. Right? Uh so this\n2:54:20 will be the layout for it. Now please note one important thing which is the embedding model has to be compatible\n2:54:27 with the LLM we're using. You can use whatever LLM you want but make sure the embedding model uh is compatible with\n2:54:35 it. For example uh let's say we're using GBD40 uh an open model but the embedding\n2:54:40 model we're using is from Olama some random model. Now that they wouldn't most likely they're not going to be\n2:54:46 compatible. Why? Because there's so many differences between them. One potential difference could be the vector dimension. So just a rule of thumb. Make\n2:54:54 sure the LLM and the embedding model is compatible. Okay. Awesome. So now we're\n2:55:01 going to specify the PDF part. So this is the stock market performance 2024 PDF. And essentially this is just a\n2:55:07 document which I created which contains um a lot about the stock market\n2:55:12 performance. Okay. Uh I can show you that right now actually. So this contains nine pages and is just a\n2:55:20 document containing about some stock market details in 2024. Okay. Awesome.\n2:55:26 So now um in case you've specified the\n2:55:31 uh you have put the PDF in a wrong directory or if it can't find it uh this error will pop up. So again I've just\n2:55:37 put this for debugging purposes if you use the code which I provided on GitHub. Okay. Now this will load the PDF and you\n2:55:46 can see pi PDF loader is one of the imports which we made here. So again\n2:55:51 it's in the name and the common. It just simply loads the PDF. Okay. Uh and this\n2:55:58 try and accept command uh just checks if the PDF is there. And pages is equal to\n2:56:04 PDF loader.load. So this essentially says how many pages are there in the document. So you can see there's nine\n2:56:12 pages in our document. So if I run this command, if I run this, so clear\n2:56:20 python rag agent.py py it should say nine\n2:56:25 pages. So there we go. PDF has been loaded and has nine pages as expected. Right? Okay.\n2:56:33 Now it's time for the chunking process. Now what is chunking? First look at this. There are two parameters which\n2:56:39 I've specified. Chunk size which is a,000 and chunk overlap which is 200. So\n2:56:45 let's break this down a bit. Going back to our document. So chunk size was 1,000 tokens. So let's say that this was a\n2:56:54 chunk for example. Okay, obviously that's not going to be a thousand tokens, but just as like uh\n2:57:00 demonstration purposes, let's assume it is. So this is saying as soon as you've reached 1,000 tokens, you create a new\n2:57:06 chunk. So let's say 1,000 tokens ended here. So this would be the start of a new chunk like such. Okay. And you keep\n2:57:12 going and going and going until the end of the document. But what if the what about the second parameter? The second\n2:57:19 parameter is specified overlap and that's essentially saying let me use it in a different color that your chunks\n2:57:25 consecutive chunks should have some tokens um which are which exist in both\n2:57:30 for example because it was 200 the second chunk is not going to start from here. It's actually going to start\n2:57:37 something like this. They're obviously going to be the same length uh in terms of tokens but\n2:57:43 they will have some tokens which will be in both chunks. So for example, this part will be in both cuz that's the\n2:57:50 overlap. 200 tokens to be precise. Okay, so that was just a brief overview of what chunks are in uh rag. Okay, so\n2:57:59 that's that part done. And again, this recursive character text splitter is one of the imports we did. Okay,\n2:58:08 so this text splitter um chunking process, we now apply it to all of the\n2:58:14 pages, all of our nine pages in our document. Okay. And this piece of code essentially\n2:58:22 saying this, the chroma vector database, we're going to be using a chroma vector database to store all of our vector\n2:58:27 embeddings, by the way. But the uh the place where we want our chroma vector\n2:58:33 database to be will be specified in this file path. And the collection's name will be called stock market. Now, you\n2:58:39 can specify it wherever you want obviously, but I've just specified it to be in the same folder. Okay.\n2:58:47 So this is just an if statement to make sure that uh if this is the first time\n2:58:53 we're running this command uh if we're running this file uh if this collection\n2:58:58 doesn't exist we will create the um collection in the specified directory.\n2:59:05 Okay, again not too hard yet. Now here comes a try except command u try accept\n2:59:11 block. So this is where we actually create the vector embedding uh where we create the chroma vector um\n2:59:19 database and these are just parameters which I specify. So for example, how I want the pages to be split, what\n2:59:25 embeddings to use, where to store it and the collection name. The collection name being stock market, right? And if there\n2:59:30 is an error, it will throw an error and if it's successful, it'll print on the terminal. Okay, awesome. So now we\n2:59:37 create something called a retriever. So the retriever is quite important in rag.\n2:59:42 It's well obviously the first part of rag retrieval augmented generation. So the retriever is what actually well\n2:59:49 retrieves the chunks the most similar chunks. Um the search type which we're going to use similarity. It's just the\n2:59:56 default anyway. Uh you don't really need to know how that works to be honest. But what you do need to know is this part.\n3:00:03 So in this code I have made sure that every time uh it goes the amount of\n3:00:09 chunks it uh outputs back is five. Why? Because k here is the amount of chunks\n3:00:16 to be returned. So I've set it as five. Now I'm pretty sure if we go to the\n3:00:21 actual documents here the default the default is four. Okay. So uh this is\n3:00:28 just a parameter which you can uh set. Now you don't want it to be too high of course or too low. So you want like a\n3:00:34 good middle ground and 405 is a good middle ground in my opinion. Okay. So now let's create our tool. So again we\n3:00:42 use decorator tool. And the tool's name is going to be this retriever tool. It will input it will take in a query and\n3:00:49 it'll output a string. So the dock string is as follows. This tool searches\n3:00:54 and returns the information from our document. Okay self-explanatory.\n3:01:00 uh and obviously we need to invoke it to the retriever. So whatever query we ask\n3:01:06 for example uh what was Apple's performance in 2024 that will be the query and that will be passed to our\n3:01:13 retriever which will grab all the chunks the most the top five most similar chunks. Okay. Now if we don't if there's\n3:01:20 nothing similar uh which it finds for example if I say something like uh who's\n3:01:26 Bob the builder something like that right obviously Bob the builder is not in this document uh so it will return as\n3:01:33 I found no relevance information in the document and uh this will be passed to our LLM agent okay if it does find it\n3:01:41 though what we'll do is we'll create an empty list and we will store all of the\n3:01:46 similarity um us the all of the chunks which it found and then return those results uh\n3:01:53 through this. Okay, still it's quite easy still uh and this piece of code\n3:02:00 we've already come across. There is only one tool. So we just bind that tool to our\n3:02:05 LLM. And this also code we have also we've uh done many times. It's the uh\n3:02:14 creation of the agent state. And again we're using our add messages reducer function. All of this we've covered many\n3:02:20 times so you should be quite familiar with it. Okay. So now we create the should continue function and the should\n3:02:26 continue function uh is going to be the underlying function between our conditional edge behind our conditional\n3:02:32 edge. So it will check if the last message contains any tool calls. If it\n3:02:37 does then we um proceed. If it doesn't then we'll just end\n3:02:44 right. Okay. So now we specify the system prompt. Now this system prompt is\n3:02:49 going to be quite big. So let me copy and paste it here. Now the reason is quite big is I want to specify as much\n3:02:56 information to the LLM so that it knows what to do. Right? So I've just said you're an intelligent AI assistant who\n3:03:02 answers questions about the document uh loaded into your knowledge base. Uh you\n3:03:07 can read the rest if you would like. But I've also written this. Please always site the specific parts of the document\n3:03:13 you use in your answers. This is really just to make sure it's not hallucinating. Right? because as we know\n3:03:19 hallucination is quite a big problem with LLMs. So this is just to make sure um hallucinations are kept to a bare\n3:03:27 minimum. Okay. All right. So now we create a dictionary of our tools and we\n3:03:35 now create the underlying function which will be our LLM agent. So this function will call the LLM with the current state\n3:03:42 and you can see it converts the messages to a list passes the system messages and passes it to our LLM which is defined\n3:03:49 like this and it will just return the messages aka the updated state. Okay, this should be like such.\n3:03:59 Okay, awesome. So now we create our second agent which will be the retriever agent which you saw on the in the graph\n3:04:06 which I showed you in the introduction. So the retriever agent executes the tool calls from the LLM response. So what is\n3:04:13 this code actually saying? Well, all in all, this massive piece of code really\n3:04:20 just says if there is a tool, if the tool name is within the is a proper\n3:04:26 specified tool, aka if it's retriever tool, then actually run it. If it's not,\n3:04:32 then we will output the result as input in incorrect tool name. Please retry and select the tool from list of available\n3:04:39 tools. It's just for checking if a if the tool which is decided from the LLM\n3:04:44 is valid or not. So that's all what this is doing. If it is valid, it will invoke it and we will store the results uh like\n3:04:52 this and we will return that. Okay. Again this should be agent state like\n3:04:59 such. Okay. So we've created all of our our two um AI agents now and now we're\n3:05:07 going to create the graph itself. So like how we've done initialize it through state graph and then we're going\n3:05:14 to add our two AI agents as nodes with their respective\n3:05:19 actions and we are now going to add the conditional edge. So which will be llm\n3:05:26 which will be start from l lm and the should continue function is the function which will be um the underlying function\n3:05:34 and this is a uh true false statement and this is the edge the set entry point\n3:05:39 all of this we've covered many times so again should be quite familiar to you and last but not least compile the graph\n3:05:48 and store it in a ragation okay one last thing though uh I've created\n3:05:55 this function and this function is just a function which allows us to keep asking questions to our graph and keep\n3:06:02 receiving qu uh answers back and if you want to exit we can write either exit or quit um and it's just a simple while\n3:06:10 loop that's all it is okay and it prints the answer okay so that's the actual code\n3:06:17 complete now we're going to test it and see uh if the if this is reliable or\n3:06:23 not. Okay. Okay. So, let's actually test this now um by doing python rag agent.\n3:06:31 py. Let's run this. Okay. PDF has been loaded and has nine\n3:06:38 pages. Created chromo vector data uh chroma database vector store. So, where\n3:06:43 is this stored? Well, you can see that this is uh by the way, this will all be on GitHub as well. But this is the\n3:06:49 Chroma database and its respective um bin bin files. Okay. And we can even\n3:06:56 view it. But it'll look something like that. Okay. But because this has been created,\n3:07:02 this is a good sign that everything is working. Okay. So, let's ask a simple question. Uh let's ask something\n3:07:11 like how was the S&P 500\n3:07:16 uh performing in 2024? Enter. So it's\n3:07:22 calling the retriever tool uh with the query this uh its result then puts that\n3:07:27 complete back to the model and the model has given us this. In 2024, the S&P 500 delivered a total return of this with a\n3:07:34 23% increase late 1990s and all of that stuff uh magnificent 7 and has given us\n3:07:39 the uh respective uh citations as well. Now, how can we verify this is uh correct? Let's\n3:07:45 see. So, notice how if you remember this part, the total\n3:07:52 return of approximately 25%. Well, the reason I prom I asked it for this is because that's exactly what uh\n3:08:00 over here it stated the benchmark roughly at 25% 23%. Uh remember this\n3:08:05 late 1990s part that's exactly what this is saying here as well and this was\n3:08:12 correctly defined in the first document. So this is clearly working now right it\n3:08:17 can't have made up this information. So that means our rag is successfully set up. Now I can ask as many questions I\n3:08:22 possib as I want now but now let's see if there is something which is not\n3:08:28 included in the rag. So for example we can say something like how did open AI\n3:08:34 perform in 2024 retrieve a tool called back to the\n3:08:40 model. Okay, now look at this. Uh if I\n3:08:46 do it like that, the documents do not provide specific information about OpenAI stock performance, which is true\n3:08:51 cuz OpenAI is not a publicly traded company. Uh and yeah, it got that\n3:08:56 correct. So no hallucination there. So you can clearly see that this is working\n3:09:02 uh completely fine. And that ladies and gentlemen is how you create a retrieval\n3:09:07 augmented generation graph in Langraph. Okay.\n3:09:12 Awesome. All right people. So that brings us to the end of this course and I hope you liked it and I hope you\n3:09:19 learned a lot about Langraph. Now although this course is finishing here, your journey in Langraph\n3:09:25 is just beginning. Just think about how many cool AI projects, AI agent systems you can make now. Maybe your own Javis\n3:09:31 as well. Now, if you have any further questions related to the course material\n3:09:37 or just things in general or just want to say hi, you can always message me on LinkedIn. With that being said, thank\n3:09:43 you so much for watching this course and I hope to see you in another course. Take care.\n0:00 Welcome to this video course on Langraph, the powerful Python library for building advanced conversational AI\n0:07 workflows. In this course, Vbeca will teach you how to design, implement, and\n0:12 manage complex dialogue systems using a graph-based approach. By the end, you'll\n0:18 be equipped to build robust, scalable, conversational applications that leverage the full potential of large\n0:25 language models. Hey guys, my name is Vava and I'm a robotics and AI student.\n0:30 In this course, we're going to be learning all about the fundamentals of Langraph. Now, I assume you've heard of\n0:36 Langraph before, hence why you clicked on this course. But I'm also going to assume you have never coded in Langraph\n0:43 before. Now, because of this assumption, I have explained every single thing in as much detail as I possibly can. Now,\n0:51 also this might mean that I might be going slow at times. So if you want you can always speed me up. Now what are we\n0:58 going to be learning in this course? Well to start we're going to be building a lot of graphs, a lot of AI agents.\n1:05 We're going to be learning a lot about the theory and I've also provided exercises throughout the course in which\n1:11 all of the answers will be provided on the GitHub. With that being said, if you're\n1:16 ready to start on this journey with me, let's go to our first section\n1:21 then. All right people. So welcome to the first section of this course. Now in\n1:26 this section we'll be covering something called as type annotations. Now admittedly this is going to be a\n1:32 completely theoretical section but it will be short and brief. I promise. The reason I've kept this specific section\n1:38 in the course is because when we do eventually go on to code uh our AI agents, our graphs and langraph, these\n1:45 will start popping up everywhere. And I don't really want you to look start coding without ever having seen these\n1:51 before or really not knowing what these actually are. So that's why I've kept it here. But I promise this will be short\n1:57 and brief. Cool. Okay. Let's begin with dictionaries. Now dictionaries are a\n2:02 data structure. Yes, but there's a reason I've kept it here. So let's see\n2:07 how a dictionary is described in Python. You should already know this. So in this case, I've described a very simple\n2:13 dictionary called uh movie. and it has two keys, the name and the year. And it\n2:18 has two values, Avengers Endgame and 2019. Now, dictionaries are awesome, don't get me wrong. They're they allow\n2:25 for efficient data retrieval based on their unique keys. They're flexible and easy to implement, but there's a\n2:30 potential problem with them. See, it's a challenge to ensure that the data is a particular structure. And this could be\n2:38 a huge problem in larger projects. So to put things in simple words, it doesn't\n2:43 really check if the data is the correct type data type or structure and that could be the source of a lot of logical\n2:50 errors in your project. And if your project is really really large, then this could be quite a headache to\n2:56 identify, right? Cuz it's quite a small detail. So what is the solution for this? Well, it's something called a type\n3:03 dictionary. Now, here is an example on how you create a type dictionary in Python. And I just want to uh emphasize\n3:10 that this type annotation is used extensively in langraph. This will be used to define states. Now don't worry\n3:18 you we haven't covered states yet. We will cover that in the next section. But just be mindful that this is quite\n3:23 important. So a type dictionary is quite easy to implement. You implement it as a\n3:28 class. In this case, I've implemented the same um example I uh uh showed you\n3:34 in the previous section where I described the movie is the same exact keys and values. So, it still has the\n3:40 name and the year. But notice in this class, I have defined the actual uh data\n3:46 type of what that key should be. So, for example, the name is a string and the year is an integer, right? And to\n3:53 initialize a dictionary uh I have done the exact same thing. to have engineet game in 2019. So now there are two main\n4:01 uh benefits of using a type dictionary it's type safety because we've explicitly defined what should be in\n4:08 this data structure and so this will really reduce the runtime errors and obviously the readability is enhanced as\n4:14 well and this will make debugging easier if something goes wrong within this type dictionary. Cool. So we've covered type\n4:22 dictionary now. Now we move on to another type of annotation which is union. Now you might have seen these\n4:29 future these later uh types annotations before if you coded in Python but again I'm just giving you a highle overview\n4:35 what these are. So union take a look at this example. So I've created a very simple function which takes in a value\n4:42 and it squares it. Now in this case the uh input x could be either an integer or\n4:48 float and union basically says that whatever value you have can be these\n4:54 data types only. So in this case x can only be integer or float. So if I pass in five or 1.23 4 this would be\n5:01 completely fine. It would square the number and everything. But if I passed in a string like I am a string it would\n5:06 completely fail. Now admittedly yes this function is quite easy. If I passed in\n5:12 I'm a string, it would have failed anyway. But in more complicated applications, hopefully you can see how\n5:17 this actually is useful. In fact, the makers of Lang Chain and Langraph used Union quite extensively throughout u\n5:24 making the actual library. So again, it's flexible and it's easy to code and\n5:30 it allows for type safety. So because it can provide hints to uh help catch\n5:35 incorrect usage. Now something similar to union is another type annotation which is optional. Now optional is quite\n5:42 similar and in this case I've described another function nice message. So you\n5:48 pass in a name. If you pass in a name it will say hi there name. So for example let the name be Bob. If I pass in Bob to\n5:56 this uh function it would say hi there Bob. But what if I don't pass in\n6:01 anything? Now if I don't pass anything optional because I've used optional says that the name parameter could either be\n6:08 a string or a none value. Now if I pass in nothing it will go in this if\n6:13 statement and say hey random person. But this is also important to emphasize that it cannot be anything else. It can't be\n6:20 an integer or or a boolean or a float or anything like that. It has to be either a string or a none value because that's\n6:27 what I've defined here. Cool. Now comes another type annotation called any. And\n6:33 any is really the easiest one to understand. It literally means this value could be anything. It could be any\n6:40 data structure. So in this case I've created a simple um function called\n6:45 print value where it takes in something and it prints that. And for example I\n6:51 passed in this string and it prints it and anything and everything is allowed.\n6:56 Cool. one last type annotation I promise and it's the lambda function. So lambda\n7:02 functions are quite useful. For example, in this I'll give you two examples now. So the first example is this really\n7:10 simple uh example. Now we've already I already created a square function before, right? Where it takes in a\n7:16 value, it takes in a number and it squares it. So for example, if I passed in square 10, it would give me 100.\n7:23 Quite an easy example. Now let me give you a second example. this. So if you've come from a\n7:29 leaf code background, then you've probably seen you've either used lambda before and you've definitely used math\n7:35 before cuz it's quite efficient. So for example, if I pass in 1 2 3 4, what this piece of code is saying is that it\n7:42 squares each number in nums. So this map function maps each value uh and performs\n7:49 this function to it. So x * x. So 1 4 9 16 and then converts that back into a\n7:55 list. Now lambda functions really are just a shortcut to writing small functions and they make everything quite\n8:02 efficient. Now obviously this could have been done in one line as well but for example this a beginner programmer could\n8:09 have might have used a for loop but a more advanced programmer could have used this and this is obviously much more\n8:16 efficient. Right? So hopefully you can start to see what how powerful these type annotations are and these will be\n8:23 coming up. So again, no need to memorize this. Just need to have a highle overview what they are. Okay, cool. So\n8:29 now I'll see you in the next section. See you there. All right, perfect. So let's\n8:36 continue on. In this section, we will look at the different elements in Langraph. So let's begin with our first\n8:44 element, one of the most fundamental elements in all of Langraph, the state.\n8:49 So what is a state? Well, it's a shared data structure that holds the current\n8:54 information or context of the entire application. In simpler terms, it is like the application's memory where it\n9:01 keeps track of the variables, the data that nodes can access and modify as they execute. Now, don't worry if you don't\n9:08 understand what a node is yet. That is what we will be talking in the next slide about. But as a good analogy,\n9:15 think of the whiteboard in a meeting room analogy. Now imagine you're in a meeting room and\n9:20 there are different participants as well and every time you come up with something new or you want to record some new uh information or update some\n9:27 information you write it on the whiteboard. In this case the whiteboard acts as your state and the participants\n9:34 act as a node. So the state shows us the updated\n9:40 content/in information of your entire application. Hopefully that made a bit of sense.\n9:47 So let's move on to the node another fundamental element in lang graph. So\n9:52 these are just individual functions or operations that perform specific tasks within the graph. So each of these node\n9:59 receives an input which is often just the current state of your application. It processes it and then produces an\n10:05 output or an updated state. So here's a good analogy of this.\n10:12 The assembly line station analogy. Now look at this image. Each of these\n10:17 station does one specific job. It could be attaching a part. It could be painting it. It could be inspecting the\n10:24 quality and so on and so on. The point is each of these stations represent a\n10:30 node because they do one specific task. So how do you actually connect\n10:36 these different nodes together? Well, before we go into that, I think it's important we understand the most\n10:42 important element of them all, the graph. It is so important that it's even\n10:48 in the name Langraph. So, the graph is just the overarching structure and it\n10:54 maps out how different tasks aka nodes are connected and executed. So it\n11:01 visually represents the workflow showing the sequence and the conditional parts\n11:06 between various operations. Now a graph is quite self-explanatory but you can think of it\n11:11 as a road map. On a road map you can see it display the different routes\n11:16 connecting cities with the different intersections offering choices on which path to take next.\n11:22 Now, here's a great image of what a graph is, and these are the individual nodes, but you'll see they're connected\n11:28 somehow. So, how are these connected? That brings us to the next element,\n11:35 edges. So, edges are just the connection between nodes and these determine the\n11:40 flow of execution. So, they tell us or tell the application which node should be\n11:45 executed next after the current one completes its task. A really good analogy of this is imagining a train\n11:52 track. So this is the train track and think of it as an edge and think of it\n11:57 as connecting two stations one here and one here which represent nodes together\n12:03 in a specific direction. Now the train which will go on the train track that acts as your\n12:10 state. So the state gets updated from one station to another.\n12:16 But there is another type of an edge and it's called a conditional edge. So this is still not very\n12:24 complicated. It's quite simple to understand. These are just specialized connections that decide the next node to\n12:30 be executed based on the specific condition or logic applied to the current state. Now a really good analogy\n12:37 for this is the traffic light analogy. So green could mean to go one way, red\n12:42 could mean to stop. yellow could mean to slow down. The point I'm trying to make here is that the condition, in this case\n12:49 the light color, it decides the next step. If you want to think even more\n12:54 simply, you could think about an if else statement. So that being said, we move\n13:01 on to the next element, the start point. So the start point or the node, the\n13:06 start node is a virtual entry point in langraph and this marks where the workflow begins. Now it's important to\n13:12 note that it doesn't perform any operations itself but it serves as the designated starting position for the\n13:18 graph's execution. Now in terms of analogy it is quite simple to understand but if you\n13:25 really want think of it as the starting line of race. Now if you have a start point well\n13:32 you need an end point as well and that's where the end element comes in. So the\n13:37 end nodes just signifies the conclusion of the workflow in Langraph. So when the\n13:42 application reaches this node, the graph's execution completely stops and it indicates that all intended processes\n13:49 have been completed. And again, a good analogy for this is just the finish line in a\n13:55 race. So nothing too hard yet. But now let's look at\n14:01 tools. So tools are specialized functions or utilities that nodes can\n14:06 utilize to perform specific tasks. For example, it could be fetching data from an API. They basically enhance the\n14:14 capabilities of these nodes by providing additional functionalities. Now, one common\n14:19 question could be, well, what's the difference between a tool and a node? The node is just the part of the graph\n14:25 structure. Whereas the tools, these guys are functionalities used within the\n14:31 nodes. Now, a really good analogy for this is just tools in a toolbox. So\n14:36 imagine a hammer for the nails, a screwdriver for the screws, etc. The\n14:41 point is each tool has a distinct purpose. Again, don't worry. You will understand the differentiation between\n14:48 tools and nodes in a lot more detail later when we code this, but this is just for a general\n14:53 overview. Now, another question you could be asking is, is there a middleman between a tool and a node? Short answer\n15:01 is yes. That's where tool node comes in. So a tool node is just a special kind of\n15:07 a node whose main job is to run a tool. So for example, a tool node could\n15:14 be a node where its only job is to use a tool and that tool's job is to fetch\n15:21 some data from an API. So it connects the tools output back into the state so other nodes can\n15:28 use that information. So think about this analogy going back to the assembly line. In this case,\n15:36 imagine the operator as the tool node and it controls the machine which is the tool and then sends all of these results\n15:43 back into this assembly line. Now if we progress further, let's\n15:50 look at the state graph. So this is quite an important element as well. This will be one of the first elements you\n15:56 actually interact with and its main purpose is to build and compile the graph structure. So it's quite\n16:02 important. It manages the nodes, the edges, the overall state and it makes\n16:08 sure that the workflow operates in a unified way and all of the data flows correctly between components. So again\n16:15 it's quite an important element. You can think about it as a blueprint of a building. So just as a blueprint\n16:22 outlines the design and the connections within a building, the state graph does\n16:28 exactly that, but it just defines the structure and the flow of your workflow or\n16:35 application. Now here's where the runnable comes in. Now some of you will be coming from a lang chain background\n16:41 and runnable is quite common there and it's quite similar in langraph as well.\n16:46 A runnable in langraph is just the standardized executable component that performs a specific task within an AI\n16:53 workflow. It basically acts as a fundamental building block allowing for us to create these modular\n17:00 systems. Now a question you could have right now is well what's the difference between a runnable and a node?\n17:07 Short answer is a runnable can represent various operations whereas a node in\n17:13 lang lang graph typically receives a state performs an action on them and\n17:18 then updates the state. Now don't worry if you didn't 100% get that when we go\n17:24 into the coding section you will get it a lot better. But a good analogy is a\n17:29 Lego brick. So just as how Lego bricks can be snapped together to build these complicated structures, runnables can be\n17:37 combined to create sophisticated AI workflows. So now let's move on to the\n17:42 different types of messages. Now again, if you come from a lang chain background, you'll be quite\n17:48 familiar with these. If you haven't, don't worry. We will look at the five most common message types in Langraph.\n17:57 So to start off, there's the human message which represents the input from a user. The AI message which represents\n18:03 responses generated by AI models. The system message which is used to provide\n18:08 instructions or context to the model. Tool message which is similar to the function message but specific to\n18:14 tool usage. And the function message represents the tool of a function call.\n18:20 If you've used an API like a large language model API before, such as OpenAI's API, a lot of these will be\n18:26 quite familiar, especially the system message, the AI message, and the human message. And that concludes this\n18:33 section. So, I will see you in the next section. Awesome. So, now this is quite\n18:41 exciting. We're actually about to start coding in Langra for the very first time. Now that we've covered all the theory, admittedly the boring section,\n18:49 we're now actually going to code up some graphs. And we're about to code up our very first graph in this sub section.\n18:55 But um for this overall section, I have a slight confession to make, which is\n19:01 we're not going to be building any AI agents in this section. Why? because I thought that one\n19:08 we haven't really even seen uh how to actually code in Langraph and combining all of these LLMs APIs and tools and all\n19:15 of that stuff which comes with it combining them together would be quite messy and it could be quite confusing at\n19:21 times especially the fact that we have never coded in Langraph before again like I said at the beginning of the\n19:27 course this course is supposed to be beginner friendly detailed and comprehensive and we're going to go in\n19:33 steps like little by little so hopefully understand but don't worry we will be coding AI agents soon we're just going\n19:39 to be building a couple of graphs right now uh understand lang graph better the syntax better and how to actually code\n19:46 up graphs and get confident with it and then we will actually build AI agents okay cool so what is the graph which\n19:53 we're going to be building together in this section I call it the uh hello world graph mainly because it's the most\n19:59 basic form of graph we can actually code in lang graph so the objectives are\n20:04 these So we're going to be understanding and defining the agent state structure and\n20:11 don't worry you'll understand what that is in a few minutes and we're going to be creating simple node functions nodes\n20:17 like we discussed in the previous section uh and we're going to be processing them and updating the state.\n20:23 We're going to be building the first ever basic langraph structure and we will understand how to compile it,\n20:29 invoke it, process it, everything. And really the main goal of this section is\n20:35 to really understand how data flows through a single node in langraph. Now just to give you a bit of a heads up as\n20:42 to what we'll actually be covering uh what we're going to be building I should say is this graph. Again like I said\n20:49 this is the most basic form of graph you can build in langraph. It has a start point and an end point and this node\n20:56 sandwiched in between them. All right cool. So hopefully you've understood what the objectives are. It's quite\n21:02 basic and yeah, I'll see you at the\n21:08 code. Okay, cool. Now let's actually code this very first graph. So I've\n21:13 imported three main things here. The dict, the type dict and the state graph. The dict and type dict is obviously\n21:20 dictionary and type dictionary but um and state graph. These three are\n21:25 elements which we covered in the previous section. So I would highly recommend you going back there if these\n21:30 are completely unfamiliar. But again you don't need to memorize what these are. Okay. But just to refresh your memory\n21:36 I've written in the comment here what the state graph is. So think of the state graph as a framework that helps\n21:43 you design and manage the flow of the tasks in your application. Um again that\n21:48 might sound a bit complicated but it's not. Once we actually start coding you\n21:53 will it'll make more sense. So now the first thing we're going to do after importing everything is create the state\n22:00 of our agent and let's call it agent state. And just to refresh your memory\n22:06 again what the state is. Think of the state as a shared data structure. And\n22:11 this keeps track of the your all of the information as the application runs. All right cool. So now let's build the agent\n22:18 state. And the way we do this in Langraph is through a class. So let's build class agent state and in this in\n22:26 these parenthesis we will try to the the state needs to be in the form of a typed\n22:32 dictionary. So that's why we specify type dictionary here. Now let's keep\n22:38 this very very fundamental and basic. Let's just pass in one input. Let's call\n22:44 it something like message and obviously we put colon and\n22:51 the we specify the data type of that uh attribute. Now obviously the data type\n22:57 of message will be string right so that's why we specify strl again this is\n23:02 just normal python so once we've done that we are now going to be coding our\n23:08 very first node again another very fundamental element in langraph so how\n23:14 do we actually define a node it's quite simple it's just a normal standard\n23:19 python function and this is how you do it so let's say let's first try to find\n23:24 The objective um let's say we are trying to let's a greeting message a simple\n23:31 greeting message. So we'll write def greeting node and we need to pass in an\n23:38 input and pass what the output type should be. Now the input type of a node\n23:44 needs to be the state and the output type also has to be the state because\n23:49 remember the state keeps track of all of the information in your application\n23:54 right so obviously you need to pass that as an input and you need to pass out the or return the updated state. So here's\n24:01 how you do it. You pass in state and what is the state of our application? Well, it's the agent state which we\n24:08 defined earlier, right? And the output is going to be agent state cuz we need\n24:14 to output the updated state. And our updated state will again just be the agent state once we've done all of the\n24:21 um all of the mechanics we do in this function, the actions we perform in this function. All right. Okay. So now we\n24:28 need to do something very very important and it gets annoying sometimes but um\n24:34 it's really a key habit which I want you to form and it is dog strings. Now dock\n24:39 strings and lang graph is quite important. Why? Because dock strings is what will tell your AI agents when we\n24:46 actually build the AI agents your LLMs what that function actually does what that function's actions are what it\n24:52 performs. So in this case uh by the way to create a dock string is just three quotation marks three pairs of quotation\n24:59 marks. Uh let's call the dock string in this case let's just write simple node\n25:05 that adds a greeting message to the state. Perfect. So now how do we\n25:14 actually refer to this message? Well again this is just normal Python code.\n25:19 So we will pass in state and we will type in message.\n25:25 Now this specific part allows us to actually update the state or the message\n25:31 part of the state. And let's say let's come up with something like hey\n25:37 plus state message. Um we can also add something\n25:42 like how is your day going something basic. Now what's the last thing which I\n25:48 need to do in this function? Think about it. Okay. So now remember in uh a few\n25:56 moments ago I said we have to return the state or the updated state. Well the updated state we've already done we've\n26:02 just manipulated the state here. So all we have to do is just simply return the state. Cool. And yeah that runs without\n26:10 any errors. Okay. Now let's actually build the graph uh which is again\n26:16 obviously very important. So how do we build the graph? Remember here I said state graph is a framework that helps us\n26:23 design and manage the flow of tasks as a graph. Well that's exactly what we're about to do now. So hopefully it clicks\n26:29 now. So to create a graph in lang graph you use the state graph attribute and\n26:35 you pass in your state. You can see the state schema which VS code has uh asked for what uh the description of what the\n26:42 parameters are. So our state schema in this case is just the agent state which we define right. So we pass an agent\n26:49 state. I will actually also write here our state\n26:54 schema. So uh you can physically see what it is.\n26:59 Okay. And let's store this in a variable called graph or something. Okay. Now now\n27:07 here comes a very important method. How do we actually add a node to this graph? Cuz this graph is completely like\n27:13 nothing right now. So to add a node we use the inbuilt function graph add node\n27:18 and it requires two main parameters. Now what VS code is suggesting is a god I\n27:25 don't even know what that all of all of that is right it's very confusing. So to put things simply you require really two\n27:33 uh parameters the name of your node and what action it will perform. So let's go\n27:39 with the name. The name could be absolutely anything sensible of course. Um let's call something like\n27:45 greeter. Cool. And you can see VS Code has also asked us to um input an action.\n27:53 Now what's the action going to be? Well, the action will just be whatever your node will actually perform. And what\n28:00 action or mechanics will this node actually perform? Well, all of that is defined by this function, right? The\n28:07 greeting node function. So we simply just put that the name of the greeting node function here and that's it. We've\n28:14 successfully added the greeting node to our function to our graph and it will be\n28:21 named as greater. So remember this\n28:27 diagram in this diagram there is supposed to be a start and an end point. We've done the node which is sandwiched\n28:33 in between these but we haven't really added the start and the end point yet. So, how do we do that? Well, there's\n28:39 actually multiple ways to do that. In this subsection, in this graph, I'm going to teach you one way. Further down\n28:45 the line, I'll teach you another way. So, but they're both they're quite easy. So, you simply just call the inbuilt\n28:51 function set entry point and as the parameter is just one\n28:56 parameter which is the key. Now, the key is the name of your node which you want the start node to connect to. Again,\n29:04 visualize it. The start the start point is here and the node is here. Obviously you need to reference a node for it to\n29:11 create like an edge right. So we simply pass greater and similarly graph dot set\n29:17 finish point. We will again pass greater here as well. Why? Because imagine again\n29:24 the node is here and your finish point is here and you need to connect some sort of connection between these two right and that's why we use uh greater\n29:30 in this case. Don't worry, you will solidify this once you complete the exercises and as we go down building\n29:36 more graphs. All right. And one last thing which we need to do is actually compile this graph. So graph compile\n29:43 using the inbuilt uh graph using the inbuilt compile function. And let's just store this in a\n29:48 variable. Cool. So that run without any errors. But just a word of caution here.\n29:54 Just because the graph compiles without any error doesn't mean it will successfully run. I mean, God knows once\n30:00 we build like more complicated graphs, there could be so many logical errors. So, that's just an important thing to\n30:06 know. So, don't get too happy once it compiles cuz there might be logical errors. Trust me, I know. Okay.\n30:15 So, I want to write some code which will actually help you visualize this. And\n30:20 you can use the IPython library. So, you can use this uh this um piece of code\n30:26 here. This code is awfully familiar with the first ever graph I showed you, right? I\n30:33 I'll put a picture somewhere here for you to compare. The only difference is really the name of the node which we've\n30:39 set. In this case, it's greater. Why is it greater? Because that's the name we gave to this node, right? Cool. So\n30:47 that's looks pretty good. Let's actually run this. So to run you use the inbuilt\n30:54 method invoke. Um so let's pass in the message\n31:00 as something like Bob or something and let's actually store this result in a\n31:09 variable. Okay. Now how can we actually specify uh how can we actually get the\n31:15 value of result? So result we need to actually reference\n31:22 a certain attribute. Now the only attribute we have in uh the entire graph is message right. So we simply just put\n31:29 message and perfect you we get the final answer which is hey Bob how's your day going now why is it like this because\n31:36 this is exactly how we set our act how we set our function to be what action it performs it says hey then concatenates\n31:44 the uh input message in this case it's just the name and it says how's your day\n31:49 going now I could have changed this to absolutely anything else right uh what goes here like these functions are\n31:56 almost endless but That's the whole flow of how everything works. So hopefully\n32:03 you understood how to build this very first hello world graph. It's quite\n32:08 simple. But um don't worry if you didn't fully 100% understand this. I'm now\n32:14 going to show you what exercise you need to complete uh to be able to solidify this. All right. All right. I'll see you\n32:20 at the exercise. Okay. So time for your very first exercise. So the exercise for this\n32:27 graph is quite similar to what we just did, but I want you to create a personalized compliment agent. So you\n32:35 should pass in your name as like something like Bob or something and then output something like Bob, you're doing\n32:42 an amazing job learning langraph. And to give you a hint as to what you need to do again, you again have to concatenate\n32:48 the state, not replace it. All right, it's very similar to what we just did and it's quite basic. You should be able\n32:55 to do this, but um this is really just to get your hands dirty. All right. Okay. Once you've completed this\n33:01 exercise, join me when we build the second graph. I'll see you\n33:06 there. Okay. So now we're about to build our second graph as you can see here.\n33:12 And it's again quite similar to the first graph we built except now we're\n33:17 going to be able to pass multiple inputs as you can see here. So again, what are the objectives which you will be\n33:23 learning in this? Well, we're going to build a more complicated agent state.\n33:28 Uh, and we're going to be creating a processing node that performs operations on list data. So now we're about to see\n33:34 how we can really work with different data types apart from just string. And\n33:39 we're going to set up the entire graph that processes and outputs these and computes these results. And we're going\n33:45 to be able to invoke the graph with the structured inputs and retrieve the outputs. But the main goal which uh I\n33:53 want you to be able to learn in this specific subsection is really how to handle multiple inputs. All right. Okay.\n34:00 Let's code this. Okay. So now let's actually code the second graph up the second\n34:07 application up. So again I've just imported the same things again the type dictionary and the state graph. And I've\n34:13 also imported the list this time. But list is just a simple data structure which you should know already. So if you\n34:19 remember from the previous graph we made we are supposed to uh implement the state schema first right. So how do we\n34:26 do that? Again we use the class agent state uh type\n34:32 dictionary. Okay before I continue just a heads up I could have named the state schema anything I want. I could have\n34:39 named it uh something arbitrary completely like a bottle for example. In this case I've just said agent state\n34:45 because one that's how I learned it. It's like a habit for me now. But it also really tells you what it actually\n34:52 is. It's the state of your agent, right? So that's why I've just kept it like that. But again, just a heads up, you\n34:57 could have named this whatever you want. Cool. Okay. So now let's the if you\n35:02 remember the main goal for this graph for this uh building this graph was to be able to handle and process multiple\n35:09 different inputs, right? So how do we actually assign and I really do that?\n35:17 Well, the answer is in the state which is here's what uh which is what we're about to do now. So you really cuz\n35:24 remember this is just a type dictionary. So you basically have multiple keys now\n35:30 you uh create that. So let's say something like values list integers.\n35:37 So let's say one of our input is a list of integers and let's also pass in a\n35:43 name which will obviously be in a string and let's have the result in a string\n35:50 something completely random. But now you can see we're now operating on two different types of data structures uh a\n35:56 a list of integers and a string. And we're handling three different uh different uh uh inputs values name\n36:04 result. Okay cool. So let's run this. Perfect. So now let's actually build our\n36:10 node because in again in this uh graph we're just going to have a single node to keep things easy. Remember step by\n36:17 step. So let's call let's write dev process values and again what was what\n36:24 needs to be here? Yeah. So we need to pass in the state and we need to return the updated\n36:31 state. So how do we do that? Well, we write state agent state and we pass out\n36:37 the agent state. Cool. Now, again, building healthy habits. I know it's\n36:43 annoying. We have to write the dog string. So, let's just write something like this\n36:50 function process handles multiple different value in multiple different\n36:57 inputs. Cool. Again, I'm not being super specific here because one, uh, I don't\n37:03 want to spend too long on writing doctrines and everything, and two, there's no AI or LLM here, right? So that's why it doesn't really matter. I'm\n37:09 just doing this to build healthy habits. Okay, so now let's do something like whatever values we pass the list of\n37:16 integers. Let's sum them up. And let's also concatenate the name as well and\n37:21 store it in the result. Sound cool? Okay, so how do we do that? We pass in\n37:27 state result cuz that's what we are uh the action we're performing is on result\n37:32 uh the attribute result and let's say something like hi there and then we refer to the name\n37:41 um cool and your sum is equal to and let's just use the inbuilt Python\n37:46 function sum and we pass state values cool and lastly we obviously\n37:54 return the Okay, perfect. And that's that done.\n38:00 Okay, so now we actually create the graph. Again, this is going to be very very similar to what we did in the\n38:07 previous section because again there's just a node, there's a start point and an endpoint. So like last time, we use\n38:14 the state graph to initialize a graph and we pass in our state schema. So agent state and let's store this in the\n38:21 variable graph. Okay. Uh let's add our node. So graph add\n38:27 node and again remember it requires two parameters. It requires the name and the\n38:32 action. So in this case the name will be let's call it processor for example. Again this could be anything you want\n38:40 and your action will be performed by this function right process values. So we can just add that. Okay. Now I've\n38:48 already told you how to uh how to initialize a start point and an end point and this is just given by that\n38:54 code. So you attach your entry point to your node. In this case it's just one node which is the processor node and\n39:00 again same goes with finish and you compile it using\n39:05 graph.compile. Perfect. So take a moment now. How do you think this graph will\n39:10 look like? That again like I said very very\n39:18 similar on how the graph actually looks like but the only difference now is the\n39:24 name of the uh node which we've kept this as processor. Okay. So now let's\n39:30 actually test this. Let's actually invoke this graph. So how do we do that? Well, we use the invoke function. Now\n39:37 here's another important part which is quite a common mistake especially like I have done this many times. Make sure to\n39:44 store your compiled graph in a variable cuz if you invoke the graph i.e. if you\n39:50 write something like graph.invoke that won't make sense cuz you haven't compiled the graph. That's why you need\n39:56 to uh invoke using app. That's why I've also done app here. If I did graph get\n40:03 graph. Oh, it's completely messed up. Right? It says state graph object has no attribute because your graph hasn't been\n40:09 compiled yet. That's why when I do appget graph the uh process works. Cool.\n40:16 So now let's again store this in uh let's store something like answers is\n40:21 equal to app.invoke. Cool. Let's pass in some values. Let's say something like\n40:29 values and let's have a list of integers. 1 2 3 4. Again, I'm just\n40:35 trying to prove a point. I'm not trying to make a very complicated um graph yet. And let's pass the name as something\n40:42 like Steve something. Okay. Uh cool. And\n40:48 let's print let's print answers. Let's see what happens. Perfect. So now you can see\n40:55 your values is 1 2 3 4. Your name is Steve. And your result is Hi there\n41:00 Steve. Your sum is equal to 10. Again, why? because that's exactly what we uh\n41:05 asked the node the action to perform. Hi there, your name which in this case is Steve. Your sum is equal to the sum of\n41:12 the values and 1 + 2 + 3 + 4 is 10. Right? And that's how you get this\n41:18 answer. Now what if I wanted to just access result? I didn't want any of this\n41:24 other uh nonsense. Well to do that you can again just specify result and you will get it\n41:31 in a more clean manner. Cool. Okay. Now I want to try one more\n41:38 thing just to build your understanding a bit more. Uh let's put some print\n41:43 statements here. So let's have a print state\n41:49 here. Then we perform the action and then we print the state here. This is\n41:55 really just to show you how the state gets updated and it should be easy like\n42:00 interpretable cuz this is quite a basic piece of code. Again, print stated before the action and print state after.\n42:06 So there cool and here you go. So value is equal\n42:12 to 1 2 3 4 name is equal to Steve and these are the inputs we passed. Now notice I didn't pass results as an input\n42:19 as well. I could have uh done that but Langraph automatically sets that as like\n42:25 a a none value in this case if you don't pass an input. Now here's where you need to be\n42:33 cautious. If I had actually used state result here as well to uh update state\n42:39 result like I used state result to update either itself or something else\n42:44 then you would run into a problem because your state result has been initialized as none because you didn't pass it as an input. So be mindful of\n42:52 that. But in this case it worked because we're only assigning state result. We're not using it to assign something. It's\n42:59 getting assigned. Cool. And you can see after the action has been performed uh\n43:05 your operation has been performed and the thing has been concatenated. You can see result is here and that was exactly\n43:12 what we were getting before we cleaned this up. Cool. So hopefully you understood that. Again it should have\n43:18 been quite intuitive and interpretable but um to solidify your understanding even more complete the exercise. So I'll\n43:25 see you at the exercise then. Okay. Welcome to the exercise,\n43:30 your second ever exercise. And for this exercise, I want you to create a graph\n43:37 which passes in a single list of integers along with a name and uh an\n43:42 operation this time. And if the operation is a plus, you add the\n43:47 elements. And if a well times, you multiply all the elements all within the\n43:54 same node. So don't create an extra node yet. So for example your input should\n43:59 could be jack sparrow your values 1 2 3 4 again and then your operation uh uh\n44:04 multiplication and your output should be in the format of hi jack sparrow your answer is 24 so just to give you a hint\n44:11 as to how you would perform something like this uh you would need an if statement in your node so slightly more\n44:17 complicated but the whole concept is the same so once you've completed this exercise I will see you in when where we\n44:25 build this third graph All right, see you there. Okay, welcome to your third\n44:33 graph. So, what are we going to do this time? Well, enough processing multiple\n44:39 values and everything. Let's actually get the graph more complicated. So, that's why we're going to be building a\n44:44 sequential graph. So, all it all that basically means is we're going to be\n44:49 creating and handling multiple nodes that can sequentially process and update different parts of the state. So we will\n44:56 learn how to connect nodes together in a graph through edges of course and we're going to invoke the graph and really see\n45:02 how the state gets transformed as we uh progress through our graphs step by step. So again your main goal is should\n45:10 be to understand how to create and handle multiple nodes in langraph.\n45:15 Sounds cool. Okay I'll see you at the code. Cool. So now we're about to code\n45:22 up the third graph. Uh, and we're making quite fast progress. So well done on that. So again, the imports are the\n45:30 same. State graph and type dictionary. Perfect. And like we've done in the previous two\n45:37 graphs, we're going to be coding the uh the state schema or the agent state first. So let's have class agent state.\n45:46 And again, it needs to be in the form of a typed dictionary, right? And in this case, let's have the three attributes as\n45:53 all strings because we've already we already know how to handle multiple data types, right? So, let's keep it simple.\n45:59 Name string, age string, and final string.\n46:06 Okay. Now, here's what we're going to build. Now, we're about to build our two\n46:11 node functions, uh, which are again the actions. Okay. So again you simply write first well\n46:19 I'll name it first node in this case and like I mentioned before we pass in the\n46:26 state and we return the updated state. Okay. So again healthy habits doc string\n46:34 again. So this is the first node of our\n46:39 sequence. Okay. And what do we want to do in this specific node? Well, I really\n46:44 just want to manipulate uh the final part. So, let's say something like\n46:51 state final is equal to state or let's\n46:56 have an f string\n47:02 f state name. Let's say something like\n47:08 hi that. Cool. And we'll just return the state. Perfect. And now again we create\n47:16 a new node. So state agent state. Return\n47:21 that. Perfect. And I'm just going to copy this dock string and just change it. This is the\n47:27 second nerf. Perfect. Okay. To speed things up. And in this case I also want\n47:34 to have state final is equal to you are\n47:43 state age years old. Again quite a simple\n47:50 example easy to follow. That's why I've kept it as quite a basic graph. I mean\n47:55 it's not going to solve the world's problems or anything but it will help you understand.\n48:00 There is one logical error which I've put deliberately here. I want you to try\n48:07 to identify it. Okay. So the logical error in this\n48:15 case is the that once we've built our graph and everything what would have\n48:20 happened is we would have said hi to whoever uh we pass in let's say Charlie\n48:26 or something. So, hi Charlie. And we store that in the final uh attribute in the state, which is what we want. But\n48:33 here's where things get like start to be well logically incorrect. Once we\n48:39 finally get to our second node, again, we're updating state final, which you can do. You can repeat, you can um\n48:46 interact with these attributes at in in any node possible in all of the nodes.\n48:52 And you can do it as many times as you want. But notice this part. What's\n48:58 happening here is we've completely replaced all of the content we had before. So remember how we had hi\n49:03 Charlie? We've just completely replaced it with you are age years old. But we\n49:10 want both of them both of those stuff, right? So how do we get both of them?\n49:15 Well, again we just concatenate them. So we can have something like state\n49:21 plus state file. And there we go. Logical error should be now solved,\n49:27 right? Cuz now we have concatenated state final. Uh we're essentially just like adding on to uh we're preserving\n49:35 what we had before, right? Okay. Now let's get to the fun part. How do we\n49:41 actually build this graph? And really it's quite similar to the previous two\n49:46 graphs except there is one new thing which you're about to learn. So like always we use state graph to start the\n49:53 framework. So agent state and let's store it in graph. Again I could have had this name\n50:00 the width variable into anything. I've just kept it graph cuz it makes intuitive sense. Okay. Now we add our\n50:07 nodes. So we do graph add node. And for simplicity sake I'm just going to have\n50:13 the name as the same name as the uh function. Okay. So that way it'll just\n50:19 be easy to follow. So graph add node and second\n50:27 node. Second node. Cool. Okay. Now that we've added both nodes, we need to\n50:34 obviously s uh add the entry point and the end point, right? So we set the\n50:40 entry point like this. Again, quite self-explanatory because we wanted to connect to the first node, not the\n50:45 second node, right? So it should be start uh first node, second node, end\n50:51 point. How do we connect the first node and the second node together\n50:59 though? Hopefully you had an answer for that. Uh if you remember or recall from\n51:04 the previous section, theory section, there was an element in Langro called the edge. That's exactly what we're\n51:10 about to do right now. We're about to use edge and that was the new thing which I was talking about a few moments ago which you're about to learn. So how\n51:17 do we use it? Well you use graph edge add edge and if we can hi perfect. So\n51:25 again it's quite simple you use a start key and end key. So sim similar to entry point where but your in this case you\n51:33 need to pass two parameters. So the edge we want is between the first node and the second node right? Well that's\n51:40 exactly what we pass here. So first node and second node and like before we will\n51:48 just set the finish point at second node and we will compile this. Now how will\n51:53 this graph look like? Take a moment to try to think of how it will look\n52:02 like like that. Start point end point and these two notes are sandwiched in\n52:07 between. But now there is a edge. It should be called a directed\n52:12 edge if I'm being like quite picky. But yes, a directed edge cuz the flow of\n52:18 data or your flow of your state updates is from the first node to your second node. Right? Cool. So now that we've\n52:24 built that, let's again invoke this. So I've got this code ready here. Uh let's\n52:30 invoke it. Let's pass the parameter as Charlie and let's pass the age as 20.\n52:37 Cool. Print result. Perfect. Apart from the uh\n52:43 misalignment here which I can just change right now. Perfect. Okay. So now you can see\n52:49 it says hi Charlie you are 20 years old. Now obviously we could have performed all of this in one single node which we\n52:56 have been doing in the previous subsection but the obviously the aim was to be able to create multiple nodes\n53:03 right and handle um the state how the state progresses. So yes you one\n53:08 important thing which you've learned is obviously how to use the add edge method but another concept which you have\n53:15 solidified here is you can uh change these at these keys of your state at in\n53:22 at any point in time like as long as as however many times you want cuz remember\n53:29 here we've passed in state final um we implemented state final here we implemented state final in the second\n53:35 node if we had more nodes in the sequence. We could have done that again and again and again. And we also learned\n53:41 how to like one key logical error is sometimes a lot of people just accidentally replace uh their content in\n53:48 one of the attributes and that leads to a lot of logical errors. So always be mindful of that. And yeah, that again\n53:55 was quite simple, not too hard and hopefully the exercise which I'm about to give you solidifies this. Cool. So I\n54:03 will see you at the exercise then. Awesome. So now we will move on to the\n54:09 exercise for this third graph. And what I want you to do is really build on top\n54:15 of what we just covered. Instead of two nodes, I want you to build three nodes. Again, in a sequence, don't need to go\n54:22 too fancy yet. We will again three nodes in a sequence. And we will have you will\n54:29 need to accept the user's name, their age, and a list of their skills. So the first node will be specifically for\n54:35 personalizing the name field with a greeting. The second node will be describing the user's age. The third\n54:42 node will be listing all of the user skill in a formatted string. And then you'll need to combine this and uh store\n54:49 it in a result field and output that. And this should be a combined message. And the format I would like you to\n54:55 output is something like this. So let's say the name was Linda. And let's say Linda welcome to the system. You are 31\n55:03 years old and you have skills in Python, machine learning and langraph. Okay. And\n55:09 just as a hint for this exercise, I would you'll need to use the add edge\n55:14 method twice. So this will really solidify your understanding on how to build graphs in general. All right,\n55:22 cool. So once you've done that, again, answers will be on GitHub for all of the exercises. Once you have uh cross\n55:28 referenced and checked that you've done it right, I will see you in the next section where we build our fourth graph.\n55:34 All right, see you there. Welcome, welcome, welcome. Okay, I'm particularly excited for uh teaching\n55:41 you this graph, graph 4. Why? Because we're about to learn how to build a conditional graph. So for the very first\n55:49 time, we're about to implement conditional logic. And obviously we've\n55:54 done it in a previous exercise before but that was within a single node. This is how to implement conditional logic in\n56:00 the overall graph structure. And so we will be implementing conditional logic to route the uh flow of data to\n56:07 different nodes. We will be using the start and the end nodes to manage entry and exit points. We will be designing\n56:14 again using multiple nodes to perform different operations such as addition and subtraction. And we will be able to\n56:20 create a router node to handle decision-m and control the graph flow. So the main goal is really to you how we\n56:28 can use this inbuilt function which uh allows you to create conditional edges in langraph. All right, exciting stuff.\n56:35 I'll see you at the code. Okay, so let's actually code this\n56:41 up now and you'll see the imports are slightly modified this time. Again, type\n56:47 dictionary and state graph is there. But now I've also imported start and end point. Again, if you remember a few\n56:54 subsections ago, I told you there are multiple ways to be able to initialize the start and the end point. And this is\n56:59 another way you could. Arguably, this is the easier way, but um whatever. I don't\n57:06 really have a preference, but I'll teach you both ways regardless. Okay, let's import these. Successful. Okay. like\n57:13 standard procedure we will design we will um code up the uh the schema the\n57:19 state schema so class agent state and let's again type dictionary in this case\n57:27 uh uh I want to be able to pass in two numbers and pass in an operation so a\n57:33 plus operation and a minus operation one of those two operations now obviously I\n57:38 could have handled uh all of this within one single node But that's not the point\n57:43 here. I've kept it deliberately very very simple. So the main concept which you learn is how to uh implement\n57:50 conditional logic. Okay. So let's code the different uh keys\n57:56 which we require. So number one will be an integer. Operation will be in the string a plus or a minus. Uh number two\n58:05 will be an integer and final number will be an integer. the final number will be the result of either adding or\n58:11 subtracting the two numbers. Easy enough. We've done this multiple times now. Okay. Now, here's\n58:18 where things get interesting. Now, just a heads up. Initially, this won't make\n58:24 sense. But when we look at it from a bird's eye view and we look back at all the code in this subsection again, uh\n58:32 everything will start to click. So again, it won't make sense initially, but it will once we look at it. Uh\n58:38 again, don't worry. All right. So let's create our first node function. Let's call it adder. And it's again still a\n58:46 node. And we input the state schema. And we return the updated state schema and\n58:53 dock string again. But uh this time I'm just going to copy it from here. Uh it's\n58:59 tells exactly what it does. This node adds the two numbers. Uh and easy enough, we just do state final number is\n59:06 equal to state uh number one plus state number two. Okay. And we just\n59:14 return the state. Quite simple, right? And just\n59:20 like what we did with the addition, we need a node for subtraction as well. So def subtractor. Now uh I already\n59:29 implemented it to uh don't to not waste time but this node subtracts the two\n59:34 numbers. It's very similar to the previous uh node function. Uh it just\n59:39 subtracts these two numbers. Again yes you could be saying what if number one is uh smaller than number two it'll give\n59:46 you a negative result. It that doesn't matter. The main aim again was to implement the conditional logic not the\n59:53 um inner workings of each node. Okay. Okay. Now we built another type of node.\n1:00:00 Uh and we initialize it the same way but this time let's call this node decide\n1:00:06 next node. Let's actually give it a name which actually says what it does. Right.\n1:00:11 So again we use state agent state and we pass like this. Perfect. Okay. Now the\n1:00:19 dock string will be something like so. So this node will select the next phase\n1:00:25 of the graph or well next node of the graph I should say. Okay. Now we use an if statement and\n1:00:33 before I code something let's just try to map how this will work. This specific\n1:00:39 node will be at the start of our uh graph. So we will have the start node. We will have this uh this specific node\n1:00:46 we'll call it the router. and this router because it routes uh the next uh\n1:00:52 to the next node depending on what the state schema is at that point. So we will have the uh I will put an image up\n1:01:00 right now so you kind of get what I'm trying to say but we essentially will\n1:01:05 have the router decide whether we uh add the two numbers and subtract the two numbers and obviously this will be\n1:01:11 decided with the operation uh attribute right which you should see from here.\n1:01:16 Okay, let's code this up now. So this is not the hard part. If state operation,\n1:01:24 if I can spell if state operation is equal to equal to\n1:01:31 plus. Okay, if state operation is equal to equal to plus, we need to do a certain thing to\n1:01:38 pass it to the next node. Okay, now here's well your first guess could be\n1:01:45 okay. Well, we guess I guess just call this function, right? Not exactly. Not in langraph. You actually return\n1:01:54 uh return the edge. Now, we haven't described the edge yet, right? But for\n1:02:00 now, I will just say the edg's name is addition operation. So, addition operation. Similarly, if it's\n1:02:07 subtraction, we will do this like so. So just to reiterate we will uh you we will\n1:02:15 see what the um value is at the operation in the state schema. If it's a plus we call we will return the edge\n1:02:23 addition operation and if it's a subtraction we will use the subtraction operation edge. Again we haven't\n1:02:30 described or defined these two edges yet. That's what I was saying earlier. When we look at it from the bird's eye\n1:02:36 view later on in a few moments once we've built everything it will make much more sense. So stick with me for now.\n1:02:42 Okay. And runs perfect. Now we build the graph. And now here's the exciting part.\n1:02:50 So we again like normal standard procedure we use state graph to create\n1:02:56 the graph framework. So graph is equal to that. And let's add these nodes uh to\n1:03:02 the uh to our graph. So graph add\n1:03:08 node and let's say router. Okay. And again we will pass\n1:03:15 this decide next node. Perfect.\n1:03:21 Okay. Now I have another confession to make. Lots of conventions. I know this\n1:03:26 won't work. I know I haven't built the rest of the graph yet but this eventually will not work. And there is a\n1:03:34 subtle reason why this won't work. You know, it's mainly in this line. Add node\n1:03:40 router decide next node. The problem is with decide next node cuz oh, you can\n1:03:47 see that the dock string appears once we press uh the decide next node. But the\n1:03:52 reason this won't work is look closely at these three functions. What are we\n1:03:57 doing in these two functions that we're not doing in this? I'll give you a moment to try to analyze\n1:04:10 this. Okay. So, doesn't matter if don't worry if you didn't get that. The\n1:04:16 correct answer is we are returning this updated state in this one and this one.\n1:04:21 But in this node, we're not. We're just returning the edge. Subtle difference I\n1:04:28 know but that's how Lang graph works and you will see why they do it like that\n1:04:35 uh right now. So how do we deal with this? Now I obviously could have built this graph and then I would have shown\n1:04:41 you the error but then things would have just gotten messy. That's why from the get- go I have told you why this wouldn't work. So now that you know why\n1:04:48 this won't work, how do you fix this? Simple. You use this code lambda\n1:04:54 state. Now, if you have used lambda functions before, this is quite easy to understand. If you haven't, don't worry.\n1:05:00 All this is saying is your input state will be your output state. That's it. In\n1:05:07 even more simpler words, think of this as a pass through function. So, what it's saying is your\n1:05:14 input state will be passed, your state will be inputed and your output will be\n1:05:21 the exact same state. Now, why is it the exact same state? because you're not changing the state at all. You're\n1:05:28 comparing stuff here, but you're not assigning anything. There's a difference between comparison and um and\n1:05:34 assignment. Right? Again, even in this one, you're just comparing to see whether the operation is a minus, but no\n1:05:41 assignments been made at all. In fact, there's been no changes to this state\n1:05:47 whatsoever. That's why we can use this as a pass through function. Now, hopefully that made\n1:05:53 sense. Okay, let's continue. Again, we will get a lot more practice. Don't worry, this\n1:05:59 is the first time you're seeing this. Okay, so now we will add the edge. And\n1:06:05 this is just the normal edge we did last time. So, we will need the start key. And now here's how you initialize\n1:06:11 differently. Remember how we used to do set entry point and set finish point? We don't do that anymore. Uh we use start\n1:06:19 the keyword cuz that's what we imported. Make sure to import it if you do it this way. uh you use start and end. So your\n1:06:26 start will be a start point and your what do you want the start to be connected to? Well, we want it to be\n1:06:32 connected to the router. If I put this in quotation marks, perfect. Now, why not add node or\n1:06:38 subtract node? Well, think again. Refer back to that diagram which I'll show in\n1:06:43 right here. We if we connected the start point to\n1:06:48 the the add node or the subtract node, well then what's the point of the router in the first place, right? The whole\n1:06:54 point was the router decides what the inputs are and then from there it branches off to the correct node. So\n1:07:01 that's why the router needs to be the first node we uh connect our start point to. Cool.\n1:07:07 Okay. Perfect. Now we add the we now implement the main the new thing which\n1:07:14 we are going to learn in this section is graph dot add conditional edge. So graph\n1:07:21 dot add conditional edges. Now again wow looks really\n1:07:26 confusing but it's actually much more simpler than it looks like. So the first uh part is your\n1:07:33 source which you can see here as well. So the source will just simply be the name of the node. And what's the name of\n1:07:40 the node which we want the conditional edge to be? It's the router node, right? So that's going to be the source part.\n1:07:47 Perfect. Now if you look here, it's asking for a path. What's the path you would like it to do? Now before we\n1:07:54 implement the path, we obviously need to per uh imple uh tell it what action what\n1:07:59 what action it needs to do. And that's where this node will come in the decide next node part. So we pass that as the\n1:08:04 second parameter. So that's the path. And now we implement something\n1:08:10 called the path map which you should have briefly saw\n1:08:15 here. Uh there path map. So we've implemented the source which is the\n1:08:21 router. We've implemented the path which is your uh decide next node function. Uh\n1:08:27 again don't need to worry about hashable runnable any and all of this stuff. Okay, it's you don't need to over\n1:08:33 complicate it. Now it's time for the path map. Okay, so now your path map will be in a form of a dictionary. And\n1:08:40 remember how I said earlier that we had implemented addition operation and subtraction operation. These were edges.\n1:08:46 So now we're about to implement those only. So we're about to create two new\n1:08:52 edges here. Let me just write this code up for you and then it will make sense.\n1:08:57 Give me one second. Okay, so there we go. Now what is this\n1:09:05 code actually saying? Well, this is in a format of edge and\n1:09:12 node. Now the starting point of this edge will obviously be this router node and it's telling us where it will\n1:09:18 connect to. This uh visualization will be it will be it'll be much easier to\n1:09:24 visualize when I actually show you the graph. Don't worry. But for now, addition operation and subtraction operation is the edge. And the two nodes\n1:09:31 are add node and subtract node. Right? Okay. Uh lastly, we now we're now at the\n1:09:38 point where we need to create the end point. But obviously, we if you look back at this diagram which I've shown on\n1:09:44 the screen right now, you can see that the we need two edges to connect to the\n1:09:51 end point, right? We need to we need an edge from the and node and we need an edge from the subtract node. So we can\n1:09:58 add two edges like this. graph edge. Uh we uh start at the add node and\n1:10:05 then we end at the endpoint. Again similar subtract node and endpoint. And then we just compile this. So app is\n1:10:11 equal to graph.compile. Cool. No errors. Okay.\n1:10:18 Now here comes the most exciting part. Again try to visualize what this graph\n1:10:23 will actually look like. Okay. So it should look something\n1:10:29 like that. Probably slightly different to what you initially anticipated but\n1:10:36 that's okay. We again have a start point. We have the router and we have the our two nodes add node subtract\n1:10:42 node. And notice remember when I said addition operation and subtraction operation are the edges names. Well,\n1:10:48 here it is. Addition operation and subtraction operation. It's telling us uh what the which direction to go into.\n1:10:55 Do we go how do we go to add node? Well, we use the addition operation. How do we go to subtract node? Well, we go to the\n1:11:01 subtract operation. And then obviously we create these two edges, these two to connect to the\n1:11:10 endpoint. Awesome. So, we will once again look at it from a bird's eye view. But let's actually invoke this graph to\n1:11:16 see what happens. So let's use this piece of code. So what\n1:11:23 it's saying is it's defining number one as 10, operation as minus and number two as five. So because we've used\n1:11:30 subtraction, the final number should be 10 - 5 which is five. And we've printed\n1:11:36 the results and the answer is like such. Uh number one is equal to 10, operation\n1:11:41 is equal to minus, number two is equal to 5 and final number is uh five. Obviously the way I've invoked it is\n1:11:47 slightly different to what I have done before. Again, this is another way you can invoke. Okay, so not too hard. But let's\n1:11:56 just go through everything one more time to solidify everything. Okay, so we\n1:12:02 imported everything. We created the state schema using agent state and a type dictionary. Then we created our\n1:12:07 three different nodes which is the add node, subtract node and the decide next node. And this is in within the decide\n1:12:15 next node. You can see that if the operation is a plus, it goes to the addition operation edge which is this\n1:12:22 edge. And if it's subtraction operation, it goes to this side. And this is how we\n1:12:28 built the graph. We added the nodes. We added the edge from the start point uh to the router. And then we added the\n1:12:34 conditional edge. the new thing which we've learned in this section uh which is we uh reference router and we use the\n1:12:40 edge node format. So the edge will be addition operation uh to add node then\n1:12:47 it will be subtraction operation to subtract node. Visually speaking it will be addition operation to add node\n1:12:53 subtraction operation to subtract node. Now, I know this will be quite confusing at first and don't worry, it took me\n1:12:59 quite a while to understand this myself as well, but hopefully the exercise I've given you will really be able to help\n1:13:05 you understand this much better. Okay, so I will see you at the exercise\n1:13:11 then. Awesome. So, let's actually find out what the exercise is for this graph. So, you need to make this monstrosity.\n1:13:20 Now at first glance it looks terrifying but if you analyze it a little bit closer all it is is what we just coded\n1:13:27 twice. So we coded this and we need to replicate it once more. So in essence\n1:13:33 you need to actually input four numbers and two operations and you need to output their final results. For example\n1:13:39 number one, number two, number three, number four and the respective operation and the respective results. Right? So in\n1:13:44 this case we would have to do 10 - 5 which is 5 and 7 + 7 + 2 aka 9 and those\n1:13:51 two numbers should be outputed. Now the reason I gave you this exercise to do is because this will really solidify your\n1:13:57 understanding about conditional edges which will really be important for the next few next graph and the next AI\n1:14:04 agents we make. Okay. So once you have uh completed it by looking and cross\n1:14:09 referencing the answer on GitHub, I will see you in the next graph.\n1:14:15 Okay. All right. Well done. We're almost at the end of this section and we're about to build our final graph aka graph\n1:14:22 5. Now we've learned quite a lot about Langraph and its internal mechanisms. And this will really help us in the next\n1:14:29 section where we finally build the AI agents you were looking for. Now in this\n1:14:34 section in this subsection sorry we're going to be learning an important concept. There's still one more concept\n1:14:39 we haven't learned and that's about looping. So we're going to be creating well a simple looping graph. Now I kept\n1:14:45 the objectives to be quite small here. There aren't that many objectives. It's essentially implementing logic uh which\n1:14:52 involves looping uh to route the flow of data back to the nodes. And we're going to be creating a single conditional edge\n1:14:58 which you know how to do in the previous section. Regarding the previous section, however, I know the exercise. Please do\n1:15:05 complete that exercise. That exercise will be probably the hardest exercise you would have done until this point.\n1:15:12 So, don't worry if you didn't get it. If you did, great job. You're doing really, really well. But if you didn't get it,\n1:15:18 look at the GitHub. Try to compare where you went wrong. Remember, in Langraph, there's more than one way of building\n1:15:24 the graphs. Make sure the graphs are well built and it actually functions.\n1:15:29 And if you want an extension, try to make it even more robust than it is. All right, but back to this now. Final\n1:15:35 graph, I promise. The main goal really is to code up the looping logic. So,\n1:15:40 with that out of the way, let's build a final code for this section. See you\n1:15:46 there. Awesome. So, final code we have to build for this section. And here we\n1:15:52 go. So, graph 5 squ. Now, I'm going to take a slightly different approach this time. And I'm actually going to show you\n1:15:58 the graph we want to end up building from the get- go. And there's a reason I'm going to start that from now so we\n1:16:04 get in good practice. The reason is once you finish this course and actually\n1:16:09 start either making your own AI agentic systems for someone else, for your clients or for yourself like make your\n1:16:15 own JavaS system or whatever. You obviously need to plan how it works, right? You need to see okay, what nodes\n1:16:22 do I need? What edges do I need? Does is this does this need to be a conditional edge? where's the start point going to go, end point going to go etc etc and\n1:16:29 you can either do that via pen and paper or software like I've used but point is you need some sort of blueprint and\n1:16:38 that's how really it works in the industry as well um you can you will obviously have a blueprint and then from\n1:16:44 there you will code up the graph similar to how a UI designer for example uh renders um their UI designs and then\n1:16:52 sends that off to a software developer who uh well develops the application forwards. Right? So that's the habit I\n1:17:00 want to start uh creating with you. All right. So this is the graph I want to\n1:17:07 build in this section. So there's obviously going to be a start and end point. And this really should be mostly\n1:17:13 familiar except for this loop. So there we're going to create a simple greeting node and another node which is called\n1:17:18 the random node. So in the greeting note I essentially want the user to have uh\n1:17:24 stated their name and it should output a simple hi there your name and then the\n1:17:31 graph progresses to the random node and in the random node I essentially want to\n1:17:36 generate five random numbers. Okay, now just as a heads up, yes, this graph in\n1:17:44 industry would be completely useless. I know, but I've deliberately kept it simple again so you know the\n1:17:49 fundamentals. Like this loop is could have easily been avoided and transferred\n1:17:55 into a for loop for example, right? Like I could have had a for loop within this node and ran it five times to generate\n1:18:02 the numbers. I get it. But this is again kept deliberately simple so you actually understand the concept. Okay, cool. So\n1:18:09 let's the usual inputs and the only difference is this time I've also imported random but if you have used\n1:18:15 Python before quite a lot you would have come across this library right okay so\n1:18:20 let's start with our agent state so class agent state type\n1:18:26 dictionary and what's the first thing we're going to need well let's see we\n1:18:31 have the start point do we need anything any keys that no for greeting note what did I say I want uh I wanted the user to\n1:18:38 be able to input their name. So, we need a name attribute or a key. And then for\n1:18:43 the random number, a random node, we need some form of um a list to like\n1:18:51 actually store the numbers. So, we have number and list\n1:18:56 int. Okay, cool. And one more thing, look at this loop. How will we actually\n1:19:02 know when to stop? We need some form of counter, right? So, counter int.\n1:19:08 Perfect. Now, obviously, just as a heads up, when you do go on to make your AI agents and everything, you're not going\n1:19:15 to know what attributes you need right from the get- go, unless if you planned it like extremely extremely well. But\n1:19:22 chances are you won't get it. But don't worry, iteratively well, you'll obviously be better at speculating what\n1:19:29 attributes you need through practice. But you can obviously do iterative development as well, right? Okay, cool.\n1:19:35 So now let's actually build these nodes. Okay. So let's start off with the\n1:19:40 uh greeting node. So how we normally define uh a function. So def greeting\n1:19:46 node, we obviously need the agent states like such. Perfect. And the dock\n1:19:55 string. But uh luckily for me, I've already got that here. So I don't need to do it again. I know it's boring, but\n1:20:01 habits. Now let's update update the uh name uh key. So how do we do that? Well,\n1:20:10 you should know by now state name is equal to let's say something like hi\n1:20:16 there. State name. Perfect. So what will this do? I input a\n1:20:22 name and it'll replace that name with a string of hi there this person. Now\n1:20:27 let's also initialize the counter variable here. Now why am I doing that?\n1:20:32 Let me just first write it and think about this. Okay. Now, obviously I'm changing I'm\n1:20:40 setting like the value. So, I will need to have passed in like an valid integer\n1:20:45 when I am passing the uh value when I'm invoking the graph, right? But here's\n1:20:52 the thing. What if I pass in minus2 for example? Well, as the counter value, as the\n1:20:58 initial counter value, if this line wasn't there, well, it would have just kept on incrementing until it got got to\n1:21:05 five cuz I want to have five numbers. But if it starts at minus2, well, it would end up giving me seven numbers.\n1:21:12 Now, that's not robust, right? So, this basically wipes out whatever rubbish\n1:21:18 integer the user even inputs. If they had put zero, well, okay, we replaced it to zero. If they put like minus 20\n1:21:25 because they're greedy or something, then we have made sure to like set that back to zero. So, so just a way to make\n1:21:31 it robust. That's all. Uh, return state. Okay, cool. So, now let's create our\n1:21:38 second node which is a random node. So, we can say random node state agent state\n1:21:46 agent state. Perfect. Dog string. Again the dog strings will be useful. I\n1:21:52 promise in the next section they will. So this generates a number random number\n1:21:57 from 0 to 10. Now this piece of code here\n1:22:03 essentially appends the appends the randomly generated number to the number\n1:22:09 list. Okay, that's all it does. And what else do we need to do in this node? Well, we need to increment the counter\n1:22:15 value, right? So C uh plus equals to one. So this will\n1:22:22 increment uh the value by one and then we just return the state. Okay, cool. Now here's where\n1:22:31 we're how we're going to implement the looping logic. Now just a warning here and please listen to this. Like in any\n1:22:37 software development uh program or programming language G2, there's more\n1:22:42 than one way of coding up an application, right? Same goes with Langraph as well. There is multiple multiple different ways of coding like a\n1:22:50 looping code like this graph. I'm going to be showing you one of them. I obviously can't show you all of them cuz\n1:22:56 there it's just time constraint, right? But obviously the more you practice the\n1:23:01 uh uh better ways you'll more efficient ways you'll find, right? But the way I'm going to show you is pretty efficient as\n1:23:07 well. Don't worry. Okay. Now, you might have speculated that I'm going to create\n1:23:12 like a router node. It's close. I'm not going to create another router node. You\n1:23:18 can see in the graph the uh the client let's say the client wants this graph. The client doesn't want another router\n1:23:24 node here. So how do we go about that? Well, we could create a conditional edge. How do we do that? Okay, let's\n1:23:31 begin that. So let's write a new function say defaf should continue uh state agent\n1:23:38 state agent state and um let's create this block\n1:23:44 string um function to decide what to do\n1:23:49 next something like that. Okay cool now here's where we set our looping logic\n1:23:55 and this should look quite familiar to you\n1:24:00 now. Perfect. So let's run that. Okay. So what have I written here? Well, if\n1:24:05 the counter value is less than five because we're starting with zero, right? So 0 1 2 3 4. That'll be five values. Um\n1:24:12 I've also written a print statement so like we can keep track of um um the\n1:24:18 progress. Also whenever I'm writing the code as well when you're uh coding with me or doing the exercise, it's really\n1:24:24 helpful to print uh statements uh like put in print statements everywhere. Or\n1:24:29 you could also use break points as well. So you know uh where to where the code failed if it\n1:24:36 fails. Okay. So here we return the loop a loop edge and the exit edge. So\n1:24:44 obviously we have the loop edge and this will be the exit edge. So everything is going to plan so far but um so far is\n1:24:50 the key. You never know, right? Okay. Uh just as a heads up though, I want to\n1:24:55 show you this. So this is how the trajectory should follow. We start at the greeting node. Why? Cuz we obviously\n1:25:02 go from the start to the greeting node. And then we enter the random node. And we enter the random node and exit it\n1:25:08 five times. So 1 2 3 4 5. Why five times? Because we want five random\n1:25:14 numbers, right? By then this if statement will uh well it won't work. It will fail. So we will go to the else\n1:25:20 statement and return exit. And if we return to exit, we'll go to the end node. Uh okay. endpoint. Okay, so that's\n1:25:28 how the general gist is. Okay, let's quickly make this graph. So you should know how to initialize a graph agent\n1:25:35 graph and let's just add these nodes. So we have our two nodes which are\n1:25:43 here greeting and random which is exactly what we wanted, right? Greeting node and random node. Perfect. Okay. And\n1:25:50 now we're going to add an edge between greeting and random. Uh why? Because\n1:25:56 well I've created this edge. You see this edge greeting node and random node. This edge that's the edge I've created.\n1:26:03 Okay. Now I'm going to create the um the conditional\n1:26:08 edges which is done through here and I've written some comments here\n1:26:14 as well. So uh there will be the source node which is the random. So where I\n1:26:21 want the conditional edge to start from and then the routing function or this tree I should have really written action\n1:26:27 here because is the action I want to perform the underlying mechanism or function which is going to which we're\n1:26:33 going to um determine which edge to use and that's uh implemented by the should continue function right and notice how\n1:26:40 again these two edges are the same edges here. So if the loop is uh the one which\n1:26:47 um uh is outputed then we need to go back into its random the random node\n1:26:54 which we've generate uh which we put there and if it doesn't we go to the end part. Okay and then obviously we set the\n1:27:01 entry point. Okay. So again you don't have to\n1:27:07 set the exit point here uh or the finish point because we've already done it using end here. Okay, perfect. And then\n1:27:14 we just compile the graph app is equal to\n1:27:20 graph.compile and okay, it compiled. That's a good sign. But let's see if we\n1:27:26 have got our graph to be the exact same. Now I'll put the graph image here\n1:27:32 so I don't keep scrolling back and forth. But you can see we have the start point and the end point. We have the greeting and the random. And then we\n1:27:39 have our two condition edges. So we have the loop going back into the random node\n1:27:45 as we wanted and the exit which you can see. So take a moment and you can see compare and contrast. Okay, let's\n1:27:54 continue. Okay, now I have this code. So I've given a name my name uh a\n1:28:01 r um a completely brand new list and I've set counter to minus one. And as you can see it enters loop\n1:28:08 one, loop two, loop three, loop four because these are print statements we printed. Uh it says hi there v which is\n1:28:15 my name. Uh number 10 21026 just randomly generated and you can see the counter value is five. Now remember what\n1:28:23 I was saying over the counter. We set the counter value to zero here to make it more robust. If we had not done that\n1:28:28 well it would have generated six times. And now I can set this to minus 100. it will still obviously give me different\n1:28:35 random values but um the code is largely the same. So that's really the way which\n1:28:42 I personally use to create loops in langraph it's pretty easy right but um\n1:28:49 obviously with practice you might even find some other ways if you do find other ways like obviously uh do let me\n1:28:55 know uh there's more than one way again you can send me a message on LinkedIn or Instagram or whatever but um yeah so\n1:29:03 this is finally finally uh we have implemented the code for our final graph\n1:29:09 of the section So just complete the graph 5 exercise please and yeah we should be good to go\n1:29:16 to make AI agents. So I'll see you at this codes exercise. Okay\n1:29:22 cool. Okay good job on that. Now for the exercise for this last graph uh you need\n1:29:28 to implement this graph on the right. So you need to implement an automatic higher or lower gain. So for context,\n1:29:36 you need to set the bounce which we can guess between 1 to 20 integers of course and the graph has to keep guessing where\n1:29:43 the max number of guesses is 7 where if the guess is correct it stops but if not\n1:29:49 we keep looping until we hit the max limit of seven. Now please note we don't have to pass any inputs the actual graph\n1:29:57 should automatically guess by itself. So there should be no human in the loop human intervention at all. So each time\n1:30:03 a number is guessed the hint node aka this node should say either higher or\n1:30:08 lower and the graph should account for this information and guess the next guess according accordingly. So for\n1:30:15 example the input should be something like the player name student. The guess should just be an empty list cuz we're\n1:30:20 initializing the list. Attempts should be set to zero and the lower bound and upper bound should be 1 to 20. Now the\n1:30:27 reason I've also passed these as inputs is because uh if you wanted to expand\n1:30:32 this to maybe 1 to 50 numbers or whatever you can. It's quite easy to do that. So just as a hint uh it will need\n1:30:40 to adjust it its bounds after every guess based on the hint provided by the hint though. So once you've completed\n1:30:47 this exercise you would have fully reinforced uh your understanding about loops in langraph. So once you've\n1:30:54 completed this, cross reference it. Cross reference the answers on GitHub. I will see you in the next section where\n1:31:00 we finally begin AI agents. See you there. Okay people. So welcome back to\n1:31:08 this brand new section where we actually start learning about AI agents. Now we\n1:31:13 finally are upgrading our ability in Langro. I even upgraded my clothing sense. Not really. But this is exciting\n1:31:21 times cuz we actually finally build AI agents. So, we're going to build a lot of AI agents in this section. And\n1:31:28 starting off with the first agent. Well, technically it's not really an agent, but I just named it that because it\n1:31:34 sounds cool. But um technically it's not though. But let's see what we're going\n1:31:40 to actually learn in this section in this subsection. So, we're going to build a simple bot. That's it. And these\n1:31:46 are the objectives. So we're going to define a state variable uh state structure which we're going to have a\n1:31:52 list of human message objects and I briefly uh me uh mentioned what a human\n1:31:58 message was uh a long time ago in the course. Uh what it is it's well it's in the name it's a message prompt which is\n1:32:05 given by the human aka us to the AI. Uh we're going to initialize the GPD40\n1:32:12 model for this uh using lang chain's chat open AAI uh uh library. Uh we're\n1:32:17 going to send and handle different types of messages. We're going to build and compile the graph of the agent. But the main goal really is how we can integrate\n1:32:25 LLMs into our graphs. So what is this sort of graph we actually going to end\n1:32:31 up building? Now it's very very simple. It's going to look like this. And yes, this looks exactly like the graph we\n1:32:38 made in the uh first ever graph we actually ever made. But um the functionality will obviously be\n1:32:44 different cuz now we're actually integrating LM. So exciting stuff people. Uh okay, I will see you at the\n1:32:50 code then. All right, coding time. So now we first code our well we code up our very\n1:32:58 first AI agent aka the simple what and um I've already imported all the\n1:33:03 necessary libraries we'll need uh to not waste time. So while you're uh coding these up as well and copying these I'll\n1:33:10 also briefly explain what these are so we're at the same level. Okay, so we've already imported type dictionary and\n1:33:17 list many times before but um these two we haven't sorry these two the lang\n1:33:23 chain codon messages import human message so I briefly mentioned this in the intro of this section of the\n1:33:30 subsection what a human message is right and this is the library we get it from and similarly we're going to be using\n1:33:37 openai's lms so that's why we're going to use chat openai from the lang chain open aai uh library uh the\n1:33:44 langraph.graph. Uh these we were familiar with and this is the env. Now\n1:33:50 just a few points. You could have been saying okay wait hold on I thought we\n1:33:55 were about to do a langraph stuff. Why is the lang chain stuff here? Now you must know that langraph is built on top\n1:34:01 of lang chain and lang chain already has the sophisticated libraries right so why\n1:34:07 not actually use them that's how langraph is designed it's designed to use the robust sophisticated libraries\n1:34:14 which lang chain offers right so no I'm not a trader we're still doing langraph stuff but we're also using leveraging\n1:34:21 lang chain strengths as well okay and um now this env file now it's okay if you\n1:34:27 haven't ever um encountered av file before. Essentially, it's just a file used to store secret stuff like API keys\n1:34:34 or configuration values. So, it's really there for security purposes. Now, I have\n1:34:40 my own um file stored in my folder structure uh\n1:34:45 so that you don't see my API key uh because if you do then I would go bankrupt. So, that's why. Now, you might\n1:34:53 also be wondering why do we need an API key here? We need the API key because\n1:34:58 we're doing calls to an external LLM. If we were using our own LLM like through\n1:35:05 OAMA, then we would um not have an API key, right? We would just use like the\n1:35:10 Olama library integration with lang chain. So because we're using charges,\n1:35:16 we need an API to communicate with the LLM in their cloud servers. Cool. So how\n1:35:21 do we actually load this? So to load our um API, we just use a simple Python uh\n1:35:28 code load. Env. All right. So now that we're at the same level, let's actually code up our AI agent. Cool. So let's\n1:35:36 define the state like we always do. So this time class agent state type\n1:35:42 dictionary. Perfect. Okay. Now what are the attributes we need in this section\n1:35:48 uh in this uh state? Well really just one the messages part right so messages but what form will it be well it will be\n1:35:55 in the form of a a list of human messages right so we'll have list human\n1:36:01 message why because we when we invoke the graph we're inputting human messages\n1:36:07 right so to tell the large language model that this is a human message I i.e\n1:36:12 Uh this is a message from me the user aka human right. Um we need to actually\n1:36:18 mention human message that it's a human message type. Cool. Okay. So now we\n1:36:24 actually initial initialize the large language model. So we just write lm is equal to chat openai. And now we specify\n1:36:32 what model we want. Now I'm going for GPD4er. Now yes there's also chat uh\n1:36:39 anthropic. I think there's chat oama. Um there's a lot of like in-built um\n1:36:45 libraries which lang chain offers which is great. Personally I've used chat openai a lot. I've also used chat\n1:36:52 anthropic a lot as well. Uh personally I like chat openai cuz it's just really simple to use. I've also used tried well\n1:36:59 tried to use chat oama before but really there's some difficulty in integrating\n1:37:05 it with lang. So that's why I've opted for openi. And if you're worried about financial cost, don't worry, it's\n1:37:11 extremely cheap. Uh if you want, you could also go for the GPD 40 mini model as well if that's a concern. But trust\n1:37:18 me, it's extremely cheap. Like the input tokens, output tokens is like in like\n1:37:24 tens of pennies for like a,000 tokens. So really, really cheap. Okay. So now\n1:37:29 let's actually define our node through our function. So process and we obviously define the\n1:37:36 state and then return the state like so. Perfect. Now\n1:37:42 how do we actually call the lm? Now lang chain and the langraph team really like\n1:37:48 using the word invoke. You might have noticed that to call a graph or like to make the graph run we've used invoke.\n1:37:54 Similarly to run the lm we use invoke as well. So we okay let's store the\n1:38:00 response we get in a variable. So uh lm.invoke and what do we invoke? Well,\n1:38:06 you can see from the uh hints here that it requires an input of language model input. What's that basically saying is\n1:38:13 what what what do you want the LM to do? Right? What's your question? Now what is our question? Well, that's in the\n1:38:19 messages. So we write state messages. So what will happen here is as soon as I've\n1:38:24 written state messages, let's say I have written hi or whatever uh we will pass\n1:38:30 this to the LLM through the invoke method. The LLM will then generate a response from its cloud server through\n1:38:37 our API and it'll get it will give us back the um its response and then we'll\n1:38:43 store it in the response section uh the response variable. Cool. And um let's\n1:38:48 actually print this like so and return the state like\n1:38:55 such. Okay, done. Now we obviously need to create the graph like such.\n1:39:02 Okay. So uh what is it saying? Well, it's saying that there is we've created\n1:39:08 a node process which is that which where the action is the process function. The\n1:39:14 add we've added an edge. We've added an edit from the start to the end node end point and we've compiled the graph.\n1:39:20 Okay. Um yeah. So let's now ask the for\n1:39:25 the user input. So user input is equal to input. We'll say enter\n1:39:32 something. And now we will invoke the agent cuz we need to invoke the agent of\n1:39:39 course because we're creating a graph, right? And the graph is well like agent\n1:39:44 in this case. Cool. Let's actually run this code now. So, Python\n1:39:50 agentbot. py and perfect. So, enter. Let's say\n1:39:57 hi. The AI message was hello, how can I assist you today? Now, I can reassure\n1:40:03 you I did not pre-code this or hardcode this. This is the actual LM. Let's run it uh one more time.\n1:40:10 Let's come up with a different message like who are\n1:40:15 you and it'll say I'm an AI language model created by open AAI called chat GBT. So you can this basically pretty\n1:40:22 much confirms that yes this is GBT uh in the background. Okay, but\n1:40:27 um why why just stick to one message, right? Why not uh be able to run\n1:40:33 multiple message like asking multiple messages kind of like a chatbot, right? So this is the code which does this and\n1:40:39 I'll walk you through this what's happening here as well. So uh like before we input our query and now we\n1:40:47 basically say keep iterating through and as soon as the user has said like exit\n1:40:52 or something then uh well you exit the while loop and that basically signifies that well you don't want to talk to the\n1:40:59 ailm anymore. So let's have get run this. So python agentbot\n1:41:05 py. Okay let's say hi again. Hello how are you? But now we can run it again.\n1:41:11 It's just a simple y loop. It's nothing groundbreaking. So like who made you? Okay, perfect. What is 2 + 2? 2 + 2\n1:41:20 equals 4. Okay. Uh let's say now, hi, I\n1:41:25 am Bob. Okay, now watch this carefully. I'm\n1:41:32 about to ask what did I just well or I should say what is my\n1:41:39 name? I'm sorry, but I don't have the ability to know your name or any personal\n1:41:45 information about you. Why is that? Why didn't it know what my name\n1:41:52 is? Well, even though I clearly specified it. So, let's quickly\n1:41:57 exit. Okay, now this is important. Nowhere in the code have we actually\n1:42:02 created some sort of memory. That's why I called this subsection simple bot. And that's why I\n1:42:09 kept on saying AI agent because it's not even an agent yet. Uh it's just a simple\n1:42:14 like the most basic LLM wrapper you can possibly have. But at least now you know\n1:42:20 how to actually integrate um LLMs in your graphs, right? And it's\n1:42:26 pretty straightforward. You just you um you just uh embed them within your functions and then your functions\n1:42:33 obviously act as the actions in your notes. And that's it. It's quite an easy piece of code. Like it's only what 29\n1:42:40 lines or 25 lines give or take. Uh but yeah, pretty simple. Um I don't think\n1:42:46 there'll be any exercise for this cuz well there really isn't much to do with this. So I will see you in the\n1:42:53 introduction for the second AI agent we're going to build. Okay. So I'll see you\n1:42:58 there. Cool. Cool. Cool. Okay. So now we're going to build our second AI system. And we're going to try to fix\n1:43:05 the problems we faced in the last uh AI system we built. And what was the\n1:43:11 problem? Well, the problem was it doesn't remember what we in what we had said before, right? Why? Cuz we were\n1:43:18 calling separate API calls. So now we're going to try to create a chatbot with some sort of memory. That's why I\n1:43:24 included the brain emoji here. So let me walk through the objectives for this uh subsection. So, we're going to use\n1:43:30 different message types in particular in particular the human message and the AI message. We're going to maintain a full\n1:43:37 conversation history using both of these message types. We're going to particularly use the GPD4 model again\n1:43:44 using the lang chains uh chat open AI library and overall we're going to\n1:43:49 create a sophisticated conversation loop. So, what is the main goal goal of this um subsection? It's really to\n1:43:56 create a form of memory for our agent. So if you're ready, let's go to the\n1:44:02 code. All right, awesome people. So let's begin coding our simple chatbot\n1:44:07 then. Okay, so like last time, I've already imported all of the uh necessary\n1:44:12 libraries and it's largely this exact same except now I've added two more uh\n1:44:17 stuff. So the first is the AI message and I explained this in the introduction of this subsection why we need the AI\n1:44:25 message. And I've also imported the union type annotation. Now the union\n1:44:30 type annotation is something we covered in the first chapter. So if you if this is the first time you are looking at it\n1:44:35 or hearing about it, I would recommend you going to the first chapter really understanding and watching the first two\n1:44:41 chapters. They're quite short to be honest and then coming back. Okay. Now\n1:44:47 that being said, let's actually begin the uh coding then. Okay. So like always, we define the state. So class\n1:44:55 agent state uh typed dictionary. Perfect. Now last\n1:45:00 time what did we define this as? Again we're only going to have messages again but uh last time we had list human\n1:45:08 message. Okay so that was what we had defined as our agent state\n1:45:16 previously. Now this time we also want to include the AI message as well. We're building a more sophisticated chatbot.\n1:45:23 So how do we do that? Well, one way or the naive way is to really have it as\n1:45:30 messages AI list AI message or something like\n1:45:35 that. Something like that. And don't get me wrong, this is still a valid approach. You can still build your graph\n1:45:41 and everything like that, but um I think it's a bit longer. So let me tell you\n1:45:47 another way which would actually be better. So remove this. Instead, let's\n1:45:53 use the type annotation union like this. So, union like so. And let's include AI\n1:46:02 message. Now, what has this done? Essentially, let me first tell you about a bit about human message and AI\n1:46:09 message. Human message and AI messages and like all of these like different structures are actually data types in\n1:46:14 Langraph and Langchain. That's what the developers of these libraries have got them to be. And um when I write union\n1:46:23 human message AI message then that basically allows me to store uh either\n1:46:29 human messages or or AI messages in this uh key in the state the messages. So\n1:46:35 that's what that literally means in a nutshell. Now, one important thing which I want to mention is this. All of these\n1:46:42 AI agentic libraries like Langchain, Langraph, Crew AI, Autogen, they're all\n1:46:48 great, but um you really can make your own AI agentic system by writing just\n1:46:55 Python functions. You don't even need to use a library. Now that being said, I\n1:47:01 would still recommend using these libraries, especially Langraph because Langraph, well, because it's a personal\n1:47:07 favorite, no bias at all, but um it's Langraph really allows you to control\n1:47:14 much more than other libraries would. Obviously, not as much control as if you\n1:47:19 were writing the Python functions yourself and everything, but I think it's a good balance of how much control you have and how much uh unnecessary\n1:47:26 jargon you need to write. Because think about it, think about how much of um this unnecessary code which you would\n1:47:32 have had to write else otherwise uh langraph and lang chain support. So that's why I highly recommend using\n1:47:39 these libraries and everything. So again human message and AI message are data types inbuilt data types within uh lang\n1:47:46 lang graph and lang chain. Cool. Okay. Now let's again initialize the large\n1:47:52 language model as we did last time. And again we're only we're using GP4. Okay, now we're going to create our\n1:47:58 node. Again, it's going to be the exact same graph structure, by the way. So,\n1:48:03 state agent state, but obviously the actions we perform will be slightly\n1:48:08 different. Now, um let's write a dock string. This node will\n1:48:15 um this node will uh do solve the request you input\n1:48:23 something. Dog strings aren't really needed for this AI agent or this subsection because we're not going to\n1:48:29 use them. But um again, good habit. Okay, cool. Let's invoke\n1:48:36 this. So what have I done here? This is exactly the same code which we did in the previous subsection. The l we invoke\n1:48:42 the lm uh with the state messages. And what are the state messages? Well, it's could be either human message or an AI\n1:48:49 message. It's a list of those. Awesome. So now we write this piece of\n1:48:56 code. Okay. State messages.appen AI message content equal to\n1:49:02 response.content. What on earth is happening there? Okay. Let's break this down. Response. Well, that's just\n1:49:08 extracting only the content part of the response aka the response being the answer or the result after we make the\n1:49:15 uh API call from the large language model. And it only extracts the content. So it only extracts like the important\n1:49:21 stuff, right? It removes all the unnecessary jargon which comes with it like the amount of tokens you use and\n1:49:26 all that. It removes that and that's uh gets stored in that gets converted to to\n1:49:32 an AI message and that's appended to our state messages um in the state. Simple.\n1:49:39 Okay. Uh now obviously to make it look pretty in the terminal we're going to\n1:49:45 print this and then we're going to return the state. That's it. That's how simple it was.\n1:49:52 Okay, so now we're going to create this exact same graph. And that's why I've just copied and pasted it because it's a\n1:49:58 time waste of me rewriting the code in front of you again and again. So we can just reuse the same code because it's\n1:50:04 the exact same graph uh graph structure as the previous subsection. Cool. Okay,\n1:50:09 now we're going to now here's where it actually starts working differently.\n1:50:14 See, last time we didn't have this the conversation history. really this is\n1:50:20 what's going to be our memory in in um this uh setup. Okay, so we have now in\n1:50:26 initialized conversation history. Now again we're going to ask the user what they want, right? What's their request?\n1:50:35 So now we use this Y loop and this Y loop was the exact same loop we had in\n1:50:40 the previous subsection as well. uh it only exits unless if the user has uh\n1:50:46 inputed well exit obviously but now look at this the conversation history is\n1:50:52 appended with the human message and the human message is obviously the user input the reason I've kept on writing\n1:50:59 content is because well that's the parameter in human message as you can see here okay cool uh and we've invoked the\n1:51:08 agent what is the agent well the agent is the compiled version of the graph the compiled graph uh with uh the entire\n1:51:15 conversation history. Now this is important. The entire conversation\n1:51:20 history is sent, not just the current human message. So uh this will make more\n1:51:26 sense. Don't worry, I'm um trying my best to explain it right now, but obviously it will make much much more\n1:51:33 sense as soon as I start running it. Okay? So bear with me if you didn't fully understand that. Don't worry.\n1:51:38 Let's remove that for now. Uh, and then we replace the conversation history completely like wipe it with the\n1:51:46 result messages. Why? Don't worry, it's going to make sense as soon as I run it.\n1:51:51 And I think yeah, we should be able to run this now. So, let's write python memory agent.py, which is\n1:51:59 the name of the file. Cool. Okay, let me just quickly write a hi just to see if the API is\n1:52:04 working. It is perfect. Okay. Hello. How can I assist you today? Uh, now I'll say\n1:52:10 like, \"Hi, my name is\n1:52:17 Steve.\" Hi Steve, it's great to meet you. How can I help you today? Okay, now\n1:52:22 remember from last time. Last time if I asked it, hey, who am I? It didn't know.\n1:52:27 Do you think it will know now? Think about\n1:52:34 it. It does. you are Steve or at least that's the name you've chosen to share with me. Uh and the rest is yes\n1:52:42 whatever. So it does know about what I have said but just looking at this code\n1:52:49 I guess you can try to like pick out okay how does it work and everything like why everything works like that but\n1:52:57 um I think we can add print statements and everything. So let's try to add print statements now and see well how\n1:53:05 this is actually working. So let's exit the program. Okay. Uh let's add a print statement\n1:53:13 here. Let me include this. Cool. So what is this saying? So this print statement\n1:53:20 actually kind think of it like a snapshot of what the current state is. So as soon as it goes into a process\n1:53:27 note as just before it's about to finish by returning the state, we also print the current state as well. And this will\n1:53:34 literally just output whatever is stored in the messages attribute within our state. Okay. So let's clear. There we\n1:53:43 go. Let's run this again. So hi, nice to meet you.\n1:53:49 Something like that. Now take a look at the current state. See it outputed hello, nice to\n1:53:56 meet you. How can I see you today? Why did it output that? Well, because in our process\n1:54:01 function it we've asked it we formatted it in a way so it says hey AI which is\n1:54:07 this part and the response or content is this part. Okay. Now this response or\n1:54:13 content is also what was stored remember how I said it's stored in the um in a\n1:54:18 nice manner and was appended to our state messages. Now was it appended to the state messages? Yes. How do you know\n1:54:25 that? Because look at the human message. The human message was what I wrote which was hi nice to meet you. Uh forget the\n1:54:31 additional keyword arguments and response metadata cuz I didn't provide any. Uh you don't need to worry about that. The main part is this part the\n1:54:37 content. And then look at the AI message part. Uh it's the content is equals to\n1:54:42 hello nice to meet you. How can I see you today? Notice how it's the exact same thing as it was\n1:54:50 here. Okay. Now, now we're going to go one step ahead and I'm going to ask it\n1:54:56 to say my name is Steve again. Now, think\n1:55:03 about how will this current state change? Pause the video and try to think\n1:55:08 about this like that. Okay. So, now the second\n1:55:16 uh message I sent was my name is Steve. Its response for the second message was hi Steve. How can I help you today? Now\n1:55:24 look at the current state. It still begins with hi, nice to meet you, which was the first ever message I inputed\n1:55:30 into this conversation and then its respective AI message. And then that gets uh appended. Why appended? Well,\n1:55:37 because we had appended the AI message and appended the human message. So that's why. Okay. And you\n1:55:45 can see the human message is my name is Steve which is the most recent uh message which I put and then the AI\n1:55:51 message which is hi Steve how can I help you today? Perfect. And we can just keep\n1:55:56 going and going and going. But uh for now I'll exit. Now here's the thing. This works\n1:56:03 well relatively well, right? We've got it like as a chatbot which is what we\n1:56:08 wanted. it has some recollection of memory or or like of what we what we are who we are and everything. But there's\n1:56:15 two big problems here. Let's start with the first uh massive problem which is\n1:56:21 this. You know how I've exited the program right now. Yeah. Okay. I'm going\n1:56:28 to run the exact same program again. Now I told it that my name is\n1:56:34 Steve. What is my name?\n1:56:40 and it says uh I'm sorry I don't have access to\n1:56:45 your personal data. Okay. And look at the current state completely wiped out. Again, that's pretty self-explanatory as\n1:56:51 to why you exited the program and that's why obviously all the var the data was stored in the variables, right? The\n1:56:57 state was stored in the variables completely got wiped away. So what is the solution? Think about it.\n1:57:06 Well, obviously one potential solution would be to store it in a database, like a large database, right? Or a vector\n1:57:12 database if you're trying to do some ragged applications. For now, I'm just going to store it in a very simple text\n1:57:18 file. Why? Cuz it's really easy. And I've got the code as well. And usually, honestly, I just store it in a text file\n1:57:24 when I'm prototyping. Now, yes, obviously, storing it in a vector database or a database is much more robust and sophisticated, and that is\n1:57:31 what you should do. But when you're prototyping and you want to really see uh try to build it quickly and fast, uh\n1:57:38 I just tend to use a text file. It still works uh still works great and everything. So what is the code for the\n1:57:44 text file? Uh it's here.\n1:57:50 Okay. So what is this code saying? Well, essentially it's saying create me a text\n1:57:55 file called logging as a as a text file you see in write mode and a file. Write\n1:58:00 your conversation log. This is just to like make it look better and more aesthetic. But this is the main part of the code which um you should actually\n1:58:07 try and understand for every single message in the conversation history. Okay. Now note the conversation history\n1:58:14 was this variable which we had like initialized the conversation history uh stores the AI messages and the human\n1:58:20 messages. So that's where all of the um the information outside the graph\n1:58:26 actually is. Right? the state is locked in within the graph now and uh the\n1:58:33 conversation history is just another I guess you can say a duplicate version of the state right because we've you we've\n1:58:40 appended the exact same human messages and AI messages and kept on updating it\n1:58:45 through this line cool so what it says is that for every single message in the\n1:58:51 conversation history by the way a conversation is the duration between my first message and the last message I\n1:58:58 sent that entire thing is a conversation. A conversation isn't just a single API call. It's the entire\n1:59:04 length. Okay? So, just to be mindful of that. So, uh it first checks if it's a\n1:59:10 human message, it writes that as you and then extracts that content and if it's the AI message, it uh puts it under the\n1:59:16 AI stuff. So, let's run this again. So, let's exit this. Clear this. Okay.\n1:59:25 Who? Okay, let's say hi, I am Steve. Again, I'm using Steve because a\n1:59:31 Minecraft movie just came out, so that's why. Okay, now I'm going to intentionally make a spelling mistake\n1:59:37 here. Good morning. It should obviously morning should have been spelled, right? But I'm doing that for a reason. It gets\n1:59:44 no problem. Let's say tell me a joke. Just another random thing. Sure. Why\n1:59:49 don't skeletons fight each other? They don't have the guts. Um, really rubbish. My point is it\n1:59:57 works. Now I'll exit the program. And now it says conversation saved to login.xt. Now look at\n2:00:04 this. Remove that. Let me remove that. Okay, perfect. So this is the conversation log. The first message I\n2:00:10 ever sent was, \"Hi, I'm Steve.\" There, it's response. Now, good morning. Now, why did I spell it like wrong? Why did I\n2:00:17 do that? Because I wanted to show you that this is the actual human message, my message being stored unaltered. So\n2:00:25 whatever I pass in the state as a human message that stays there. So it's unaltered. The AI message cannot or or\n2:00:34 anything can really change the previous human messages at all. Right? So that's\n2:00:39 why. And you can see tell me a joke. Sure. It's it's a rubbish joke is after that. And that's the end of the login.xt\n2:00:46 file. So that's a really fast efficient way, not the most robust way of course,\n2:00:52 but it is a fast efficient way to be able to store your data outside um the\n2:00:57 application if it stops. Perfect. Now, what was the second problem that I was mentioning? It's\n2:01:03 this. Look at how I initially I say, \"Hi, I'm Steve.\" I don't know why I\n2:01:09 printed twice there. Weird, but whatever. Look at the current state length.\n2:01:15 Okay. Then I pass in another message, it becomes longer. I pass in another\n2:01:20 message, uh it gets longer. It keeps getting longer and longer and\n2:01:25 longer. That's a problem because think about it, you will use these uh library\n2:01:31 uh you'll use these like large language models whether it's for your own AI agentic startup or your own mini Javas\n2:01:36 or your own projects or whatever it is. You would obviously want to minimize cost, right? But using so many tokens uh\n2:01:45 using so many tokens like input tokens especially will really eat away uh your\n2:01:51 uh the amount of money you will uh spend like it will drastically increase it and\n2:01:57 that's a huge problem right we want to try to be conservative a bit about our money and our financial our finances so\n2:02:04 what is one what is a way to solve this think about\n2:02:10 that Well, right off the bat, I can give you an easy solution to implement which is within the code, write it, write some\n2:02:17 code where if the number of human messages exceeds five or something like\n2:02:23 that, then you remove the first human message in your uh history. Why remove\n2:02:29 the first and not the latest? Well, because the latest is most likely to be more relevant, right? The first message\n2:02:35 could is most likely to be the one where um the one which is well not needed or\n2:02:42 it could have been like it can it has more of a chance to be like a bit more less of an impact to have been removed.\n2:02:51 So why did I pick five? Well, five is just a random number I thought of. You could do 10, 15, 20, 25, three,\n2:02:58 whatever. But that's a really easy solution to do. Okay, so we learned\n2:03:04 quite a lot there. We learned how to integrate human message and AI message within a thing. And now we've created a\n2:03:11 somewhat of a sophisticated chatbot, right? It has a memory. It still talks to us. We if we define uh if we write\n2:03:19 who we are, it remembers that and everything and it works great. Obviously, it has its flaws, but for now, it's pretty good. Okay, so now\n2:03:26 we're going to build our third AI agent. And this is going to be a special type of an AI agent.\n2:03:32 The technical term for this type of agent is called a react agent and react\n2:03:37 stands for reasoning and acting. So this is a quite a common type of AI agent\n2:03:43 which you will build. So how does it look like? Well, it looks something like this. So it's quite simple. There's a\n2:03:51 start point and then it's an end point obviously. Then you have your agent and then we use a loop where we attach it to\n2:03:58 tools. Now, this could be one tool, two tools, a lot of tools. And it's the agent's job or the LLM in the background\n2:04:06 to be able to decide which tool to select. But not only that, it's all it's also its job to be able to decide when\n2:04:13 there's no more tool calling left to do. And when that happens, it goes to the end part. So that's the general gist of\n2:04:20 what a React agent is. It's a very very common and famous type of agent to make in Langraph. And that's exactly what\n2:04:26 we're going to be building in this subsection. So what are the objectives? So to build a react agent, the\n2:04:32 objectives are learn how to really create tools in langraph. We're going to be creating a react graph. Of course,\n2:04:39 we're going to be working with different types of messages such as tool messages. See, last subsection we've we covered AI\n2:04:46 messages, human messages, but now we're going to look at a lot more types of messages. for example, tool messages,\n2:04:52 system messages, base messages, and we're obviously going to test our robustness um of our graph. So, the main\n2:04:58 goal is to create a robust React agent. So, if you're excited, I'll see you at\n2:05:04 the code. Okay, people. So, now we're going to code up the React agent. And just a\n2:05:11 heads up, this is going to be quite a long subsection. So, get ready. You can see it's going to be long because of how\n2:05:17 many imports I've done. But because I've done so many new imports, I actually want to take some time off and really\n2:05:22 explain each line so that we're all on the same page. Okay, let's go. So the first line is from typing import\n2:05:29 annotated sequence and type dictionary. Now we obviously know what a type dictionary is, but we haven't come\n2:05:35 across annotated or sequence yet. So these are also type annotations. And I'll start off by explaining what an\n2:05:41 annotated is. So annotated is a type annotation which provides additional\n2:05:47 context to your uh variable or your key without actually affecting the type\n2:05:52 itself, the data type itself. Now what exactly does that mean? Well, I'll give\n2:05:57 you an example. Let's say I am trying to create a type dictionary where there is\n2:06:02 an email key in it. Okay? Now, obviously an email is string. So if I was to create a type dictionary, I would have\n2:06:09 written email colon string, right? Sl. That's how we've been doing it. But here's the thing with certain keys like\n2:06:16 email, they have to be a certain uh format. But like for example, it has to\n2:06:22 be like abcgmail.com for example. But if I pass in\n2:06:28 abcd-gmail.com or something like that, that's not a valid email format anymore, but it's still a string technically. So\n2:06:34 it would pass through. So how do we resolve that? Well, that's where annotated comes in. And I'll give you an\n2:06:40 example here. Let's say email is equal to annotated. I'm not going to create the whole type dictionary to save time.\n2:06:46 But for uh the example itself, you first pass in what data type you want it to\n2:06:51 be. So we want email to be a string, right? That's not changing. But here in quotation marks, I provide some more\n2:06:56 additional information, additional context. And this is basically adding onto the metadata of this key or\n2:07:04 variable. For example, uh let's say this has to be\n2:07:09 a valid email format. Now, obviously, I should do it\n2:07:15 in more detail, but um that's how uh for now, that's fine. So, how how can I\n2:07:22 actually see the metadata? So, if I want to, I would write print email metadata\n2:07:29 uh like that. And then I would press run. And here we go. You can see this\n2:07:35 has to be a valid email format. That's the exact same thing which is which we wrote here. So that's annotated done.\n2:07:42 But what about sequence? What does sequence mean? Well, sequence is also a type annotation. And the way I've\n2:07:48 described it is here. It basically automatically handles the state updates for sequences such as by adding new\n2:07:54 messages to a chat history. Now what does that mean? Well, it's really just\n2:08:00 there to avoid any list manipulation to the graph nodes. Obviously, like when we're using graphs and nodes and all all\n2:08:07 of that stuff and updating the states, there's a lot of uh list manipulations which we'll have to do. Sequence really\n2:08:12 handles a lot of that. So, that's really what it's there for. You don't really need to uh worry about it too much.\n2:08:18 Okay. Now, if we continue, we have env uh from import loadenv. From last time,\n2:08:26 we know that this is just to store our API keys and I've done that here. That will load the API keys. But you'll see\n2:08:32 now these three uh imports. We're importing some new message types here.\n2:08:37 So we're importing base message, tool message, and system message. I'll start off with the tool message. So it's\n2:08:43 essentially a type of message where where the data is passed back to the LM\n2:08:48 after the tool has been called and like the information which is passed is like the content itself, the tool call ID. Uh\n2:08:56 that's what tool messages. It's pretty self-explanatory. Now for a system message, it's the it's a message for\n2:09:02 providing instructions to the LLM. So like for example, if you've used uh LLM\n2:09:07 APIs before, you might have written you are a helpful assistant. That's exactly what a system message is. And don't\n2:09:13 worry, we're going to code this up as well. So you'll actually see what they are. Now what's a base message? So in\n2:09:19 the comments, you can see that I've written the foundational class for all message types in Langraph. Now here's\n2:09:25 how this works. Think about the class hierarchy. So you know how you have a parent class and then you have child\n2:09:31 classes as well. Well the base message would be the parent class and these uh\n2:09:37 AI message, human message, tool message, system message and all these other types of message will be like the child\n2:09:42 classes and they will inherit all the properties of the base message cuz that's the parent one. I guess you can\n2:09:48 say the uh all father or something but the AI message, human message and all\n2:09:53 these child uh classes obviously they'll have their own properties, right? For example, the tool message has its own\n2:09:58 content and tool call ID and all that stuff. So that's what the base message is. It's really the foundational class\n2:10:04 for all the message types in Langraph. Cool. Okay. So now if we\n2:10:10 continue, you can see we've imported chat, openAI. Uh we've done state graph and M. These we've come across. We know\n2:10:16 what they are. And we've imported tool and tool nodes which we cover in the second chapter or second section of this\n2:10:23 course. uh these are different elements which we're going to be uh using in langraph. Now what about this line from\n2:10:29 langraph dossage import add messages. Now what does that mean? So this is a\n2:10:34 little bit um different. This add messages is a reducer function. Now if\n2:10:41 this is the first time you're hearing that don't panic. It's not that hard. So let's let me copy this one second. Okay.\n2:10:49 So a reducer function is essentially just a rule that controls how updates from nodes are combined with the\n2:10:56 existing state. In simpler words, it really just tells us how to merge new data into the current state. Now here's\n2:11:03 the thing. If we didn't have some sort of a reducer function, uh updates would have just replaced the existing value or\n2:11:09 state entirely. And I'll give you an example for this.\n2:11:15 So let's say I had a state where it was just high. I had one attribute messages\n2:11:21 and high. Now obviously I should have created the type dictionary and everything and formalize it but just for\n2:11:26 simpler um for times saving purposes I've done it like this. Now what if I\n2:11:32 had an update which says nice to meet you. If I didn't have a reducer function that would completely overwrite it. Now\n2:11:38 in the previous uh graphs and agents we've made we've appended it but now that we're using so many different\n2:11:45 messages and calls and tool calling and what whatever we can't really always append\n2:11:50 everything like it will get far too complicated. So that's why we need to leverage reducer function. So if we\n2:11:56 didn't use a reducer function it would just overwrite it completely. But if we did like hi nice to meet you it would\n2:12:03 append it. That's the key. So in a nutshell, the reducer function really\n2:12:08 just aggregates the uh data in the state. This reducer function uh and the reducer function which I'm talking about\n2:12:13 is add messages. So once again, add messages is a reducer function that will\n2:12:19 really just allow us to append everything into the state without any overring happening cuz so we want to\n2:12:26 preserve the state. Okay, cool. So now let's actually code this uh react agent.\n2:12:32 Okay. All right. Okay. Okay, I've cleared the screen now and let's actually begin like we how we always\n2:12:38 begin with the uh creation of our state of our agent. So, type dictionary like\n2:12:44 such. Okay. And now we we'll only have one key in this uh in this example which\n2:12:52 is just messages. And now let's use the new type annotations we've learned. So,\n2:12:58 sequence base message and reducer function add messages. So again this\n2:13:05 piece of code is saying to preserve the state by actually appending it rather\n2:13:10 than overwriting. That's what this reducer function does. Okay. All right.\n2:13:15 Okay. Oh, and the sequence of base messages is the data type and this\n2:13:20 provides the metadata. That's why we have the annotated keyword here. That's really it. Okay. Uh now let's create our\n2:13:28 first ever tool. Now how do we do this? Some of you who have a um who have come\n2:13:33 from lang chain might know how to do this already. We use a decorator and we\n2:13:39 define like this. Now this decorator basically tells Python that this function is quite is special. It does\n2:13:45 something and well it is special because it's a tool which we're going to use. So let's define our tool as def. Let's\n2:13:52 create a simple addition tool. Okay. So we'll say a integer b integer.\n2:13:59 It's basically going to add two numbers. And this is where doc strings actually come now. And I'll show you how important they are. For now, let's say\n2:14:06 uh this is an addition function that adds two numbers together.\n2:14:15 Okay. All right. And we just return a plus b. Simple. Now, how can we actually\n2:14:23 infuse these tools to our large language model? Well, first let's create a list.\n2:14:30 Add like such. Now, yes, at this current moment, I only have one tool, but in a\n2:14:36 few moments, we'll have multiple tools. That's why I'm adding this uh list for now. And let's actually create our\n2:14:41 model. So, model is equal to chat openai. Model is equal to\n2:14:48 GPT40. Again, I'm using GPD40 because I've never had a problem with it to be honest. So how can we tell our GPD40\n2:14:56 large language model that these are the tools you can use? Well, we can use this inbuilt Python um inbuilt function\n2:15:03 called bind tools. Bind tools like that. And we pass in the list of tools we\n2:15:08 have. So that's tools. Pretty simple, right? Okay. So now large language model\n2:15:14 will have access to all of our tools. Okay. So now we need to create a\n2:15:19 node which actually acts as the agent within our graph. So how do we do that?\n2:15:24 Let me create just a simple function like def model call. We pass in the state agent state. Again it needs to\n2:15:31 return the agent state. Okay. Now I'm going to quickly copy this\n2:15:37 piece of code. Give me a\n2:15:42 second. Okay. So what is this code doing? uh you can see that we're invoking the\n2:15:49 model aka running the model and this is the system message which we are asking.\n2:15:54 So we're explicitly saying the large language model that you are my a system please answer my query to the best of\n2:16:01 your ability. So that's what the large language model's task is to do. Now if\n2:16:07 we want to get technical here, you could have written it in a slightly different way and that way is through\n2:16:15 this. So remove this. We could have said system\n2:16:22 prompt. Okay. So what's going on here? Remember how I said system message is also something which we imported. Uh so\n2:16:29 the system message like I said is this line of uh is this line. You are my AS system. Please answer my query to the\n2:16:35 best of your ability. Now, either way would have worked if we if I had just straight up\n2:16:40 passed this string into here. That would have worked as well. Personally, I think this way is better. Even though they\n2:16:46 achieve the exact same thing, I think this way is better cuz it's more readable. Okay? And you're only adding\n2:16:51 just one more import. Okay? So, I would prefer you to I would really recommend\n2:16:56 you doing like uh like this so even the large language model knows that this is a system message. Okay, cool. And this\n2:17:04 is uh just another way of writing like the updated state. You know how we've been writing state uh brackets messages\n2:17:12 is equal to something something something. Well, this is a more compact way of updating the state as well. So\n2:17:17 return messages response. So we update the messages with the response. No plus\n2:17:22 equal to this this this or adding something we just we can simply just write it with the updated state. Why?\n2:17:29 because the add messages aka the reducer function handles the appending uh for us. It doesn't overwrite it. Now, if I\n2:17:37 ran this code and I built the graph and everything, would it work? No. Why it wouldn't work? Because\n2:17:45 think about it, the response when we've invoked the model and we store it in the response when we actually invoked it, we\n2:17:52 didn't actually pass in the query. How do we pass in the query? Think about it.\n2:17:58 All I passed is my system message. Where does the query go? So to be able to add\n2:18:03 the query, I actually have to add like this. So state messages. The query it\n2:18:10 will be in the form of a human message. And the human message will be stored in the messages attribute, right? And now\n2:18:16 that we've passed that into our model as well and we can invoke it. And now this\n2:18:21 should work. Okay. Okay. Okay, so now we define the\n2:18:28 conditional edge. Now why do we need the conditional edge here? I'll put the picture of the react agent. Again here\n2:18:34 you can see that the looping part even like in the last one in the graph when we made the loops for the first time you\n2:18:40 saw that was it was a conditional edge which we had to use and now that's actually going to come in play here.\n2:18:46 That's why I took so time to build those graphs because now the concept is coming. So how do we define the\n2:18:53 conditional edge def should\n2:18:59 continue. Okay. So again like always we pass in the state and let's do it like\n2:19:09 this like such else\n2:19:14 return continue. Okay. So as you know as you um might have guessed end and\n2:19:21 continue will be edges which I'll define later in the graph. But what is going on here? Well essentially when I'll pass in\n2:19:28 the query uh when we've invoked the actual model you will know that we'll create a list of tools right so what\n2:19:36 we're going to be doing is we're going to be uh getting the last message and we're going to see if there's any more\n2:19:42 tools needed to be ran. If there are then we'll go into the continue edge aka\n2:19:48 we'll go to the tool node and we'll select the tool and we'll do all this uh actions and then come back. If there's\n2:19:54 no more tool calling left we will just end and we'll just exit the uh graph and\n2:19:59 that'll be the case. You'll get uh uh you'll understand more what I what I mean when we've actually test we're\n2:20:05 testing and running the graph. Okay. Now let's just define the graph. So like\n2:20:11 always we create the graph we initialize the graph through the state graph and let's call the node R agent. So the\n2:20:17 action will be the model call aka the underlying function will be this. Okay. Now we create something called a\n2:20:25 tool node which is also what we covered in the previous uh in the second section\n2:20:30 or second chapter in this course. The tool node essentially is just a singular\n2:20:35 node which contains all of the different tools. So we only have one tool. If you see what this variable is tools, we only\n2:20:41 have one tool which is add. Don't worry, we'll add some more tools like subtracts and multiply in a bit. But I just want\n2:20:47 to uh like really solidify your concept of how we can add these tools and how the graph will work. Okay. Now we\n2:20:55 obviously set our entry point and point it to the R agent. Now let's add our conditional\n2:21:01 edge. So remember remember how I said there's two edges, continue and end. again continue and end and if it goes to\n2:21:09 the end we end it. If it goes to tools then we go to tool node which is tools. Okay. Okay. So yeah this is\n2:21:17 pretty straightforward still. Right now we also need to add an edge which goes back from our tool to our agent cuz\n2:21:24 that's how we're going to create a circular connection. Right? You can see that the conditional\n2:21:30 edge only provides a one-way directed edge from the from either the agent to\n2:21:36 the tool node or the agent to the endpoint. But we need another edge which will go back from the uh tool node back\n2:21:43 to the agent. And that's what this um that's what this edge does. And lastly, we need to uh obviously compile it. So\n2:21:50 we'll just say app is equal to graph dompile. Perfect. That's it. Now I've\n2:21:57 just created a a new helper function here which this isn't part of langraph.\n2:22:03 I've just written this code because it will make every like the tool calling and everything uh like output in a much\n2:22:09 better way. So you'll see what I mean in just one second. Okay. So now we\n2:22:16 actually can begin. So let's say the input is uh something like this.\n2:22:24 Let's say I want to add 3 + 4. Okay, simple. And this line of code basically\n2:22:31 streams the data. That's all it does. So, let's actually run this. Clear. And\n2:22:36 let's do it. Okay. So, remember we wrote add\n2:22:41 3+4. Wow, look at that. So, we've added 3+4. It calls the tool and it even knows\n2:22:47 what tool to pick. Add. Um, and it gives us the result. The tool message as you\n2:22:52 can see is seven and the AI message the final AI message is the sum of three and four is seven. That's it. Let's try\n2:23:00 something harder now. Let's write add 34 + 21. So if we run\n2:23:08 this you can see 55 cuz 34 + 21 is 55. And you can also see again all the tool\n2:23:14 calls and everything that's done right. I want to show you one two more things actually before we add some more tools\n2:23:20 which is this. If I remove this dock string here by commenting out for\n2:23:25 now. Let's clear and let's run that\n2:23:30 again. Error. Why? Because the function must have a dock string if description\n2:23:36 is not provided. The dock string is necessary. That's why included otherwise the graph won't work. It's remember it\n2:23:43 tells the LM what that tool is for. Okay. So now that we've have uh we've\n2:23:49 got that there, let's try this as well. Add uh 3+ 4. Again, this time I want both of\n2:23:58 them to be executed. So clear now. Do you think this will work? Let's\n2:24:05 see. Add 34 + 21. Add 3+ 4. Perfect. Brilliant. Okay. So you can see the\n2:24:11 result of adding 34 + 21 is 55. The result of adding 3+ 4 is 7. You can see how the tool was called twice this time\n2:24:18 and that's the power of the loop which we created. Remember we created the conditional edge and then we also\n2:24:24 created that directed edge back from the tool node to the agent. Let's let's try to make it even uh give more um\n2:24:31 complicated stuff. Let's say add add 12 + 12 something. So let me\n2:24:38 clear this. Clear. Let's see what happens.\n2:24:46 Wow, look at this. If I press enter, sorry, I messed up there. But you can\n2:24:53 see the results of the addition as well as 34 + 21 is 55 7 24 or and you can\n2:24:58 also see that I called the tool the sorry the AI called the tool three times.\n2:25:04 Now these tool calls is also an indication that the LLM didn't use its own like information inbuilt information\n2:25:11 which it was trained on to come up with an answer. Right? Remember an LLM doesn't know how to do maths. It just\n2:25:16 guesses the next output like through probability. But through this we were\n2:25:21 able to actually add the two numbers. So an important concept here is\n2:25:27 the LLM actually decides what should be passed as the arguments to each tool. So\n2:25:33 3 + 4 like if I said add 3 + 4 it will actually uh create it will actually uh\n2:25:39 input the numbers 3 and four and then this tool will handle the uh information return it and it will go back to the\n2:25:44 agent and then the AI agent will decide what's the answer and everything. So that's how it works. Awesome. Okay. Now\n2:25:50 let's make this even more complicated. Let's add some more tools. Let's add\n2:25:58 subtract and multiply. Okay. And the only re change we have to do is instead\n2:26:05 of this one line we just now include subtract and multiply as well. That's\n2:26:11 it. Otherwise this line this code largely stays the same. Now let's\n2:26:16 actually run this same command and see if it gets confused with the different\n2:26:21 um different tools we have it has access to. Now let's see. Okay.\n2:26:29 You can see again that 55 724. Okay, it didn't get confused. Perfect. Let's now give it a\n2:26:36 different command. Let's say something like this. One\n2:26:44 second. Add 40 + 12 and then multiply the result by 6. So now it has to make\n2:26:49 use of two different tools. Let's see if it gets that.\n2:26:55 Okay. Wow. Brilliant. So it first used the add tool and then used the multiplication tool and you can see all\n2:27:02 the queries or all the tool called and everything and the final answer is 312. So 52 * 6 yes it is 312. Okay. Wow that\n2:27:10 works like brilliantly. So now that we know that this is robust what about if I\n2:27:16 add this let's say also tell me a joke\n2:27:22 please. What do you think will happen? Do you think this will break? Let's see.\n2:27:28 If I play this and run this. Let's\n2:27:37 see. Wow. Look at this. The result of 40 adding 14 and 12\n2:27:43 is 52 multiplying that is by 6 is 312. And here's a joke for you. Why don't skeletons fight each other? They don't\n2:27:49 have the gun. I swear to God, it's always the same dead joke. But you get the point. This is so robust. It can\n2:27:55 handle even queries where it doesn't even need a tool and that ladies and gentlemen is the power of langraph. So\n2:28:01 it's it's so robust even if we don't need to use a tool it will still give us an answer and the reason it was able to\n2:28:09 do that is once all the tool calling is done it passes it to the agent the agent checks again oh I need to tell it I need\n2:28:16 to tell the user a joke as well and adds that to the final information and then ends it that's the power of\n2:28:22 lang okay so after all of that we finally now know how to create a react\n2:28:27 agent yes it was a simple react agent but the concepts the same. You can create your own external tools from now\n2:28:33 onwards and you can create your own graph. And that was the whole point of this course, right? For you to actually\n2:28:38 understand how we can uh create these um how we can use different tools and then the rest is up to you. It's up to your\n2:28:45 imagination. Okay, perfect. So now I will see you at the next subsection. All\n2:28:51 right, see you there. Okay, people. So we've made great progress so far. So\n2:28:57 well done on that. But now we make a fourth AI agent. And this time we'll do\n2:29:02 things again slightly differently. Well, this time we're going to be making a mini project together. So the project's\n2:29:10 name is going to be called Drafter. And you'll see why in a minute. So picture\n2:29:15 this. Me and you are working in a company together. And our boss comes up\n2:29:20 to us and she has a problem and some orders for us. So the problem is this.\n2:29:26 Our company is not working efficiently. We spend way too much time drafting documents and this needs to be fixed.\n2:29:33 Again, a valid problem. So, what are her orders? She says you need to create an\n2:29:38 AI agentic system that can speed up drafting documents, emails, etc. The AI\n2:29:44 agentic system should have human AI collaboration, meaning the human should be able to provide continuous feedback\n2:29:49 and the AI agent should stop when the human is happy with the draft. The system should also be fast and be\n2:29:56 able to save the drafts. Okay. So then me and you start discussing and we are\n2:30:02 going to use land graph obviously and we come up with a sketch. Now the sketch of\n2:30:08 our graph is something like this. It obviously is going to have a start and an end point and it's going to have our\n2:30:14 agent and the agent will have access to tools aka the tool node. Now this looks\n2:30:20 similar to a react agent which we covered in the last subsection. But there's a reason we don't we haven't\n2:30:26 chosen to do that. See we realize that one of the tools is the save tool. It\n2:30:31 will save the draft, right? That was one of our requirements. But obviously when we once we've saved it, the process\n2:30:37 should end, right? But if you remember from a React agent, the tools always goes back to the AI agent, not directly\n2:30:45 to the endpoint. And we don't want that anymore. So that's why as soon as the save tool is used because the save tool\n2:30:52 will be within tools right it ends. So that is the structure we have chosen to\n2:30:58 go with. So the only thing left is to actually code this graph. So let's code\n2:31:04 this together then. Okay. So let's actually code up this drafter project then. So you can\n2:31:11 see I've already done all the imports and I've loaded up my env file. Now all of these imports are imports which\n2:31:17 you've already uh encountered before. So there's no point in looking at them again. But the first thing which I'm\n2:31:23 going to do is I'm going to be defining the a global variable. Now this global variable yes it's a bit\n2:31:31 odd defining global variables and there's a reason which I've done it and this will become more apparent as I go\n2:31:37 through the code but just as a heads up the reason I've defined a global variable in this case is to actually\n2:31:44 pass in a state in tools the the correct way to do it in langraph is through\n2:31:50 something called injected state now injected state is beyond the scope of this uh course so the workound on that\n2:31:58 is to use a global variable and what will happen is our tools will uh\n2:32:04 whatever updates are made uh we'll update the global variable and then when we go on to save it uh the save tool\n2:32:12 will use the contents in this global variable and save that into a text file.\n2:32:17 So that's why this is included. Okay. So now let's define our agent state again.\n2:32:23 And the way that's done is the exact same way we did last time. Uh class\n2:32:28 agent state messages annotated sequence base message add message as the reducer function. So now we define the tools and\n2:32:37 there will be two tools for this. The first tool will be the update tool and the second tool will be the save tool.\n2:32:42 So let's start off with the uh update tool and I will obviously use the decorator and then create def\n2:32:50 update and then we need to pass in\n2:32:55 uh pass in a parameter content. Now just as a refresher whatever parameters you\n2:33:01 pass or you request who actually gets those parameters? Well, the LLM or your\n2:33:08 model in the background that's uh what will automatically pass the parameters\n2:33:13 for this model uh for this tool. So, uh in this case the content parameter will be uh that will be provided by the lm in\n2:33:21 the background. So, you don't need to worry about that. Okay. So, now we need the dock string obviously and I've just\n2:33:27 created a simple dock string which just updates the document with the provided content because that is exactly what it does.\n2:33:33 So now we define to interact with the global variable in Python, you obviously need to uh define it uh you need to code\n2:33:40 it like this and then you need to update your document content aka the global\n2:33:47 variable with your current content and then you just return again a statement\n2:33:53 to the like the large language model telling it that we have successfully updated it. So I've written document has\n2:33:58 been updated successfully. The current content is this which is the content which we store in the thing. Okay. So\n2:34:07 now we define our second tool which is the save tool. So again same decorator we use uh like\n2:34:14 this. And now we request the llm to give us a file name as well. So it will it\n2:34:22 should give us a suitable file name uh which will be a suitable file name for the text file and uh it will and now\n2:34:28 this save tool will automatically handle all the save logic. So uh as a dock\n2:34:35 string I pass like this. So saves the current document to a text file and finishes the process. And the arguments\n2:34:42 are file name which is the name for the text file. Now, I've specifically mentioned that we're going to be using a\n2:34:48 text file so that the uh uh the LLM knows that the file name which it needs\n2:34:54 to pass has to have a txt in the end of it. Now, if it doesn't uh by any means\n2:35:01 to make the uh graph to make the entire code more robust, I've also written this if statement such that if this file name\n2:35:07 doesn't end with a txt, just put a txt there just uh as robust as measure. Now\n2:35:13 again we need to uh call the global variable again. So global document\n2:35:19 content. Okay. Now this next bit of code that's this is not langraph. This is just uh whatever you put in the tool. Uh\n2:35:26 it it doesn't have to it's not going to be langraph related. Right. So this piece of code is just uh some code which\n2:35:34 allows you to save the uh contents a the the content store in in the global\n2:35:40 variable under the file name uh and as a text file and I've also added this\n2:35:45 exception uh which is a good thing for debugging purposes where it if there's\n2:35:51 an error it will tell me exactly what the error is and then we can fix it. Okay. So hopefully there won't be any\n2:35:57 errors. Now we create a list of tools which uh again will be update and save\n2:36:04 because we only have two tools. And now we actually call the uh model and how do\n2:36:10 we call the model like such? Now let me ask you a question. Is this it for the model definition or do\n2:36:18 we need something else? Well, there's a reason I asked that question, right? We forgotten to do\n2:36:24 bind tools. So bind tools and tools. So that will do. Okay. Now we actually\n2:36:31 initialize the agent itself or the function which will cuz remember the agent will be a node in our graph. And\n2:36:39 what will be the function behind that? It will be this function which we're about to define. So let's write this as\n2:36:46 def r agent. And again we need to pass in the state the agent state and it'll\n2:36:51 return the agent state. And okay so now this doc uh not doc\n2:36:58 string this we need to pass in a system message to our llm right now this llm\n2:37:03 this system prompt will be quite large so get ready uh like such so in this system prompt I\n2:37:11 have specifically said this is a system message and the content is this you are drafter a helpful writing assistant\n2:37:18 you're going to help the user aka us to update and modify documents and I've also written some more stuff about what\n2:37:25 the uh update or what what to do if the user wants to update. We use the update tool. Uh we need to use the save tool to\n2:37:33 save it and to always show the current document say after modifications and all that stuff. Cool.\n2:37:40 Okay. So, oops. There we go. And now it's time for some robustness\n2:37:48 measures. So when we're first initializing the graph like when it's the first message we're writing\n2:37:54 obviously we're not going to straight up say uh how would you like to change the document right because we haven't passed in a document yet. So if messages uh\n2:38:03 this part if that if there's nothing in it we will have to say something like an\n2:38:08 introduction message right. So this is how you can do that. So we can\n2:38:15 say if not state messages aka if there's nothing in the state messages then we\n2:38:20 can say uh I'm ready to help you update a document. What would you like to create? and then it collects the user\n2:38:26 input and passes it as a put stores it as a a human message in this user\n2:38:32 message variable. Now what if I've already passed it uh passed in a message\n2:38:37 or like we are on the process of updating our draft or drafting it. Well to do that we need this else statement\n2:38:45 and what does this say? Well it says what would you like to do with the document? So this assume this says that\n2:38:50 there's already stuff in the messages uh state a messages key in the state how do you want to update it further and then\n2:38:57 we also print it uh under this emoji uh in the terminal so the user can also see\n2:39:03 what they've inputed and then this is also stored in the user message. All right. Okay.\n2:39:10 Now we combine all of this uh all messages aka the system prompt which was\n2:39:16 the system message uh and we create a list of uh list of the uh state messages\n2:39:22 and the user message the new message which we want the aka the update and\n2:39:27 then we just invoke the model and how do we invoke the model you just use the uh\n2:39:33 model invoke okay so pretty basic code so far there's nothing hard or nothing\n2:39:39 uh extraordinary or something we haven't seen before. All of this we have seen before. And now the rest of this\n2:39:47 function is just a print statement which I've included. This print statement is\n2:39:52 just for uh um making things look prettier on the terminal. That's all it is. You can see the true print\n2:39:58 statements. There's the AI response which will be printed and then there'll be the tools uh whatever the tool\n2:40:04 messages are that's also printed. So that's the whole point of it. there's nothing like to really like talk about\n2:40:09 it here. Uh and then we also need to obviously return the updated state. Now remember\n2:40:16 last time I showed you that this is also a really convenient concise way to uh\n2:40:22 update the states. So from now onwards we're only going to update the states like this. Okay. Now we create our\n2:40:29 conditional edge function or the function behind the conditional edge cuz remember let me open this up. So the\n2:40:36 conditional edge which I'm talking about will be this this this conditional edge.\n2:40:42 So there from tools there will be either the select the uh the choice of going to\n2:40:47 back to the agent or the choice of ending it. So we need to create the underlying function behind that. So\n2:40:54 let's create that now uh under this. So should continue. We've\n2:41:02 done this many times before. it det will determine if we should continue or end the conversation and remember continue\n2:41:08 or end the conversation. Okay, makes total sense. Okay, so\n2:41:16 now we do this. So we get the messages and if there's nothing in the messages,\n2:41:22 well obviously we'll need to continue, right? It won't go to the end part. Uh\n2:41:28 and this is just as like a robustness measure to be honest. Okay. So now this piece of code\n2:41:35 is basically saying look at the most recent tool message or the uh recent\n2:41:41 tool we've used and we need to check if this tool uh has used the save tool. Now\n2:41:48 why remember how we have two tools we have either the uh update tool or the\n2:41:54 save tool. If we use the update tool, well, we will obviously need to use the continue branch, right? But if we use\n2:42:01 the uh save tool, well, after you saved it, there's nothing else to do, right?\n2:42:07 You finished your draft, you finished everything, so might as well end the program. That's why this end tool. So,\n2:42:14 for the continue, uh if to go to the continue um through the continue edge,\n2:42:19 we have to use the update tool. And to go to the end uh edge you need to use the uh the save tool. So should make\n2:42:28 sense now but don't worry if it doesn't we will do some more print statements so you see the workflow. Don't worry. And\n2:42:35 lastly we need to obviously return continue because by default it's checked here that it's used\n2:42:42 the save tool. The only other tool left is the right tool and uh sorry the\n2:42:47 update tool. And the update tool means that we have to go to the continue edge, right? Okay. And that's that uh function\n2:42:54 done as well. So pretty easy still. Now this next function is again I only coded\n2:43:01 this just to make the print statements in a more readable message format uh\n2:43:06 when we printed on the terminal. So you will see where this comes in play when we actually start uh invoking the graph\n2:43:12 and seeing how our process is going. Okay, cool. Okay. So now we actually\n2:43:19 init uh create the graph. So how do we create the graph? We've done this many times. We will initialize it through a\n2:43:26 state graph. And now we will add the nodes. So agent and tools. And the tools\n2:43:33 will be a tool node. And again if you notice back we had one node, two node,\n2:43:38 the agent node and the tools node. I'm keep I'm like reflecting back and forth between this diagram and the code\n2:43:45 so I can show you exactly what we're coding. Okay. So again agent and tools node uh we've\n2:43:51 done now we will set the entry point at agent which is the start point aka this\n2:43:57 part right and now we're going to add an edge\n2:44:02 between agent and tools. Now we need to obviously create this edge because the agent needs to go to the tools right and\n2:44:08 then this edge this directed edge and this conditional edge creates the loop\n2:44:14 uh which will allow for the human AI collaboration. All right. Okay. So now\n2:44:20 we add the conditional edge and that's the conditional edge which I was talking about the continue at the end aka this\n2:44:27 condition this conditional edge from tools. Okay. And now the last thing we need to do is\n2:44:35 just compile it because we've finished the graph completely, right? There's nothing left. We've done the start point, we've done the end point, the\n2:44:41 end, this conditional edges done, the nodes done, and then this directed edge is done and the start point is obviously\n2:44:47 done because we've uh created a directed. So you can see the entire graph we have created just like that. So\n2:44:53 again, nothing too hard. Cool. Okay. So now we actually run\n2:44:59 the program. And to run it, I have just written this um function so that\n2:45:04 everything is in a more compact way. This is just to invoke the graph. Okay.\n2:45:09 And let's do that. So that was the entire code. And this code will allow\n2:45:15 for human AI collaboration. Now, yes, we used a global variable. And again, there\n2:45:21 is nothing wrong with using a global variable. I know some of you might frown upon it, but um again, there's nothing\n2:45:27 wrong with it. If we wanted to use more complicated uh form uh complicated uh\n2:45:32 stuff from langraph like the injected state or even using something like commands and interrupts uh we would have\n2:45:39 to write the code slightly differently but because this is a beginner level course uh we've just disregarded that\n2:45:46 completely and we found another way of performing human AI collaboration. Awesome. So let's actually run this now.\n2:45:53 So let's write python draft. py and you should be able to see all of\n2:46:00 the things. I made my face cam slightly smaller so you can hopefully see everything. Perfect. So you currently\n2:46:05 have an empty document. Could you let me know what you like to add or create in the document? So what would you like? So\n2:46:11 let's say we are writing an email to our colleague Tom saying that we can't make\n2:46:16 it to the meeting. So let's say write me an email. Let's say uh write me an email\n2:46:22 to Tom saying we I cannot make it to the\n2:46:28 meeting. Let's see what it says. So it says\n2:46:34 uh hi Tom I hope this message find you well. Please let me know. Okay let's now\n2:46:40 give it some feedback on how we how we can improve. So and also you can also see that it's used the update tool as\n2:46:46 well. Perfect. So, let's say um make sure to also have specified that\n2:46:56 the meeting was supposed to be at 1000 a.m. at some random negation.\n2:47:05 Canary Wolf. Okay. Okay. Let's see the updated thing.\n2:47:11 Hi, Tom. Uh you can see message meeting at 10. Uh, can I wolf due to unforeseen\n2:47:18 circumstances? Uh, let's I don't like this uh your name part though. So, let's say my name is\n2:47:26 V and it will update that as you can see. Perfect. Uh, what do what else do\n2:47:32 we want to change? We can also say something like uh let's say but tell him\n2:47:40 that I can make it at 12 p.m. in\n2:47:47 um New York, some random location. Okay, I'm making this up, but you you get the\n2:47:53 uh plan. Uh the next day. So, let's\n2:47:59 see. And perfect. It's updated it. However, I am available to meet at 12:00\n2:48:04 p.m. in New York the next day. Obviously, it's complete like rubbish like the timings of the location I've written. But you can see how we can just\n2:48:13 uh use human AI collaboration here. Uh one more thing which I don't like is\n2:48:18 this part. I don't like the fact that it's not a new line. So, I mean I'm being a bit picky here. We can say\n2:48:24 something like uh put the II hope this message finds you\n2:48:36 well. Awesome. And as you can see that's done as well. So now let's say I like it. Save it please. And what\n2:48:45 happens? You can see that uh it used the save tool. The tool results is document\n2:48:52 has been updated successfully. The current content is this and the document has been saved to unable to attend\n2:48:58 meeting email. Now remember we never passed in the file name at all. That was all generated by the by the agent\n2:49:05 itself. And to check we need to go on unable to attend meeting. So let's see\n2:49:10 here it is. And you can see it's the exact same\n2:49:15 meeting uh exact same email we said. So, subject, oops, best regards me. All the\n2:49:22 exact same content. Perfect. And we don't even need to uh make it so that\n2:49:27 we're drafting emails. We can even drop short stories. We can drop whatever we want. In fact, we can also pass in uh a\n2:49:35 previous message. So, the reason it started off like with nothing is because\n2:49:40 we pass in an empty list. But if you wanted to, we could have written something over here uh with our pre with\n2:49:48 a already existing email or already existing document and then it could the model the agentic system would know that\n2:49:55 this is what the content is the current content how would you like to uh change that and that is exactly how uh we will\n2:50:02 be able to operate on our existing ones. So you can see that this is quite a robust thing. If we want another\n2:50:09 example, for example, uh let's say python drafter.\n2:50:16 py. Okay, now watch this as well. Look how robust this is. If I say something\n2:50:22 like write an email, it actually gives back questions.\n2:50:28 So sure, what would you like the email to say? D. So remember, it didn't even go through any tool here. uh using\n2:50:35 langraph we can really make the agents quite robust and that's the thing which I wanted to show you it doesn't always\n2:50:42 have to pick a tool its own like LLM like the agent itself cuz remember the\n2:50:47 agent node has an LLM in the background back end the bind tools function allows\n2:50:52 it allows it scope like it increases the scope of it uh by providing some tools\n2:50:57 but that doesn't mean it has to use those tools if it doesn't feel like the need to use the tools it won't and in\n2:51:04 this case it wanted to ask us more questions about it. So it would say show what would you like this email to say\n2:51:10 because to be fair I only wrote three words. Uh but that was what I was trying to show you. So let's just clear this\n2:51:16 now cuz we don't need to. And yeah you can see perfectly works human AI\n2:51:21 collaboration in langraph and this is actually somewhat useful as well. Now yes of course you can use GPT4 canvas\n2:51:29 and all of that stuff of course but um this is how you would do it in Lagraph. All right. So, if you would like an\n2:51:36 extension to this, what you could do is add a voice feature as well. So, maybe\n2:51:42 you could add use OpenAI whisper for uh speech to text conversion or add 11 laps\n2:51:48 for text to speech conversion and maybe you can make it voice based cuz right now I'm giving it I'm how am I\n2:51:55 communicating it with text mode? What about voice mode? You could also include a GUI to this. There's a lot of stuff\n2:52:02 which you can do on you can even have your own knowledge base as well and include that. So a lot of potential with\n2:52:08 this if you want a homework for this uh specific project that there you go. All right. Okay. Cool. So that's the end of\n2:52:16 this subsection. Awesome. So now let's build our fifth AI agent. And some of you\n2:52:22 might have been looking forward to this. It's retrieval augmented generation rag.\n2:52:27 So what will the graph look like? It will look something like this. Again,\n2:52:32 start point, end point, really similar to what a react agent was, right? But uh\n2:52:38 we have two agents in this case. We have a retriever agent and we have our main agent LLM, right? So, and it will have\n2:52:44 obviously a conditional edge, a loop, and everything. Again, we're bringing everything we've learned so far and\n2:52:49 merging them into one. And we're also going to be learning about a little bit about rag. Now, I'll assume you know\n2:52:55 what rag is. I'm not going to go too much in detail into like the nitty-gritty of it. But again, in the\n2:53:01 surface level, I will obviously explain what rag is about and everything. Okay. So, if you're excited, let's uh let's\n2:53:08 jump to the code. Okay. So, now you can see that I've already done all of the imports\n2:53:13 which we'll need. But you'll notice how there are these four imports which we haven't come across yet. Now, rather\n2:53:20 than explain them from the get- go, I will explain them as they come because it'll make more sense. uh it'll make\n2:53:25 more intuitive sense that way. Okay. So now I'm going to be loading our uh ENV\n2:53:31 file which contains all the API keys. And this time I'm going to be\n2:53:37 initializing our LLM differently. Well, slightly differently. It's the same LLM, but why did I say differently? Because\n2:53:44 I've passed in a new parameter called temperature. Now for those of you who do not know what temperature is, it's\n2:53:49 essentially a parameter which depicts how stochastic the model outputs how\n2:53:54 stoastic you want the model outputs to be. So because I've set it to be zero, temperature equal to zero makes the\n2:54:00 model output more deterministic. Similarly, if I had set the temperature to be one, the model output would have\n2:54:07 been more stochastic. Okay. So now we create the embedding\n2:54:13 model. And the embedding model uh is what's going to convert our text into vector embeddings. Right? Uh so this\n2:54:20 will be the layout for it. Now please note one important thing which is the embedding model has to be compatible\n2:54:27 with the LLM we're using. You can use whatever LLM you want but make sure the embedding model uh is compatible with\n2:54:35 it. For example uh let's say we're using GBD40 uh an open model but the embedding\n2:54:40 model we're using is from Olama some random model. Now that they wouldn't most likely they're not going to be\n2:54:46 compatible. Why? Because there's so many differences between them. One potential difference could be the vector dimension. So just a rule of thumb. Make\n2:54:54 sure the LLM and the embedding model is compatible. Okay. Awesome. So now we're\n2:55:01 going to specify the PDF part. So this is the stock market performance 2024 PDF. And essentially this is just a\n2:55:07 document which I created which contains um a lot about the stock market\n2:55:12 performance. Okay. Uh I can show you that right now actually. So this contains nine pages and is just a\n2:55:20 document containing about some stock market details in 2024. Okay. Awesome.\n2:55:26 So now um in case you've specified the\n2:55:31 uh you have put the PDF in a wrong directory or if it can't find it uh this error will pop up. So again I've just\n2:55:37 put this for debugging purposes if you use the code which I provided on GitHub. Okay. Now this will load the PDF and you\n2:55:46 can see pi PDF loader is one of the imports which we made here. So again\n2:55:51 it's in the name and the common. It just simply loads the PDF. Okay. Uh and this\n2:55:58 try and accept command uh just checks if the PDF is there. And pages is equal to\n2:56:04 PDF loader.load. So this essentially says how many pages are there in the document. So you can see there's nine\n2:56:12 pages in our document. So if I run this command, if I run this, so clear\n2:56:20 python rag agent.py py it should say nine\n2:56:25 pages. So there we go. PDF has been loaded and has nine pages as expected. Right? Okay.\n2:56:33 Now it's time for the chunking process. Now what is chunking? First look at this. There are two parameters which\n2:56:39 I've specified. Chunk size which is a,000 and chunk overlap which is 200. So\n2:56:45 let's break this down a bit. Going back to our document. So chunk size was 1,000 tokens. So let's say that this was a\n2:56:54 chunk for example. Okay, obviously that's not going to be a thousand tokens, but just as like uh\n2:57:00 demonstration purposes, let's assume it is. So this is saying as soon as you've reached 1,000 tokens, you create a new\n2:57:06 chunk. So let's say 1,000 tokens ended here. So this would be the start of a new chunk like such. Okay. And you keep\n2:57:12 going and going and going until the end of the document. But what if the what about the second parameter? The second\n2:57:19 parameter is specified overlap and that's essentially saying let me use it in a different color that your chunks\n2:57:25 consecutive chunks should have some tokens um which are which exist in both\n2:57:30 for example because it was 200 the second chunk is not going to start from here. It's actually going to start\n2:57:37 something like this. They're obviously going to be the same length uh in terms of tokens but\n2:57:43 they will have some tokens which will be in both chunks. So for example, this part will be in both cuz that's the\n2:57:50 overlap. 200 tokens to be precise. Okay, so that was just a brief overview of what chunks are in uh rag. Okay, so\n2:57:59 that's that part done. And again, this recursive character text splitter is one of the imports we did. Okay,\n2:58:08 so this text splitter um chunking process, we now apply it to all of the\n2:58:14 pages, all of our nine pages in our document. Okay. And this piece of code essentially\n2:58:22 saying this, the chroma vector database, we're going to be using a chroma vector database to store all of our vector\n2:58:27 embeddings, by the way. But the uh the place where we want our chroma vector\n2:58:33 database to be will be specified in this file path. And the collection's name will be called stock market. Now, you\n2:58:39 can specify it wherever you want obviously, but I've just specified it to be in the same folder. Okay.\n2:58:47 So this is just an if statement to make sure that uh if this is the first time\n2:58:53 we're running this command uh if we're running this file uh if this collection\n2:58:58 doesn't exist we will create the um collection in the specified directory.\n2:59:05 Okay, again not too hard yet. Now here comes a try except command u try accept\n2:59:11 block. So this is where we actually create the vector embedding uh where we create the chroma vector um\n2:59:19 database and these are just parameters which I specify. So for example, how I want the pages to be split, what\n2:59:25 embeddings to use, where to store it and the collection name. The collection name being stock market, right? And if there\n2:59:30 is an error, it will throw an error and if it's successful, it'll print on the terminal. Okay, awesome. So now we\n2:59:37 create something called a retriever. So the retriever is quite important in rag.\n2:59:42 It's well obviously the first part of rag retrieval augmented generation. So the retriever is what actually well\n2:59:49 retrieves the chunks the most similar chunks. Um the search type which we're going to use similarity. It's just the\n2:59:56 default anyway. Uh you don't really need to know how that works to be honest. But what you do need to know is this part.\n3:00:03 So in this code I have made sure that every time uh it goes the amount of\n3:00:09 chunks it uh outputs back is five. Why? Because k here is the amount of chunks\n3:00:16 to be returned. So I've set it as five. Now I'm pretty sure if we go to the\n3:00:21 actual documents here the default the default is four. Okay. So uh this is\n3:00:28 just a parameter which you can uh set. Now you don't want it to be too high of course or too low. So you want like a\n3:00:34 good middle ground and 405 is a good middle ground in my opinion. Okay. So now let's create our tool. So again we\n3:00:42 use decorator tool. And the tool's name is going to be this retriever tool. It will input it will take in a query and\n3:00:49 it'll output a string. So the dock string is as follows. This tool searches\n3:00:54 and returns the information from our document. Okay self-explanatory.\n3:01:00 uh and obviously we need to invoke it to the retriever. So whatever query we ask\n3:01:06 for example uh what was Apple's performance in 2024 that will be the query and that will be passed to our\n3:01:13 retriever which will grab all the chunks the most the top five most similar chunks. Okay. Now if we don't if there's\n3:01:20 nothing similar uh which it finds for example if I say something like uh who's\n3:01:26 Bob the builder something like that right obviously Bob the builder is not in this document uh so it will return as\n3:01:33 I found no relevance information in the document and uh this will be passed to our LLM agent okay if it does find it\n3:01:41 though what we'll do is we'll create an empty list and we will store all of the\n3:01:46 similarity um us the all of the chunks which it found and then return those results uh\n3:01:53 through this. Okay, still it's quite easy still uh and this piece of code\n3:02:00 we've already come across. There is only one tool. So we just bind that tool to our\n3:02:05 LLM. And this also code we have also we've uh done many times. It's the uh\n3:02:14 creation of the agent state. And again we're using our add messages reducer function. All of this we've covered many\n3:02:20 times so you should be quite familiar with it. Okay. So now we create the should continue function and the should\n3:02:26 continue function uh is going to be the underlying function between our conditional edge behind our conditional\n3:02:32 edge. So it will check if the last message contains any tool calls. If it\n3:02:37 does then we um proceed. If it doesn't then we'll just end\n3:02:44 right. Okay. So now we specify the system prompt. Now this system prompt is\n3:02:49 going to be quite big. So let me copy and paste it here. Now the reason is quite big is I want to specify as much\n3:02:56 information to the LLM so that it knows what to do. Right? So I've just said you're an intelligent AI assistant who\n3:03:02 answers questions about the document uh loaded into your knowledge base. Uh you\n3:03:07 can read the rest if you would like. But I've also written this. Please always site the specific parts of the document\n3:03:13 you use in your answers. This is really just to make sure it's not hallucinating. Right? because as we know\n3:03:19 hallucination is quite a big problem with LLMs. So this is just to make sure um hallucinations are kept to a bare\n3:03:27 minimum. Okay. All right. So now we create a dictionary of our tools and we\n3:03:35 now create the underlying function which will be our LLM agent. So this function will call the LLM with the current state\n3:03:42 and you can see it converts the messages to a list passes the system messages and passes it to our LLM which is defined\n3:03:49 like this and it will just return the messages aka the updated state. Okay, this should be like such.\n3:03:59 Okay, awesome. So now we create our second agent which will be the retriever agent which you saw on the in the graph\n3:04:06 which I showed you in the introduction. So the retriever agent executes the tool calls from the LLM response. So what is\n3:04:13 this code actually saying? Well, all in all, this massive piece of code really\n3:04:20 just says if there is a tool, if the tool name is within the is a proper\n3:04:26 specified tool, aka if it's retriever tool, then actually run it. If it's not,\n3:04:32 then we will output the result as input in incorrect tool name. Please retry and select the tool from list of available\n3:04:39 tools. It's just for checking if a if the tool which is decided from the LLM\n3:04:44 is valid or not. So that's all what this is doing. If it is valid, it will invoke it and we will store the results uh like\n3:04:52 this and we will return that. Okay. Again this should be agent state like\n3:04:59 such. Okay. So we've created all of our our two um AI agents now and now we're\n3:05:07 going to create the graph itself. So like how we've done initialize it through state graph and then we're going\n3:05:14 to add our two AI agents as nodes with their respective\n3:05:19 actions and we are now going to add the conditional edge. So which will be llm\n3:05:26 which will be start from l lm and the should continue function is the function which will be um the underlying function\n3:05:34 and this is a uh true false statement and this is the edge the set entry point\n3:05:39 all of this we've covered many times so again should be quite familiar to you and last but not least compile the graph\n3:05:48 and store it in a ragation okay one last thing though uh I've created\n3:05:55 this function and this function is just a function which allows us to keep asking questions to our graph and keep\n3:06:02 receiving qu uh answers back and if you want to exit we can write either exit or quit um and it's just a simple while\n3:06:10 loop that's all it is okay and it prints the answer okay so that's the actual code\n3:06:17 complete now we're going to test it and see uh if the if this is reliable or\n3:06:23 not. Okay. Okay. So, let's actually test this now um by doing python rag agent.\n3:06:31 py. Let's run this. Okay. PDF has been loaded and has nine\n3:06:38 pages. Created chromo vector data uh chroma database vector store. So, where\n3:06:43 is this stored? Well, you can see that this is uh by the way, this will all be on GitHub as well. But this is the\n3:06:49 Chroma database and its respective um bin bin files. Okay. And we can even\n3:06:56 view it. But it'll look something like that. Okay. But because this has been created,\n3:07:02 this is a good sign that everything is working. Okay. So, let's ask a simple question. Uh let's ask something\n3:07:11 like how was the S&P 500\n3:07:16 uh performing in 2024? Enter. So it's\n3:07:22 calling the retriever tool uh with the query this uh its result then puts that\n3:07:27 complete back to the model and the model has given us this. In 2024, the S&P 500 delivered a total return of this with a\n3:07:34 23% increase late 1990s and all of that stuff uh magnificent 7 and has given us\n3:07:39 the uh respective uh citations as well. Now, how can we verify this is uh correct? Let's\n3:07:45 see. So, notice how if you remember this part, the total\n3:07:52 return of approximately 25%. Well, the reason I prom I asked it for this is because that's exactly what uh\n3:08:00 over here it stated the benchmark roughly at 25% 23%. Uh remember this\n3:08:05 late 1990s part that's exactly what this is saying here as well and this was\n3:08:12 correctly defined in the first document. So this is clearly working now right it\n3:08:17 can't have made up this information. So that means our rag is successfully set up. Now I can ask as many questions I\n3:08:22 possib as I want now but now let's see if there is something which is not\n3:08:28 included in the rag. So for example we can say something like how did open AI\n3:08:34 perform in 2024 retrieve a tool called back to the\n3:08:40 model. Okay, now look at this. Uh if I\n3:08:46 do it like that, the documents do not provide specific information about OpenAI stock performance, which is true\n3:08:51 cuz OpenAI is not a publicly traded company. Uh and yeah, it got that\n3:08:56 correct. So no hallucination there. So you can clearly see that this is working\n3:09:02 uh completely fine. And that ladies and gentlemen is how you create a retrieval\n3:09:07 augmented generation graph in Langraph. Okay.\n3:09:12 Awesome. All right people. So that brings us to the end of this course and I hope you liked it and I hope you\n3:09:19 learned a lot about Langraph. Now although this course is finishing here, your journey in Langraph\n3:09:25 is just beginning. Just think about how many cool AI projects, AI agent systems you can make now. Maybe your own Javis\n3:09:31 as well. Now, if you have any further questions related to the course material\n3:09:37 or just things in general or just want to say hi, you can always message me on LinkedIn. With that being said, thank\n3:09:43 you so much for watching this course and I hope to see you in another course. Take care.