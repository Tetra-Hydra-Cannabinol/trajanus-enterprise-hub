Title: LangChain Crash Course for Beginners
Channel: freeCodeCamp.org
Video ID: lG7Uxts9SXs
URL: https://www.youtube.com/watch?v=lG7Uxts9SXs
Duration: 1:05:29
Level: BEGINNER
Application: LangChain
Topics: LangChain, LLM, Prompt Templates, Chains, Agents, Vector Stores, Streamlit, OpenAI API, Pets Name Generator, YouTube Assistant
Ingested: 2025-12-21
Source: Playwright Browser Extraction
==============================================================================

0:00 Lang chain is a framework designed to simplify the creation of applications using large language models it makes it\n0:06 easy to connect AI models with a bunch of different data sources so you can create customized NLP applications\n0:12 Rashad Kumar created this Lang sync course for beginners he is an experienced engineer and a great teacher\n0:19 let's learn about what langchin is sulang 10 is an open source framework\n0:25 that allows developers working with AI to combine large language models like\n0:30 gpt4 with external sources of computation and data the framework is\n0:36 currently offered in Python in JavaScript well typescript to be specific and you can combine large\n0:44 language models like gpt4 from open AI or hugging phase to your own application\n0:50 so it's an open source framework that allows you to build you know AI llm applications allows you to connect a\n0:57 large language model like tpt4 to your own sources of data and we are not\n1:02 talking about you know pasting a snippet of text into chat GPT prompt we're\n1:07 talking about referencing an entire database filled with your own data so it could be you know a book that's in PDF\n1:15 format that you have converted into the right format for these llms to use which\n1:21 are known as Vector databases and not only that once you get all this information you need you can have leg\n1:28 chain to perform a certain Action For You by integrating external apis so\n1:33 let's say you want to send an email at the end of you know whatever task you did with your given data set and this is\n1:41 where the kind of the main Concepts come into play for the Lang chain framework\n1:47 so I built this diagram to better you know kind of understand the concepts so\n1:52 you have three main kind of Concepts you have components chains and agents So\n2:00 within components you know we have llm wrappers that allow us to connect to a\n2:06 large language model like gpt4 or hugging face then we have prompt templates\n2:13 prompt templates allows us to avoid having to hard code text which is the\n2:19 input to LLS and then we have indexes that allows us\n2:24 to extract the relevant information for the other labs the second concept is change the chains\n2:32 allow us to combine multiple components which are these here\n2:37 together to solve a specific task and build an entire application\n2:44 and finally we have the agents that allows llm to interact with its\n2:50 environment and any of the external apis remember how I talked about the task you\n2:56 want to perform after you have retrieved the information there is a lot to unpack\n3:01 in Lang chain and new stuff is being added every day but on a high level this\n3:06 is what the framework looks like but I have built you know kind of a demo app\n3:11 as you know projects are the way that all of this information basically sticks\n3:18 talking about requirements for this course so you will need python installed and specifically version 3.8 or higher\n3:26 and pip which is python package manager a code editor so I'll be using visual\n3:33 studio code but you can choose whatever code editor of your choices\n3:38 and also an open AI account since we'll be using the open AIS llm today to build\n3:44 our link chain applications I'll be using a Windows machine so all of the commands you'll see in the terminal will\n3:50 be for Windows users but they are quite similar on Mac OS or Linux systems so\n3:56 let's start with the first thing which is you'll need an openai account and in\n4:03 order to sign up for an opening account you can go to openai.com and click on\n4:08 login this will take you to the login screen I already have an account signed up with\n4:15 my Google account so I'll go ahead and log in the reason why we need openai is we will be using open AIS llm and we\n4:23 need an API key so if you click on your user account on the top right hand corner you can click on view API Keys as\n4:30 you can see I have generated a few of them in your case you'll not see any API keys so you can click on create new API\n4:38 key and this will give you a new openai API key now remember to save that safely\n4:46 somewhere because as you can see you can't reveal the API key again so once\n4:51 you create a new one it'll be only revealed one time so save that and we'll be using it later as an environment\n4:58 variable in our code so now let me open up my terminal here and what I'm going\n5:04 to do is create the project directory where our code will reside so I want to\n5:10 make sure I'm in the right directory on my computer here which is GitHub and\n5:16 I'll create a new directory by typing in the command mkdir and we'll call this\n5:21 Lang chain Dash llm-app now let's change our directory to our project directory\n5:28 here and let me open it up in Visual Studio code which is the editor of my\n5:34 choice again you can use any code editor that you like okay now that we have of\n5:39 the project directory open in Visual Studio code I'm just going to open up a terminal in my visual studio code here\n5:46 what I want to do now is create a virtual environment so we'll be using\n5:51 Python and we'll be creating a virtual environment and you can do that by typing python Dash mvnv and then dot VNV\n6:00 so this is the command and then dot VNV is the directory where the virtual\n6:05 environment will exist and as you can see on the right hand side where my project directory is open we have a\n6:13 folder now called dot V EnV and once we have that prepared we'll need to\n6:19 activate this virtual environment and you can do that on Windows by typing in\n6:24 E and V scripts and then activate.ps1 which is a Powershell\n6:29 script that will activate our virtual environment as you can see there is a green virtual environment text in the\n6:36 front of the prompt so this means the my virtual X environment has been active and now we'll use pip which is a python\n6:44 package manager to install the required packages that we'll be using today so I'm gonna do pip install and then Lang\n6:50 chain openai streamlit and also python dot EnV so Lang chain allows us to you\n6:57 know work with Lang chain using python open AI since we'll be using open Ai\n7:02 zlnm and then streamlit allows us to build interface for python applications\n7:08 and you'll be seeing it how streamlit makes it so easy to build interfaces and then python.env allows us to use dot EnV\n7:16 file which is where our openai API key will reside safely as you know\n7:21 environment variables in our python code hit enter okay so after some time all the packages\n7:29 should be installed and you can see my terminal is giving me a warning that a new version of pip is available so if\n7:36 you get same burning you can either upgrade it or you can ignore the warning for now I'll just hit clear so that my\n7:42 terminal has a clear screen but also I'll close it for now what I want you to do is now create a main dot Pi file so\n7:50 now we have main.pi we are python code for the site so let's start by importing\n7:57 Lang chain on the top and we'll be using llms I want to use open AI again I'm\n8:03 using open AI I know it will cost some money and I'll show you in my openai\n8:08 dashboard how much of the API calls cost but it's in cents but it is the best one if you want to use some other ones like\n8:16 the open source hugging phase llm models you can do that too Lang chin supports\n8:21 it but right now I'm happy with openai and also what I want to do is use dot\n8:27 EnV the python.env package that we installed to load our environment\n8:32 variables and we can initiate that by typing in load.env now I can go ahead\n8:38 and create a DOT EnV file and save my open AI underscore API underscore key as\n8:46 an environment variable here and this is where you will paste the SK Dash key that was created in the openai dashboard\n8:53 so let me do that and I don't want to reveal my open AI API key okay so I\n8:59 copied my API key from my open AI account and pasted it in EnV file here\n9:05 so I'll close that now what I want to do with the first sample application here is generate pet names so let's say I\n9:14 have a pet dog and I want to generate some cool names for it and maybe we'll add few parameters where people can\n9:22 select what kind of pet it is and maybe color so let's to start with that\n9:27 function so you can define a function in Python by typing in Def and then we'll call this generate underscore pet\n9:34 underscore name and now we'll be using llm from our Lang chain library and as I\n9:41 said I'll be using openai today so this has few properties one of them is\n9:46 temperature now what temperature means is how creative you want your model to\n9:52 be so if the temperature is set to let's say 0 it means it is very safe and it is\n9:58 not taking any bets or risks but if it is set to 1 it will be very creative and\n10:04 will take risks and also might generate wrong output but it is very creative at\n10:09 the same time so I tend to set my temperature to be 0.5 or 0.6 so that you\n10:16 know it can get a little bit of creative so let's set that by typing in temperature\n10:22 and now what I want to do is use this llm to create cool names for my pet\n10:28 which is in my case a DOT so I'll type something like I have a dog pad and I want cool names for it suggest me five\n10:36 cool names so that's what our luncheon app is gonna be it'll suggest five cool names for your pet so let me type that\n10:43 out as a prompt okay so I have my prompt ready and this function will return the\n10:49 name and now what we can do is if name is equal to main which is you know\n10:55 boilerplate python code I wanted to print whatever that function\n11:01 generates so generate pet name will be printed in our console output so let's\n11:06 give this a try by opening up the terminal here and typing in Python main\n11:12 dot py so as you can see it gave me five names for my pet dog Apollo Blaze\n11:20 Hershey Kona and Maverick which are pretty good names and as you can see I\n11:25 ended up setting the temperature to 0.7 so it's getting a little bit of creative again you can you know test this out by\n11:33 toggling this between 0 to 1 and see what temperature suits your needs but\n11:40 for me yeah 0.5 to 0.7 anything between that is good since I need my llm to be a\n11:46 bit creative so we just introduced one component of Lang chain which is llm the\n11:52 next thing that I want to introduce you to is promptemplate so prompt templates\n11:58 make it easy to generate these problems so you don't have to keep asking openai\n12:05 a different prompt every time right so we want to repurpose this so that people on the internet might be able to\n12:11 generate pet names so maybe we will create you know imagine that you want to create a web app where people can\n12:17 comment and read pet names we want to repurpose this prompt and also we don't want to hard code dog and if we want to\n12:24 have pet color as an option we don't want to hard code that so we want the ability to repurpose our llm prompt for\n12:34 different kind of animals and different kind of colors and the way we can do that is by using prompt templates so\n12:41 prompt template name let's just call it that and in Lang chain it's called\n12:47 prompt template and we will also have to import it from Lang change so going to\n12:52 the top let's import prompt templates okay so you're using Lang chin prompts\n12:57 and importing prompt template now you can see the squiggly line underneath it has gone so let's give it to let's give\n13:05 it an input variables so input variables are the parameters that\n13:11 can be dynamic so in our case it will be animal type right so animal underscore\n13:17 type and now we'll also have to add that as a parameter to our python function\n13:22 there we go so animal type is the input variable and the template that our\n13:28 prompt has is same as this so I'll copy this and instead of a dog pet I will use\n13:36 the input variable here which is animal underscore type so now you can imagine you can say hey I have a cat and some\n13:45 other person comes and says hey I have a cow pet and I want a cool name for it suggest me five cool names so that is\n13:52 what prompt templates allows you to do and now we'll have to also get rid of this and use chains as a concept so\n14:00 that's import chain from Lang chain from Lang chain dot chains import llm chain\n14:08 what llm chain allows us to do is put these individual components of Lang\n14:14 chain together so llm and Prime template in our case so llm chain llm is equal to\n14:20 llm in our case because we named it and prompt is equal to prompt template so\n14:26 I'll just copy this so prompt template name and instead of name let's call this\n14:31 name chain right since this is an llm chain and instead of returning name let's create a response here\n14:40 and that response basically will be name underscore chain and we'll be using the\n14:46 animal type parameter here right which is basically whatever the animal type\n14:51 the person specifies and will be returning the response here so response\n14:58 will be whatever this chain gives us the output has right now let's try instead\n15:05 of dog let's try cat right so we are using parameters to print five cool pet\n15:11 names using our name underscore chain which is the llm chain using openai and\n15:18 using this prompt template hit Ctrl s and going back to my terminal here\n15:24 let's run python main.py so now you can see we are getting a Json\n15:30 response with animal type which is cat and the text that we got is so these are\n15:37 the names that we got one is mochi or Moki nacho Pebbles tiger and whiskers so\n15:46 we got five names for our animal type cat similarly you can try cow here hit\n15:52 Ctrl s and run the python file again now it says animal type was cow and the\n15:58 text response is where our cow pet names are so one is hambone Daisy moo Moody\n16:06 Milky Way and give her hugs awesome so the other parameter that I want to add\n16:11 to our pet's name generator is the pet color because I think that is an\n16:17 important aspect when you name your pet right so pet color and so we'll add pet\n16:23 color as a parameter to our generate pet names function but also we'll have to add it as an input variable in our\n16:30 prompt template so let's add fat color over here there we go and now we'll also\n16:36 have to change the template itself so I have an animal type pet and I want a\n16:42 cool name for it and let's add it is whatever the color is so pet color so maybe it's black in color suggest me\n16:50 five cool names for my pet there we go so that is our new prompt\n16:56 hit control s and in the name chain we'll also have to add the pet color\n17:01 here so pet underscore color and that will be equal to whatever the pad color\n17:07 the person picks or says so now we can\n17:12 run this by saying cow and our cow color is black so let's let's try that out\n17:18 toggle back my terminal here and type in Python main.pi and you can see so we got\n17:24 animal type cow pet color is black and we received text response with those\n17:30 five names so one is Shadow second is midnight uh Starlight and we have Raven\n17:36 awesome so our pet's name generator is working as expected maybe I want to\n17:42 publish this as web app later right and that's where streamlib comes in streamlit will build us a web interface\n17:49 and we don't have to do much we can use our python file here to build that\n17:55 beautiful interface and then people can come in and select whatever pet kind\n18:00 they have and whatever pet color they have and it would output those five\n18:06 names utilizing the Lang chin app we built so in order to do that what I I\n18:11 want to do is instead of having all of this code in main.pi I want to create\n18:18 another file called Lang chain underscore Helper and this is where all\n18:24 our Lang chain code will go so I'm going to go into main.pi Ctrl a to select all\n18:31 the code and paste it in the langchin helper file here and then we can clear\n18:37 the main.pi so our main.pi is blank and I have moved all my code to Lang chain\n18:43 underscore helper.py hit Ctrl s so make sure you have saved that and in main.pi\n18:49 what I want to do is input our Lang chain helper Library so we can do that\n18:55 by doing Simple import statement on the top so I'm importing Lang chain helper as lch just short form so that I'll be\n19:04 able to call our generate pet name function by just using lch dot right\n19:10 also remember we did pip install streamlit in the beginning so we'll be using that here too and I'll be calling\n19:18 it throughout the python code AS SD which is just short for streamlit so in order to create our streamlit app you\n19:25 can use different text types and you can also use markdown which streamlit will\n19:31 render but one of the main things is having a title for our web interface and\n19:37 you can do that by doing St dot title and we'll call this pet's name\n19:43 generator right hit save and now I'll just show you how to run a streamlined app where\n19:50 you can do that is open the terminal and type in streamlit run main.py hit enter\n19:56 and let me open my browser on Port 8501\n20:02 there we go so as you can see right out of the box we have this interface that was built using streamlit\n20:09 and again if you haven't heard about streamlit it's an amazing tool you can go to streamlit.io and go through their\n20:16 documentation on how to even make your web app better since I'll be using some\n20:22 basic components from streamlit to display our pet's name generator beautifully so let's get back to our app\n20:31 here so back in our code editor I'll hit Ctrl C in my terminal to stop the\n20:36 streamlit app and bring my terminal down and now we need some variables and Logic\n20:43 for the ability for users to pick their pets and the pet color so one of them is\n20:49 the animal type right whether it's dog cat or a cow will give a sidebar selection for our users so SD dot\n20:58 sidebar dot select box will allow you to do that and you can input what the\n21:04 question is so what is your pet question mark and then you can include the\n21:11 options so it will be a drop down where people can select cat right dog and cow\n21:19 and maybe a hen right so think of all the pets then people that people can\n21:24 have maybe hamster is more popular I guess so cat dog cow hamster and then\n21:29 you can just keep going so that is the animal type and I can show you how this looks on our streamlit apps so streamlit\n21:35 space run space so you can see that and I can zoom in a\n21:41 little bit on the left hand side we have a sidebar now and you can select what kind of pet you have so what is your pet\n21:48 the next logic that I want to build is another option to select the color of\n21:54 your pet but I want it in a way that once you have selected the pad type so\n21:59 animal type right if it's cat it should say what color is your cat and we can do\n22:04 that by if statements so if animal underscore type is cat right I want pet\n22:11 color which is another variable we pass to our generate pet name function here\n22:18 you can say pet color is equal to and then we use the select box component\n22:24 from streamlit to ask what color is your\n22:29 cap now I feel like there can be different variations so you can't just\n22:34 put in black blue white orange you know since with cows and even cats\n22:42 and dogs you can have multiple colored pets right like a white dog with black\n22:47 spots on it so we can't have a select box let's just keep this as a text to you and I just thought of that as I was\n22:55 building this right so instead of a select box we have a sidebar with a text\n23:00 area that asks for what color is your cat and I also want to maybe have a\n23:08 limit of Maximum characters that people can put into this because remember we are calling the open AI API and the API\n23:15 calls depend on the amount of information you are sending in the prompt template so if our prompt gets\n23:22 bigger we'll be charged more so in order to limit that let's have a Max character\n23:28 property here again this is available on Shameless documentation and we'll use\n23:34 the label ER so the label is what color is your cat and the maximum characters that users will be allowed to put in is\n23:40 15 and we can hit save what you can do is copy this over for dog cow so I'll\n23:48 put dog here and what color is your dog or dog for cow it will be what color is\n23:54 your cow and then I think we're left with one which is for hamster again I'll\n23:59 just copy this and paste for hamster okay there is an efficient way to do\n24:06 this but I'm just gonna copy the code that I already have go back to my browser here refresh my streamlit page\n24:13 and now you can see if we select dog it will say what color is your dog and you see the text area which has a limit of\n24:20 15 characters similarly if you select the cow you can see it asks\n24:26 what color is your cup so both of the parameters have been set right now what\n24:32 I want to do is send this information to our Lang chain helper right because this\n24:38 is where it will generate those names and give it back to us so let's do that\n24:44 so after we have set the pet color right because that's the last question\n24:49 we ask our users what we want to do is have a variable here called response\n24:56 and response is equal to LC Edge which stands which is just short for Lang\n25:02 chain helper here and the function in the Lang chain helper is generate pet\n25:08 name so I'll copy that over so you do lch dot generate pet name so we are accessing\n25:15 that function animal type was the first parameter that we need again I'm using\n25:21 animal type as a variable here maybe we can say user\n25:27 underscore animal type and I'll have to change that over here\n25:33 over here over here and over here again just so that you're not confused so\n25:40 two parameters animal type and pet color and then I'm using the user animal type as a variable on our main.pi so user\n25:48 underscore animal underscore type and the second parameter is pet color again\n25:53 you can do the same here so user underscore pet underscore color and you'll have to update all of these here\n26:00 just to avoid confusion so we are passing these variables that the user\n26:06 said so user will say I have a dog and its pet color is white and we are\n26:12 passing those to our generate pet name function and then we'll just write that\n26:19 as a text field so our text Will field will just reply with response so let's\n26:25 save that now let's go back to our browser here hit refresh\n26:31 now let's select dog and type in the color black\n26:37 and you can hit Control Plus enter to apply and you can see we got a response\n26:45 with the five pet names right and\n26:51 what you can do to display this beautifully is set an output key right\n26:59 so let's go back to our Lang chain helper here and in the name underscore chain We'll add a third property called\n27:06 output key right and the output key is pet underscore name so basically instead\n27:13 of giving us a text output it will associate those five names that it\n27:18 generated to this output key and we can access this in our main.pi so instead of\n27:25 just returning the entire response so the whole text here see how it looks\n27:30 weird we'll just we'll just access the names that it generated and we can do\n27:36 that by doing response and then accessing that underscore name which was the Kiwi set\n27:44 so hit Ctrl s go back to our browser window and click refresh this time let's\n27:49 go with the cat which is white hit Control Plus enter to apply and you can see it displays the text now\n27:58 better right it looks beautiful and we have the recommendations here as snowy\n28:04 marshmallow cotton pull blizzard let's go over the brown hamster so hamster\n28:10 and brown Coco mocha Chestnut caramel biscuit\n28:16 love those names so now as you can see we have a streamlit app and we are using Lang chain to generate\n28:23 five cool pet names for the pets that we might have and we saw how you can use\n28:30 another lamp prom templates and the chain which are three main components of\n28:38 Lang chain but now the important one that's left is Agents right so agents\n28:45 allow llms to interact with the environment so think of apis or things\n28:51 you want to do after Gathering the information so going over the Lang chain documentation about agents the core idea\n28:58 of Agents is to use an llm to choose a sequence of actions to take in Chains a\n29:05 sequence of actions is hard coded in code whereas in agents a language model is\n29:12 used as a reasoning engine to determine which actions to take and in which order\n29:18 and there are several key components Langton provides a few different types of agents to get started even then you\n29:25 will likely want to customize those agents depending on the personality of the agent and the background context you\n29:32 are giving to the agent and then there are tools so tools are functions that an\n29:37 agent calls there are two important considerations giving the agent access to the right tools and describing the\n29:45 tools in a way that is most helpful to the agent so let's test it out so we\n29:52 already have a pet's name generator thing that's working for us right gives\n29:57 us a name for our pet now let me create another function here\n30:03 which will name Lang chain underscore agent and before we can interact with\n30:10 the agent we have to import the Lang chain Agents from the framework so you\n30:15 can do that by adding these three import statements on top so we are importing\n30:20 tools we are also importing the initialization of the agent and the\n30:26 agent type so coming back to our function here so first we'll Define the llm that we want to use and I still want\n30:33 to use the openai llm and the temperature will set it to 0.5 here and\n30:39 then we can load some tools that will perform the given action so\n30:45 there are various tools that are available and again you can go through the availability of tools or the list of\n30:53 tools on the link chain documentation but I'll be using Wikipedia which will\n30:59 be the first tool I want to use and I'll get to it why I want to use Wikipedia and the other one is llm matte because I\n31:06 want to perform some matte and this is to just showcase what agents can do right and then the llm that we'll be\n31:14 using is defined here which is the open AI so llm is equal to llm right and now\n31:20 we'll have to initiate the agent so agent and to initialize its initialize\n31:27 underscore agent and here you specify the tools that will\n31:32 be providing it which is stored right here which is Wikipedia and lmat the llm\n31:38 we want to use right and the agent type so one of the agent\n31:43 types that's available in the quick start guide for langchain is the react\n31:49 and you can go to the agent types documentation here so zero shot react is\n31:55 the one that I'll be using decision uses react framework to determine which tool\n32:00 to use based solely on the tools description so heading over to our code\n32:06 and the way you define that agent type is by setting it here and we'll set the\n32:13 verbose flag to True which means it'll show us the reasoning that'll happen in\n32:19 our console so that's the agent we want and we'll create a result here where we\n32:26 run the agent and now you can specify the tasks so you want to perform through\n32:32 this agent so since our app is solely based on pets let's ask it what is the\n32:38 average age of a dog and I'll ask it to do some math\n32:44 and that is the reason why I loaded the llm math tool here multiply the age by\n32:50 three and at the end we'll print result so that looks good and I will change\n32:55 this so I'll comment this out instead we'll print whatever this generates so\n33:01 Lang chain agent right hit save and now we can run this and just to demonstrate\n33:07 it I'll not be linking this to our streamlit app which was the web interface I'll just run the\n33:14 Lang chain underscore helper python file just to Showcase you how agent works so\n33:20 before I do that I have to make sure that Wikipedia is installed through pip\n33:25 so pip install Wikipedia will install that python Library so now if I run the\n33:31 langchin helper file we'll see the agent in action okay so you'll see that it\n33:38 finished the chain and the answer was the average of a dog is 45 years when\n33:43 multiplied by three but the final answer that it got was 15 right so the average\n33:49 age of the dog is 15 and then it multiplied by 3 which is 45. so you can\n33:55 see that it was able to grab the information from Wikipedia which is 15\n34:01 as the average age of a dog and it was also able to perform the math and get to\n34:08 this right and now since we set the verbose flag to true you can see the\n34:13 reasoning that went into it right and I'll increase my terminal and with no size here and get rid of the file\n34:21 explorer on the right so you can see I need to find out the average age of a\n34:26 dog action is Wikipedia action input is averages of talk and this is the\n34:32 observation that it found right so it did scan few pages on Wikipedia\n34:38 thought I now know the average age of a dog and the age of the oldest dog right and then action is calculator where it's\n34:46 trying to multiply 15 which is the average age by three because that's what we asked it to do awesome so that's how\n34:53 the agents work and I believe we have kind of covered almost all components\n34:59 within the langchin framework the only thing that's left is indexes right so\n35:05 what are indexes basically as you can see we are still working with the open\n35:12 AI llm but we are also not providing any of the custom knowledge right so we are\n35:18 still relying on open Ai and the information that they have gathered but\n35:23 with langchain you can also provide your own knowledge or knowledge base on which you can ask llm to do certain actions so\n35:32 think of a PDF file or even URLs that you can script or maybe you have a large\n35:40 PDF file with a lot of text and maybe you want to run an llm AI chat bot for\n35:46 your own document so you can do that with the help of language in the next project that I want to showcase you will\n35:52 exactly do that will take a long YouTube video so think of a podcast which is\n35:58 hours long or a long YouTube video right so what I have here is\n36:04 the Microsoft CEO certain dealer full interview on recode but it's 51 minutes\n36:09 long and what I want to do with Lang chain is the ability to ask questions to\n36:16 this video so the context that the llm would have is strictly of that video and\n36:22 I'll be using few libraries like YouTube transcript which basically converts\n36:28 whatever URL we provide for a YouTube video and gets its transcript right so\n36:33 let's build this YouTube assistant now I'm going to show you how you can create this assistant that can answer questions\n36:40 about a specific YouTube video so coming back to the concept of indexes I touched\n36:47 briefly on it but we also saw it in the Lang chain diagram but we know that these large language models become\n36:54 really powerful when you combine them with your own data and your own data in this scenario will be the YouTube\n37:00 transcript that we are going to download automatically but you can basically replace that transcript with any\n37:07 information in this approach so it could be a PDF it could be blog post URL right\n37:13 so what Langton offers is document loaders and I can quickly show you the YouTube\n37:21 transcript one so this is the YouTube transcript and basically it allows you\n37:26 to get the transcript which will be the text version of the YouTube video right\n37:31 but there are several other document loaders that you can see on the left hand side right so you can bring in an\n37:38 S3 file you could bring an Azure blob storage file you could do Hacker News\n37:44 posts or articles right so these are some of the document loaders that are\n37:50 supported by linkchin as of now and we'll be using text Splitters and Vector\n37:55 stores so we are going to use these three components to load our YouTube video transcript split it into smaller\n38:02 chunks and then store it as Vector stores so you can think of these as little helper tools that will make it\n38:09 easy for us to load the transcript which might be thousands of lines of text so\n38:16 to get us started what I have already done is created a YouTube assistant\n38:21 directory so not be using the pets generator directory that we had and what\n38:26 I have done is pretty similar to the pet's name generator right so I have main.pi which will hold our streamlit\n38:33 interface and then the langchin helper will have the length chain components\n38:39 and I've also created a virtual environment and installed all the\n38:44 necessary packages which is link chain openai YouTube transcript also I've I\n38:50 went ahead and created dot EnV file which holds my openai API key so pretty\n38:56 similar to the pet's name generator and now we can start with the lag chain\n39:01 helper first so the first thing that we are going to import is the YouTube loader that we saw right which is a\n39:09 document loader so from langtin dot document loaders we are importing that YouTube loader and the second important\n39:15 thing we need is the text splitter so as I showcased that the video that I have\n39:21 is 51 minutes long you could also pick up a podcast like Lex and they have\n39:29 podcasts that are three hours long and which means you'll have thousands of\n39:35 lines and that is where we'll use the the text splitter to break down those\n39:41 huge transcripts into smaller chunks and I'll show you how and for the rest of the inputs we are gonna input the lag\n39:49 chain components like the llm which will be open AI prompt template and llm chain\n39:54 the other thing coming back to indexes we'll be using Vector stores so I'll be using the phase\n40:02 library and I'll quickly show you what the face library is phase is a library by meta or\n40:11 Facebook for efficient similarity search and you might have heard of other Vector\n40:17 stores or databases like Pinecone or vv8 right but I'll be using phase for this\n40:25 project so let's start with writing some code so I've done all the necessary\n40:30 inputs here the only input that's left is the dot EnV which will load our\n40:37 environment variables and I'll initiate dot EnV here also since I'll be using\n40:44 openai embeddings so we'll initiate that to here and I forgot to import those so\n40:51 I'll import the open aim bearings and now we can create our first function to\n40:57 create a function we know that in Python it's deaf and let's name this function\n41:02 that will be be creating a vector DB\n41:08 create Vector DB from YouTube so that's a pretty big function name right but I\n41:14 want to specify what we are doing and we'll be using phase here also for the\n41:20 parameter let's give this a required parameter which is the video URL right\n41:25 so we'll be pasting this video URL in our streamlit interface and that's what\n41:30 we'll be using and this will be a string right so the first thing we want to do\n41:35 is load the YouTube video from the URL right so we'll use loader which we\n41:42 imported on the top so YouTube loader Dot from YouTube URL and we'll pass the\n41:50 video URL parameter here after we have loaded the YouTube video I want to save\n41:55 this into the transcript variable so we'll create transcript here and we'll\n42:00 just do loader dot load and this should give us the transcript now we'll be\n42:07 using text splitter and I'll specifically tell you why so text\n42:12 splitter and we imported it here as recursive character text splitter you\n42:18 can specify few parameters when using this so the first one is chunk size\n42:24 which will set to 1000 and chunk overlap so chunk size is how much each chunk\n42:31 will contain so for me it will be 1000 right and then overlap is once it has\n42:37 created those individual docs from the long transcript it'll have an overlap in\n42:43 every document so document one the last hundred words would also be included in\n42:48 the document twos first hundred words right so that is what overlap is and now we'll save them into a docs\n42:56 variable so text underscore splitter not split documents as the function and\n43:03 we'll provide the transcript that we had loaded from the YouTube url there we go\n43:08 okay now let's also initiate the phase so\n43:14 phase Dot from documents and we will be using docs which we stored here right\n43:22 docs and we'll be using the open Ai embeddings and we'll return this DB\n43:29 okay so now on to the explanation why we have to split the text so basically what we\n43:37 are doing at the text splitter is we have taken over thousands of lines and\n43:43 split up the documents so it has taken very large transcript over and split it\n43:49 up into chunks of 1000 so that is the first step now you might wonder right so we can't just provide thousand lines to\n43:57 the open AI API remember there is a token size or a limit on how much\n44:04 information you can send to open AIS API and that is why we have split the amount\n44:10 of context we'll be sending for for a YouTube transcript right because the model that I'll be using is the text\n44:18 DaVinci 003 and as you can see it can only take\n44:24 4097 tokens so I cannot send the entire transcript to open aiz Ai and that is\n44:32 why we'll be splitting it and storing it into Vector stores again this is quite technical I'll not\n44:40 go into much detail but vectors basically are a numerical representation\n44:45 of the text we just created here right so the core responsibility of this\n44:52 function is to load the transcript right take all the text that's in the\n44:57 transcript split it into smaller chunks and then save those chunks as Vector\n45:03 stores again we can't just provide all of these Vector stores to the open AI\n45:08 right we can't just send over the 10 000 or maybe even 50 chunks that we have\n45:15 created of smaller text that's where we'll use phase to do a similarity\n45:20 search right and that's what the next function will be and before I write that\n45:25 next function we'll see if this works so video underscore URL so I'm gonna hard\n45:32 code the video URL that we have for the podcast and see if we get the smaller\n45:39 chunk documents right so let's print this function at the end\n45:47 hit save and we'll open the terminal make sure your virtual environment is\n45:53 activated and you have installed the required packages again all of this will\n45:58 be available on GitHub for reference later but let's run the line chain helper python file again it'll take some\n46:06 time to do the computation I missed to write print so we'll have to\n46:12 print this whatever this function returns which should be the database that we created right so let's run it\n46:20 again and this time we should get the vector stores that were created and so\n46:25 instead of DB if I return docs you'll see those chunks\n46:32 so if I expand my terminal here you can see we have quite a few text here but\n46:39 here are the docs right so you can see that there's a document and then it\n46:46 starts with the content and you'll see multiple document chunks so these are\n46:51 the chunks that we created from the larger transcript so this is one right this is the second one\n46:58 and so on I know the formatting is weird so you can't really tell where the new\n47:04 document starts but yeah this is all the chunks that we have awesome so our\n47:09 function to create the vector DB from YouTube url is working as expected so\n47:14 I'll get rid of this print statement and full return DB here now for the next\n47:19 function which is going to be getting off the response on our query we have to\n47:26 ask this YouTube video right so let's create that function we'll name it get\n47:32 underscore response from query again pretty self-explanatory name for the\n47:39 function itself and we'll pass few parameters to this function one is DB the important one will be query which\n47:47 will be the question that the user asks and K which is another argument that\n47:52 I'll go over this is used for the similarity search that will do so keep in mind the amount of tokens that the\n48:00 text DaVinci 3 Model can take right so keep that in mind it's 4097 so I'll just\n48:06 add a comment here saying text DaVinci can handle 2097 tokens right now in\n48:15 order to do a similarity search we'll save that into a docs variable within this function so DB\n48:22 is what we'll use we'll perform a similarity search on the DB which is the database we created in the previous\n48:29 function so gb.similarity underscore search and the search will be basically\n48:35 the query so the first thing I want to do with this function is basically search the query relevant documents so\n48:42 let's say in this podcast they talk about a ransomware somewhere so right\n48:48 here they talk about ransomware right and if I want to ask a question saying what did they talk about ransomware so\n48:54 my query is just about ransomware that that they talked about in the podcast so\n49:00 it will only search the document that has details about ransomware so we'll\n49:06 not send the entire documents that were created but just the one that is\n49:12 relevant to the query that the user made I hope that makes sense and this is also\n49:17 where we'll pass the K as argument and I'll tell you what K is so remember that\n49:25 we can have 4097 tokens but our chunk size is 1000.\n49:31 so that means we can kind of send four documents right because each document is\n49:39 a size of thousand so let's set that value to four okay so we'll be sending\n49:44 four relevant docs based on the query that the user made now I'll create another variable called docs page\n49:51 content and what we'll basically do is join those four docs that we'll be sending\n50:03 okay so we got those four docs and we are joining them to create one dock\n50:08 because the Toca limit is 4097 and here we'll almost have 4 000 tokens being\n50:15 sent to the text DaVinci 3 mod awesome now let's work with the llm right so\n50:23 pretty similar to what we did with the pet's name generator we'll initiate the llm to be open Ai and\n50:31 as I said the model that I'll be using is text DaVinci 3 so let me go to the\n50:37 open AIS documentation copy this model name come back here and paste it and\n50:42 there is some white space at the end so we'll get rid of that and the second thing we did with the pets name\n50:48 generator was prompt right so prompt templates is the is another main\n50:53 component of Lang chain so we'll use that and this is variable define what the prompt should be for the open AI llm\n51:02 so the first thing would be to specify the input variables right so the first\n51:08 one is question or query right so whatever the question is being asked by\n51:14 the user in Docs so docs is basically the similarity\n51:19 search we did there we go now the template that we'll be using is a prompt\n51:25 that I've created here so I'm gonna copy this really quick since it's a long prompt okay so I've copied the prompt\n51:32 basically it says you're a helpful YouTube assistant that can answer questions about videos based on the\n51:39 videos transcript right answer the following question and this is where the input variable goes\n51:46 whatever the question the user is asking by searching the following video transcript which is the docs right so\n51:53 docs is basically the similarity search we did only use factual information from the\n51:58 transcript to answer the question if you feel like you don't have enough information simply say I don't know\n52:04 right because we don't want the AI or the llm to hallucinate your answer should be needed so that is basically\n52:11 the prompt that we'll be using to answer questions and now we'll be using another\n52:17 main component which is chain within the Lang chain so let's create an llm chain\n52:23 where llm is equal to llm because we specified it here that will be using\n52:29 openai model text DaVinci 3 and prompt is equal to prompt which we specified\n52:36 here using prompt template okay now we just have to learn the response so\n52:43 I'll create a variable call response it will do chain dot run which will basically run our chain since we had\n52:49 question as the input variable here we'll say that question is equal to\n52:56 query because that's what we were referring to it on the previous function and\n53:03 Docs is equal to docs page underscore content\n53:09 remember because we joined all the four documents because K is set to 4 to\n53:17 be one doc because we can we have the ability to send four thousand tokens and\n53:22 then response is equal to response dot replace and this is just some\n53:29 formatting that we have to do because if you remember in the pet's name generated to the response we were\n53:35 getting was in one line and it included new line characters so we'll replace that with\n53:42 some white space and we'll return response okay so now we can test this\n53:50 out as it is in the console by hard coding the question and the URL which we\n53:56 already did so let's get ready for that but also build the interface because it'll be really quick with streamlit so\n54:03 coming over to our main dot Pi let's do some inputs on the top so pretty similar\n54:08 to what we did in our pets named generator so streamlit I'm importing it as St and the langchain helper where are\n54:17 all of the Lang chain code is and I'm also importing text wrap basically it\n54:22 gives you the ability to wrap text so that you're not you don't have to scroll the page the title of this page will be\n54:31 YouTube assistant right so YouTube assistant and now on the sidebar we can have those\n54:39 parameters that we need from the user with sidebar I want to create a farm so\n54:45 we have a submit button at the end so SD dot form is how you do that\n54:52 and you also have to specify a key so key is my form again this is all\n54:59 streamlit stuff and let me know in the comments if I should create a course on streamlit on how to build you know cool\n55:05 python interfaces I love this tool because I don't have to care about building a front end and the first\n55:12 parameter we had in our length chain helper was the YouTube url right so\n55:18 we'll save that as video URL so YouTube url is equal to SD dot sidebar text\n55:27 as we used in the pet's name and we'll just say that the label is what is the\n55:34 YouTube video URL and we'll give a Max to maximum character limit of 50 because I don't think a video URL can exceed 50\n55:42 characters uh the other parameter we had was the question that the user can ask and we'll save it as query here so St\n55:49 dot sidebar dot text underscore area right and then the label will be asked\n55:57 me about the video so again you can have a limit here right so maybe you can only\n56:05 ask questions that are not long enough so we'll set max characters 50 here too\n56:11 and also set the key to query here okay and at the last since I created this as\n56:18 a form we'll give it a submit button and the label here will be submit now\n56:25 so if Kiri which is the question the user can ask and YouTube url exist right\n56:32 what I want to do is basically run this function to give us the answer right so\n56:40 we'll be as we are already importing the link chain helper on the top as LS lch\n56:46 so that's what we'll be using here so DB which is the database will be equal to\n56:53 so remember we have to pass the video URL uh to the create Vector DB function\n56:59 to create a new Vector database based on the transcript that we got so DB is\n57:05 equal to lch which helps which is basically that we are accessing this python file and then the create Vector\n57:12 DB from YouTube url function and we'll pass the YouTube url as the parameter because remember we\n57:19 just need the video URL here response comma docs is equal to and now we'll get\n57:28 a response which we can do by running this function which is get response from\n57:33 query and remember the parameters that will be passing so lch dot getresponse\n57:40 from query the first one is DB which we just created right and query is the\n57:46 question that I will be asking so um right here whatever the user asks will be the query\n57:53 so I am missing a comma here as I'm going through my code so I'll add that and now we'll save that response in our\n58:02 interface with streamlit so let me create a sub header here which will say answer right and below that we'll have\n58:10 St dot text and we'll wrap that text\n58:15 and this is where the text wrap library is being used you'll you'll see this in the interface once I run it so text wrap\n58:22 dot fill and whatever the response we get from the length chain function\n58:30 you can also set the width of this text area to be 80 let's go with 80 and see\n58:36 how that looks and that is basically it so two parameters for necessary one is the\n58:42 YouTube video URL and the question that the user asks right and we are passing so if the both of those parameters exist\n58:49 first we are creating the database from the YouTube video URL and then we're getting the response based on the\n58:56 question that the user asked using the llm so now we can run our streamlit app\n59:02 after saving the file so if I scroll down to the bottom here for my terminal\n59:07 expand this and run stream lit run main.pi\n59:13 hit enter it should load our web interface for our\n59:18 streamlit app awesome on the left hand side you can see we need to provide a YouTube video URL so\n59:26 I'll just go ahead copy this interview video URL paste it here\n59:32 ask me about the video so let's say what did they talk about rent somewhere is\n59:42 what I want to know and hit submit okay so we have got some errors saying input variables let's go\n59:51 to our terminal and see if we have any logging okay so I found the error I was just\n59:59 missing S I thought I typed it right so instead of input variable it needs to\n1:00:05 be input variables and we'll Ctrl C to stop our streamlit app and do streamlit\n1:00:13 run run main.pi again so after adding the S hit enter and now\n1:00:20 we need the same exact information so copy this\n1:00:25 and copy the question so the YouTube video URL and what did they talk about\n1:00:31 ransomware hit submit there we go we got our answer so it says\n1:00:39 they discussed how ransomware is difficult to track due to zero day exploits and how Microsoft is making it\n1:00:45 a mission to help with secure cloud backup for Enterprises better tracking of zero day exploits and helping with\n1:00:52 enforcements they also discussed the importance of public-private Partnerships in order to prioritize\n1:00:57 cyber security and create new standards such as those for nist so\n1:01:02 remember our prompt I asked it to be as detailed as possible also say I don't know if it doesn't know\n1:01:09 what the answer is based on the transcript we provided and not to hallucinate so I think this is a pretty\n1:01:15 good answer um that we got out of this 52 minute\n1:01:20 video again you can pick a longer video and ask about anything specifically\n1:01:27 longer from podcasts right maybe the video is four to five hour Longs and you\n1:01:32 need to know a specific detail I think that's where this tool or the app we\n1:01:38 build can be really handy right but yeah so we learned a lot about\n1:01:44 Lang chain today specifically the main three main components which is llm so\n1:01:52 any of the large language models that you can use like open AI or hugging face prompt templates right\n1:01:59 and chains so how you can combine these components into chains to perform the\n1:02:05 required task and agents right remember in the pets generator we talked a little\n1:02:11 bit about agents and how they have reasoning behind the\n1:02:16 tasks that they perform because we try to calculate average age of a dog and\n1:02:22 also multiply it by three so it used Wikipedia and llm math to get those\n1:02:27 answers but also we learned a bit about indexing and Vector stores so how you\n1:02:33 can split large documents into smaller chunks and store it as Vector which is basically you know\n1:02:39 numerical representation of the documents that we created and then\n1:02:46 passing those on to the llm since there are certain limits of how much context\n1:02:52 you can send to the API but yeah one other thing I would like to mention is\n1:02:58 if you are planning to make these apps public remember we were storing our\n1:03:04 environment variables in dot EnV file and you might be wondering every ship I\n1:03:10 also created an openai API key like how much all of this is going to cost so\n1:03:16 I'll go into my dashboard in into billing to see how much did it cost me\n1:03:21 to you know basically kind of build this course out so you can see um\n1:03:28 10 cents and 30 cents so very close to\n1:03:33 less than a dollar like half of a Dollar close to 50 cents is what it costed me\n1:03:39 to make all of these queries to the openai llm the thing I was gonna\n1:03:45 recommend if you want to publish this app so that the public can use it is to have a field here uh you know with\n1:03:54 the sidebar saying open AI API key so that the users have to submit their\n1:04:00 openai API key with their app so you can have a text field here saying hey what\n1:04:06 is your open AI API key just so that you know you are not being charged and you can make that as a secret field so that\n1:04:14 the key is not displayed in the interface but you can use that key to make these queries you will just have to\n1:04:21 pass it in the Lang chain helper so whatever the variable name you decide\n1:04:27 maybe like open AI API key which you'll get the value from our streamlit\n1:04:34 interface you can pass that right here when you initiate the large language\n1:04:40 model so you'll specify openai API key as a\n1:04:45 parameter here and the value of that key which will be the variable you decide so\n1:04:51 yeah that's pretty much it for this course again we learned quite a bit about the langchin framework\n1:04:58 specifically in Python uh you know the models prompts indexes chains and agents\n1:05:03 or the five main Concepts within nag chain that I wanted to cover again I\n1:05:09 hope this helps you understand the framework itself and how you can utilize this information to build something\n1:05:16 really cool with the power of llms but if you would like to see a streamlit\n1:05:21 course again let me know in the comments but I hope you find this course helpful I'll see you in the next one peace\n0:00 Lang chain is a framework designed to simplify the creation of applications using large language models it makes it\n0:06 easy to connect AI models with a bunch of different data sources so you can create customized NLP applications\n0:12 Rashad Kumar created this Lang sync course for beginners he is an experienced engineer and a great teacher\n0:19 let's learn about what langchin is sulang 10 is an open source framework\n0:25 that allows developers working with AI to combine large language models like\n0:30 gpt4 with external sources of computation and data the framework is\n0:36 currently offered in Python in JavaScript well typescript to be specific and you can combine large\n0:44 language models like gpt4 from open AI or hugging phase to your own application\n0:50 so it's an open source framework that allows you to build you know AI llm applications allows you to connect a\n0:57 large language model like tpt4 to your own sources of data and we are not\n1:02 talking about you know pasting a snippet of text into chat GPT prompt we're\n1:07 talking about referencing an entire database filled with your own data so it could be you know a book that's in PDF\n1:15 format that you have converted into the right format for these llms to use which\n1:21 are known as Vector databases and not only that once you get all this information you need you can have leg\n1:28 chain to perform a certain Action For You by integrating external apis so\n1:33 let's say you want to send an email at the end of you know whatever task you did with your given data set and this is\n1:41 where the kind of the main Concepts come into play for the Lang chain framework\n1:47 so I built this diagram to better you know kind of understand the concepts so\n1:52 you have three main kind of Concepts you have components chains and agents So\n2:00 within components you know we have llm wrappers that allow us to connect to a\n2:06 large language model like gpt4 or hugging face then we have prompt templates\n2:13 prompt templates allows us to avoid having to hard code text which is the\n2:19 input to LLS and then we have indexes that allows us\n2:24 to extract the relevant information for the other labs the second concept is change the chains\n2:32 allow us to combine multiple components which are these here\n2:37 together to solve a specific task and build an entire application\n2:44 and finally we have the agents that allows llm to interact with its\n2:50 environment and any of the external apis remember how I talked about the task you\n2:56 want to perform after you have retrieved the information there is a lot to unpack\n3:01 in Lang chain and new stuff is being added every day but on a high level this\n3:06 is what the framework looks like but I have built you know kind of a demo app\n3:11 as you know projects are the way that all of this information basically sticks\n3:18 talking about requirements for this course so you will need python installed and specifically version 3.8 or higher\n3:26 and pip which is python package manager a code editor so I'll be using visual\n3:33 studio code but you can choose whatever code editor of your choices\n3:38 and also an open AI account since we'll be using the open AIS llm today to build\n3:44 our link chain applications I'll be using a Windows machine so all of the commands you'll see in the terminal will\n3:50 be for Windows users but they are quite similar on Mac OS or Linux systems so\n3:56 let's start with the first thing which is you'll need an openai account and in\n4:03 order to sign up for an opening account you can go to openai.com and click on\n4:08 login this will take you to the login screen I already have an account signed up with\n4:15 my Google account so I'll go ahead and log in the reason why we need openai is we will be using open AIS llm and we\n4:23 need an API key so if you click on your user account on the top right hand corner you can click on view API Keys as\n4:30 you can see I have generated a few of them in your case you'll not see any API keys so you can click on create new API\n4:38 key and this will give you a new openai API key now remember to save that safely\n4:46 somewhere because as you can see you can't reveal the API key again so once\n4:51 you create a new one it'll be only revealed one time so save that and we'll be using it later as an environment\n4:58 variable in our code so now let me open up my terminal here and what I'm going\n5:04 to do is create the project directory where our code will reside so I want to\n5:10 make sure I'm in the right directory on my computer here which is GitHub and\n5:16 I'll create a new directory by typing in the command mkdir and we'll call this\n5:21 Lang chain Dash llm-app now let's change our directory to our project directory\n5:28 here and let me open it up in Visual Studio code which is the editor of my\n5:34 choice again you can use any code editor that you like okay now that we have of\n5:39 the project directory open in Visual Studio code I'm just going to open up a terminal in my visual studio code here\n5:46 what I want to do now is create a virtual environment so we'll be using\n5:51 Python and we'll be creating a virtual environment and you can do that by typing python Dash mvnv and then dot VNV\n6:00 so this is the command and then dot VNV is the directory where the virtual\n6:05 environment will exist and as you can see on the right hand side where my project directory is open we have a\n6:13 folder now called dot V EnV and once we have that prepared we'll need to\n6:19 activate this virtual environment and you can do that on Windows by typing in\n6:24 E and V scripts and then activate.ps1 which is a Powershell\n6:29 script that will activate our virtual environment as you can see there is a green virtual environment text in the\n6:36 front of the prompt so this means the my virtual X environment has been active and now we'll use pip which is a python\n6:44 package manager to install the required packages that we'll be using today so I'm gonna do pip install and then Lang\n6:50 chain openai streamlit and also python dot EnV so Lang chain allows us to you\n6:57 know work with Lang chain using python open AI since we'll be using open Ai\n7:02 zlnm and then streamlit allows us to build interface for python applications\n7:08 and you'll be seeing it how streamlit makes it so easy to build interfaces and then python.env allows us to use dot EnV\n7:16 file which is where our openai API key will reside safely as you know\n7:21 environment variables in our python code hit enter okay so after some time all the packages\n7:29 should be installed and you can see my terminal is giving me a warning that a new version of pip is available so if\n7:36 you get same burning you can either upgrade it or you can ignore the warning for now I'll just hit clear so that my\n7:42 terminal has a clear screen but also I'll close it for now what I want you to do is now create a main dot Pi file so\n7:50 now we have main.pi we are python code for the site so let's start by importing\n7:57 Lang chain on the top and we'll be using llms I want to use open AI again I'm\n8:03 using open AI I know it will cost some money and I'll show you in my openai\n8:08 dashboard how much of the API calls cost but it's in cents but it is the best one if you want to use some other ones like\n8:16 the open source hugging phase llm models you can do that too Lang chin supports\n8:21 it but right now I'm happy with openai and also what I want to do is use dot\n8:27 EnV the python.env package that we installed to load our environment\n8:32 variables and we can initiate that by typing in load.env now I can go ahead\n8:38 and create a DOT EnV file and save my open AI underscore API underscore key as\n8:46 an environment variable here and this is where you will paste the SK Dash key that was created in the openai dashboard\n8:53 so let me do that and I don't want to reveal my open AI API key okay so I\n8:59 copied my API key from my open AI account and pasted it in EnV file here\n9:05 so I'll close that now what I want to do with the first sample application here is generate pet names so let's say I\n9:14 have a pet dog and I want to generate some cool names for it and maybe we'll add few parameters where people can\n9:22 select what kind of pet it is and maybe color so let's to start with that\n9:27 function so you can define a function in Python by typing in Def and then we'll call this generate underscore pet\n9:34 underscore name and now we'll be using llm from our Lang chain library and as I\n9:41 said I'll be using openai today so this has few properties one of them is\n9:46 temperature now what temperature means is how creative you want your model to\n9:52 be so if the temperature is set to let's say 0 it means it is very safe and it is\n9:58 not taking any bets or risks but if it is set to 1 it will be very creative and\n10:04 will take risks and also might generate wrong output but it is very creative at\n10:09 the same time so I tend to set my temperature to be 0.5 or 0.6 so that you\n10:16 know it can get a little bit of creative so let's set that by typing in temperature\n10:22 and now what I want to do is use this llm to create cool names for my pet\n10:28 which is in my case a DOT so I'll type something like I have a dog pad and I want cool names for it suggest me five\n10:36 cool names so that's what our luncheon app is gonna be it'll suggest five cool names for your pet so let me type that\n10:43 out as a prompt okay so I have my prompt ready and this function will return the\n10:49 name and now what we can do is if name is equal to main which is you know\n10:55 boilerplate python code I wanted to print whatever that function\n11:01 generates so generate pet name will be printed in our console output so let's\n11:06 give this a try by opening up the terminal here and typing in Python main\n11:12 dot py so as you can see it gave me five names for my pet dog Apollo Blaze\n11:20 Hershey Kona and Maverick which are pretty good names and as you can see I\n11:25 ended up setting the temperature to 0.7 so it's getting a little bit of creative again you can you know test this out by\n11:33 toggling this between 0 to 1 and see what temperature suits your needs but\n11:40 for me yeah 0.5 to 0.7 anything between that is good since I need my llm to be a\n11:46 bit creative so we just introduced one component of Lang chain which is llm the\n11:52 next thing that I want to introduce you to is promptemplate so prompt templates\n11:58 make it easy to generate these problems so you don't have to keep asking openai\n12:05 a different prompt every time right so we want to repurpose this so that people on the internet might be able to\n12:11 generate pet names so maybe we will create you know imagine that you want to create a web app where people can\n12:17 comment and read pet names we want to repurpose this prompt and also we don't want to hard code dog and if we want to\n12:24 have pet color as an option we don't want to hard code that so we want the ability to repurpose our llm prompt for\n12:34 different kind of animals and different kind of colors and the way we can do that is by using prompt templates so\n12:41 prompt template name let's just call it that and in Lang chain it's called\n12:47 prompt template and we will also have to import it from Lang change so going to\n12:52 the top let's import prompt templates okay so you're using Lang chin prompts\n12:57 and importing prompt template now you can see the squiggly line underneath it has gone so let's give it to let's give\n13:05 it an input variables so input variables are the parameters that\n13:11 can be dynamic so in our case it will be animal type right so animal underscore\n13:17 type and now we'll also have to add that as a parameter to our python function\n13:22 there we go so animal type is the input variable and the template that our\n13:28 prompt has is same as this so I'll copy this and instead of a dog pet I will use\n13:36 the input variable here which is animal underscore type so now you can imagine you can say hey I have a cat and some\n13:45 other person comes and says hey I have a cow pet and I want a cool name for it suggest me five cool names so that is\n13:52 what prompt templates allows you to do and now we'll have to also get rid of this and use chains as a concept so\n14:00 that's import chain from Lang chain from Lang chain dot chains import llm chain\n14:08 what llm chain allows us to do is put these individual components of Lang\n14:14 chain together so llm and Prime template in our case so llm chain llm is equal to\n14:20 llm in our case because we named it and prompt is equal to prompt template so\n14:26 I'll just copy this so prompt template name and instead of name let's call this\n14:31 name chain right since this is an llm chain and instead of returning name let's create a response here\n14:40 and that response basically will be name underscore chain and we'll be using the\n14:46 animal type parameter here right which is basically whatever the animal type\n14:51 the person specifies and will be returning the response here so response\n14:58 will be whatever this chain gives us the output has right now let's try instead\n15:05 of dog let's try cat right so we are using parameters to print five cool pet\n15:11 names using our name underscore chain which is the llm chain using openai and\n15:18 using this prompt template hit Ctrl s and going back to my terminal here\n15:24 let's run python main.py so now you can see we are getting a Json\n15:30 response with animal type which is cat and the text that we got is so these are\n15:37 the names that we got one is mochi or Moki nacho Pebbles tiger and whiskers so\n15:46 we got five names for our animal type cat similarly you can try cow here hit\n15:52 Ctrl s and run the python file again now it says animal type was cow and the\n15:58 text response is where our cow pet names are so one is hambone Daisy moo Moody\n16:06 Milky Way and give her hugs awesome so the other parameter that I want to add\n16:11 to our pet's name generator is the pet color because I think that is an\n16:17 important aspect when you name your pet right so pet color and so we'll add pet\n16:23 color as a parameter to our generate pet names function but also we'll have to add it as an input variable in our\n16:30 prompt template so let's add fat color over here there we go and now we'll also\n16:36 have to change the template itself so I have an animal type pet and I want a\n16:42 cool name for it and let's add it is whatever the color is so pet color so maybe it's black in color suggest me\n16:50 five cool names for my pet there we go so that is our new prompt\n16:56 hit control s and in the name chain we'll also have to add the pet color\n17:01 here so pet underscore color and that will be equal to whatever the pad color\n17:07 the person picks or says so now we can\n17:12 run this by saying cow and our cow color is black so let's let's try that out\n17:18 toggle back my terminal here and type in Python main.pi and you can see so we got\n17:24 animal type cow pet color is black and we received text response with those\n17:30 five names so one is Shadow second is midnight uh Starlight and we have Raven\n17:36 awesome so our pet's name generator is working as expected maybe I want to\n17:42 publish this as web app later right and that's where streamlib comes in streamlit will build us a web interface\n17:49 and we don't have to do much we can use our python file here to build that\n17:55 beautiful interface and then people can come in and select whatever pet kind\n18:00 they have and whatever pet color they have and it would output those five\n18:06 names utilizing the Lang chin app we built so in order to do that what I I\n18:11 want to do is instead of having all of this code in main.pi I want to create\n18:18 another file called Lang chain underscore Helper and this is where all\n18:24 our Lang chain code will go so I'm going to go into main.pi Ctrl a to select all\n18:31 the code and paste it in the langchin helper file here and then we can clear\n18:37 the main.pi so our main.pi is blank and I have moved all my code to Lang chain\n18:43 underscore helper.py hit Ctrl s so make sure you have saved that and in main.pi\n18:49 what I want to do is input our Lang chain helper Library so we can do that\n18:55 by doing Simple import statement on the top so I'm importing Lang chain helper as lch just short form so that I'll be\n19:04 able to call our generate pet name function by just using lch dot right\n19:10 also remember we did pip install streamlit in the beginning so we'll be using that here too and I'll be calling\n19:18 it throughout the python code AS SD which is just short for streamlit so in order to create our streamlit app you\n19:25 can use different text types and you can also use markdown which streamlit will\n19:31 render but one of the main things is having a title for our web interface and\n19:37 you can do that by doing St dot title and we'll call this pet's name\n19:43 generator right hit save and now I'll just show you how to run a streamlined app where\n19:50 you can do that is open the terminal and type in streamlit run main.py hit enter\n19:56 and let me open my browser on Port 8501\n20:02 there we go so as you can see right out of the box we have this interface that was built using streamlit\n20:09 and again if you haven't heard about streamlit it's an amazing tool you can go to streamlit.io and go through their\n20:16 documentation on how to even make your web app better since I'll be using some\n20:22 basic components from streamlit to display our pet's name generator beautifully so let's get back to our app\n20:31 here so back in our code editor I'll hit Ctrl C in my terminal to stop the\n20:36 streamlit app and bring my terminal down and now we need some variables and Logic\n20:43 for the ability for users to pick their pets and the pet color so one of them is\n20:49 the animal type right whether it's dog cat or a cow will give a sidebar selection for our users so SD dot\n20:58 sidebar dot select box will allow you to do that and you can input what the\n21:04 question is so what is your pet question mark and then you can include the\n21:11 options so it will be a drop down where people can select cat right dog and cow\n21:19 and maybe a hen right so think of all the pets then people that people can\n21:24 have maybe hamster is more popular I guess so cat dog cow hamster and then\n21:29 you can just keep going so that is the animal type and I can show you how this looks on our streamlit apps so streamlit\n21:35 space run space so you can see that and I can zoom in a\n21:41 little bit on the left hand side we have a sidebar now and you can select what kind of pet you have so what is your pet\n21:48 the next logic that I want to build is another option to select the color of\n21:54 your pet but I want it in a way that once you have selected the pad type so\n21:59 animal type right if it's cat it should say what color is your cat and we can do\n22:04 that by if statements so if animal underscore type is cat right I want pet\n22:11 color which is another variable we pass to our generate pet name function here\n22:18 you can say pet color is equal to and then we use the select box component\n22:24 from streamlit to ask what color is your\n22:29 cap now I feel like there can be different variations so you can't just\n22:34 put in black blue white orange you know since with cows and even cats\n22:42 and dogs you can have multiple colored pets right like a white dog with black\n22:47 spots on it so we can't have a select box let's just keep this as a text to you and I just thought of that as I was\n22:55 building this right so instead of a select box we have a sidebar with a text\n23:00 area that asks for what color is your cat and I also want to maybe have a\n23:08 limit of Maximum characters that people can put into this because remember we are calling the open AI API and the API\n23:15 calls depend on the amount of information you are sending in the prompt template so if our prompt gets\n23:22 bigger we'll be charged more so in order to limit that let's have a Max character\n23:28 property here again this is available on Shameless documentation and we'll use\n23:34 the label ER so the label is what color is your cat and the maximum characters that users will be allowed to put in is\n23:40 15 and we can hit save what you can do is copy this over for dog cow so I'll\n23:48 put dog here and what color is your dog or dog for cow it will be what color is\n23:54 your cow and then I think we're left with one which is for hamster again I'll\n23:59 just copy this and paste for hamster okay there is an efficient way to do\n24:06 this but I'm just gonna copy the code that I already have go back to my browser here refresh my streamlit page\n24:13 and now you can see if we select dog it will say what color is your dog and you see the text area which has a limit of\n24:20 15 characters similarly if you select the cow you can see it asks\n24:26 what color is your cup so both of the parameters have been set right now what\n24:32 I want to do is send this information to our Lang chain helper right because this\n24:38 is where it will generate those names and give it back to us so let's do that\n24:44 so after we have set the pet color right because that's the last question\n24:49 we ask our users what we want to do is have a variable here called response\n24:56 and response is equal to LC Edge which stands which is just short for Lang\n25:02 chain helper here and the function in the Lang chain helper is generate pet\n25:08 name so I'll copy that over so you do lch dot generate pet name so we are accessing\n25:15 that function animal type was the first parameter that we need again I'm using\n25:21 animal type as a variable here maybe we can say user\n25:27 underscore animal type and I'll have to change that over here\n25:33 over here over here and over here again just so that you're not confused so\n25:40 two parameters animal type and pet color and then I'm using the user animal type as a variable on our main.pi so user\n25:48 underscore animal underscore type and the second parameter is pet color again\n25:53 you can do the same here so user underscore pet underscore color and you'll have to update all of these here\n26:00 just to avoid confusion so we are passing these variables that the user\n26:06 said so user will say I have a dog and its pet color is white and we are\n26:12 passing those to our generate pet name function and then we'll just write that\n26:19 as a text field so our text Will field will just reply with response so let's\n26:25 save that now let's go back to our browser here hit refresh\n26:31 now let's select dog and type in the color black\n26:37 and you can hit Control Plus enter to apply and you can see we got a response\n26:45 with the five pet names right and\n26:51 what you can do to display this beautifully is set an output key right\n26:59 so let's go back to our Lang chain helper here and in the name underscore chain We'll add a third property called\n27:06 output key right and the output key is pet underscore name so basically instead\n27:13 of giving us a text output it will associate those five names that it\n27:18 generated to this output key and we can access this in our main.pi so instead of\n27:25 just returning the entire response so the whole text here see how it looks\n27:30 weird we'll just we'll just access the names that it generated and we can do\n27:36 that by doing response and then accessing that underscore name which was the Kiwi set\n27:44 so hit Ctrl s go back to our browser window and click refresh this time let's\n27:49 go with the cat which is white hit Control Plus enter to apply and you can see it displays the text now\n27:58 better right it looks beautiful and we have the recommendations here as snowy\n28:04 marshmallow cotton pull blizzard let's go over the brown hamster so hamster\n28:10 and brown Coco mocha Chestnut caramel biscuit\n28:16 love those names so now as you can see we have a streamlit app and we are using Lang chain to generate\n28:23 five cool pet names for the pets that we might have and we saw how you can use\n28:30 another lamp prom templates and the chain which are three main components of\n28:38 Lang chain but now the important one that's left is Agents right so agents\n28:45 allow llms to interact with the environment so think of apis or things\n28:51 you want to do after Gathering the information so going over the Lang chain documentation about agents the core idea\n28:58 of Agents is to use an llm to choose a sequence of actions to take in Chains a\n29:05 sequence of actions is hard coded in code whereas in agents a language model is\n29:12 used as a reasoning engine to determine which actions to take and in which order\n29:18 and there are several key components Langton provides a few different types of agents to get started even then you\n29:25 will likely want to customize those agents depending on the personality of the agent and the background context you\n29:32 are giving to the agent and then there are tools so tools are functions that an\n29:37 agent calls there are two important considerations giving the agent access to the right tools and describing the\n29:45 tools in a way that is most helpful to the agent so let's test it out so we\n29:52 already have a pet's name generator thing that's working for us right gives\n29:57 us a name for our pet now let me create another function here\n30:03 which will name Lang chain underscore agent and before we can interact with\n30:10 the agent we have to import the Lang chain Agents from the framework so you\n30:15 can do that by adding these three import statements on top so we are importing\n30:20 tools we are also importing the initialization of the agent and the\n30:26 agent type so coming back to our function here so first we'll Define the llm that we want to use and I still want\n30:33 to use the openai llm and the temperature will set it to 0.5 here and\n30:39 then we can load some tools that will perform the given action so\n30:45 there are various tools that are available and again you can go through the availability of tools or the list of\n30:53 tools on the link chain documentation but I'll be using Wikipedia which will\n30:59 be the first tool I want to use and I'll get to it why I want to use Wikipedia and the other one is llm matte because I\n31:06 want to perform some matte and this is to just showcase what agents can do right and then the llm that we'll be\n31:14 using is defined here which is the open AI so llm is equal to llm right and now\n31:20 we'll have to initiate the agent so agent and to initialize its initialize\n31:27 underscore agent and here you specify the tools that will\n31:32 be providing it which is stored right here which is Wikipedia and lmat the llm\n31:38 we want to use right and the agent type so one of the agent\n31:43 types that's available in the quick start guide for langchain is the react\n31:49 and you can go to the agent types documentation here so zero shot react is\n31:55 the one that I'll be using decision uses react framework to determine which tool\n32:00 to use based solely on the tools description so heading over to our code\n32:06 and the way you define that agent type is by setting it here and we'll set the\n32:13 verbose flag to True which means it'll show us the reasoning that'll happen in\n32:19 our console so that's the agent we want and we'll create a result here where we\n32:26 run the agent and now you can specify the tasks so you want to perform through\n32:32 this agent so since our app is solely based on pets let's ask it what is the\n32:38 average age of a dog and I'll ask it to do some math\n32:44 and that is the reason why I loaded the llm math tool here multiply the age by\n32:50 three and at the end we'll print result so that looks good and I will change\n32:55 this so I'll comment this out instead we'll print whatever this generates so\n33:01 Lang chain agent right hit save and now we can run this and just to demonstrate\n33:07 it I'll not be linking this to our streamlit app which was the web interface I'll just run the\n33:14 Lang chain underscore helper python file just to Showcase you how agent works so\n33:20 before I do that I have to make sure that Wikipedia is installed through pip\n33:25 so pip install Wikipedia will install that python Library so now if I run the\n33:31 langchin helper file we'll see the agent in action okay so you'll see that it\n33:38 finished the chain and the answer was the average of a dog is 45 years when\n33:43 multiplied by three but the final answer that it got was 15 right so the average\n33:49 age of the dog is 15 and then it multiplied by 3 which is 45. so you can\n33:55 see that it was able to grab the information from Wikipedia which is 15\n34:01 as the average age of a dog and it was also able to perform the math and get to\n34:08 this right and now since we set the verbose flag to true you can see the\n34:13 reasoning that went into it right and I'll increase my terminal and with no size here and get rid of the file\n34:21 explorer on the right so you can see I need to find out the average age of a\n34:26 dog action is Wikipedia action input is averages of talk and this is the\n34:32 observation that it found right so it did scan few pages on Wikipedia\n34:38 thought I now know the average age of a dog and the age of the oldest dog right and then action is calculator where it's\n34:46 trying to multiply 15 which is the average age by three because that's what we asked it to do awesome so that's how\n34:53 the agents work and I believe we have kind of covered almost all components\n34:59 within the langchin framework the only thing that's left is indexes right so\n35:05 what are indexes basically as you can see we are still working with the open\n35:12 AI llm but we are also not providing any of the custom knowledge right so we are\n35:18 still relying on open Ai and the information that they have gathered but\n35:23 with langchain you can also provide your own knowledge or knowledge base on which you can ask llm to do certain actions so\n35:32 think of a PDF file or even URLs that you can script or maybe you have a large\n35:40 PDF file with a lot of text and maybe you want to run an llm AI chat bot for\n35:46 your own document so you can do that with the help of language in the next project that I want to showcase you will\n35:52 exactly do that will take a long YouTube video so think of a podcast which is\n35:58 hours long or a long YouTube video right so what I have here is\n36:04 the Microsoft CEO certain dealer full interview on recode but it's 51 minutes\n36:09 long and what I want to do with Lang chain is the ability to ask questions to\n36:16 this video so the context that the llm would have is strictly of that video and\n36:22 I'll be using few libraries like YouTube transcript which basically converts\n36:28 whatever URL we provide for a YouTube video and gets its transcript right so\n36:33 let's build this YouTube assistant now I'm going to show you how you can create this assistant that can answer questions\n36:40 about a specific YouTube video so coming back to the concept of indexes I touched\n36:47 briefly on it but we also saw it in the Lang chain diagram but we know that these large language models become\n36:54 really powerful when you combine them with your own data and your own data in this scenario will be the YouTube\n37:00 transcript that we are going to download automatically but you can basically replace that transcript with any\n37:07 information in this approach so it could be a PDF it could be blog post URL right\n37:13 so what Langton offers is document loaders and I can quickly show you the YouTube\n37:21 transcript one so this is the YouTube transcript and basically it allows you\n37:26 to get the transcript which will be the text version of the YouTube video right\n37:31 but there are several other document loaders that you can see on the left hand side right so you can bring in an\n37:38 S3 file you could bring an Azure blob storage file you could do Hacker News\n37:44 posts or articles right so these are some of the document loaders that are\n37:50 supported by linkchin as of now and we'll be using text Splitters and Vector\n37:55 stores so we are going to use these three components to load our YouTube video transcript split it into smaller\n38:02 chunks and then store it as Vector stores so you can think of these as little helper tools that will make it\n38:09 easy for us to load the transcript which might be thousands of lines of text so\n38:16 to get us started what I have already done is created a YouTube assistant\n38:21 directory so not be using the pets generator directory that we had and what\n38:26 I have done is pretty similar to the pet's name generator right so I have main.pi which will hold our streamlit\n38:33 interface and then the langchin helper will have the length chain components\n38:39 and I've also created a virtual environment and installed all the\n38:44 necessary packages which is link chain openai YouTube transcript also I've I\n38:50 went ahead and created dot EnV file which holds my openai API key so pretty\n38:56 similar to the pet's name generator and now we can start with the lag chain\n39:01 helper first so the first thing that we are going to import is the YouTube loader that we saw right which is a\n39:09 document loader so from langtin dot document loaders we are importing that YouTube loader and the second important\n39:15 thing we need is the text splitter so as I showcased that the video that I have\n39:21 is 51 minutes long you could also pick up a podcast like Lex and they have\n39:29 podcasts that are three hours long and which means you'll have thousands of\n39:35 lines and that is where we'll use the the text splitter to break down those\n39:41 huge transcripts into smaller chunks and I'll show you how and for the rest of the inputs we are gonna input the lag\n39:49 chain components like the llm which will be open AI prompt template and llm chain\n39:54 the other thing coming back to indexes we'll be using Vector stores so I'll be using the phase\n40:02 library and I'll quickly show you what the face library is phase is a library by meta or\n40:11 Facebook for efficient similarity search and you might have heard of other Vector\n40:17 stores or databases like Pinecone or vv8 right but I'll be using phase for this\n40:25 project so let's start with writing some code so I've done all the necessary\n40:30 inputs here the only input that's left is the dot EnV which will load our\n40:37 environment variables and I'll initiate dot EnV here also since I'll be using\n40:44 openai embeddings so we'll initiate that to here and I forgot to import those so\n40:51 I'll import the open aim bearings and now we can create our first function to\n40:57 create a function we know that in Python it's deaf and let's name this function\n41:02 that will be be creating a vector DB\n41:08 create Vector DB from YouTube so that's a pretty big function name right but I\n41:14 want to specify what we are doing and we'll be using phase here also for the\n41:20 parameter let's give this a required parameter which is the video URL right\n41:25 so we'll be pasting this video URL in our streamlit interface and that's what\n41:30 we'll be using and this will be a string right so the first thing we want to do\n41:35 is load the YouTube video from the URL right so we'll use loader which we\n41:42 imported on the top so YouTube loader Dot from YouTube URL and we'll pass the\n41:50 video URL parameter here after we have loaded the YouTube video I want to save\n41:55 this into the transcript variable so we'll create transcript here and we'll\n42:00 just do loader dot load and this should give us the transcript now we'll be\n42:07 using text splitter and I'll specifically tell you why so text\n42:12 splitter and we imported it here as recursive character text splitter you\n42:18 can specify few parameters when using this so the first one is chunk size\n42:24 which will set to 1000 and chunk overlap so chunk size is how much each chunk\n42:31 will contain so for me it will be 1000 right and then overlap is once it has\n42:37 created those individual docs from the long transcript it'll have an overlap in\n42:43 every document so document one the last hundred words would also be included in\n42:48 the document twos first hundred words right so that is what overlap is and now we'll save them into a docs\n42:56 variable so text underscore splitter not split documents as the function and\n43:03 we'll provide the transcript that we had loaded from the YouTube url there we go\n43:08 okay now let's also initiate the phase so\n43:14 phase Dot from documents and we will be using docs which we stored here right\n43:22 docs and we'll be using the open Ai embeddings and we'll return this DB\n43:29 okay so now on to the explanation why we have to split the text so basically what we\n43:37 are doing at the text splitter is we have taken over thousands of lines and\n43:43 split up the documents so it has taken very large transcript over and split it\n43:49 up into chunks of 1000 so that is the first step now you might wonder right so we can't just provide thousand lines to\n43:57 the open AI API remember there is a token size or a limit on how much\n44:04 information you can send to open AIS API and that is why we have split the amount\n44:10 of context we'll be sending for for a YouTube transcript right because the model that I'll be using is the text\n44:18 DaVinci 003 and as you can see it can only take\n44:24 4097 tokens so I cannot send the entire transcript to open aiz Ai and that is\n44:32 why we'll be splitting it and storing it into Vector stores again this is quite technical I'll not\n44:40 go into much detail but vectors basically are a numerical representation\n44:45 of the text we just created here right so the core responsibility of this\n44:52 function is to load the transcript right take all the text that's in the\n44:57 transcript split it into smaller chunks and then save those chunks as Vector\n45:03 stores again we can't just provide all of these Vector stores to the open AI\n45:08 right we can't just send over the 10 000 or maybe even 50 chunks that we have\n45:15 created of smaller text that's where we'll use phase to do a similarity\n45:20 search right and that's what the next function will be and before I write that\n45:25 next function we'll see if this works so video underscore URL so I'm gonna hard\n45:32 code the video URL that we have for the podcast and see if we get the smaller\n45:39 chunk documents right so let's print this function at the end\n45:47 hit save and we'll open the terminal make sure your virtual environment is\n45:53 activated and you have installed the required packages again all of this will\n45:58 be available on GitHub for reference later but let's run the line chain helper python file again it'll take some\n46:06 time to do the computation I missed to write print so we'll have to\n46:12 print this whatever this function returns which should be the database that we created right so let's run it\n46:20 again and this time we should get the vector stores that were created and so\n46:25 instead of DB if I return docs you'll see those chunks\n46:32 so if I expand my terminal here you can see we have quite a few text here but\n46:39 here are the docs right so you can see that there's a document and then it\n46:46 starts with the content and you'll see multiple document chunks so these are\n46:51 the chunks that we created from the larger transcript so this is one right this is the second one\n46:58 and so on I know the formatting is weird so you can't really tell where the new\n47:04 document starts but yeah this is all the chunks that we have awesome so our\n47:09 function to create the vector DB from YouTube url is working as expected so\n47:14 I'll get rid of this print statement and full return DB here now for the next\n47:19 function which is going to be getting off the response on our query we have to\n47:26 ask this YouTube video right so let's create that function we'll name it get\n47:32 underscore response from query again pretty self-explanatory name for the\n47:39 function itself and we'll pass few parameters to this function one is DB the important one will be query which\n47:47 will be the question that the user asks and K which is another argument that\n47:52 I'll go over this is used for the similarity search that will do so keep in mind the amount of tokens that the\n48:00 text DaVinci 3 Model can take right so keep that in mind it's 4097 so I'll just\n48:06 add a comment here saying text DaVinci can handle 2097 tokens right now in\n48:15 order to do a similarity search we'll save that into a docs variable within this function so DB\n48:22 is what we'll use we'll perform a similarity search on the DB which is the database we created in the previous\n48:29 function so gb.similarity underscore search and the search will be basically\n48:35 the query so the first thing I want to do with this function is basically search the query relevant documents so\n48:42 let's say in this podcast they talk about a ransomware somewhere so right\n48:48 here they talk about ransomware right and if I want to ask a question saying what did they talk about ransomware so\n48:54 my query is just about ransomware that that they talked about in the podcast so\n49:00 it will only search the document that has details about ransomware so we'll\n49:06 not send the entire documents that were created but just the one that is\n49:12 relevant to the query that the user made I hope that makes sense and this is also\n49:17 where we'll pass the K as argument and I'll tell you what K is so remember that\n49:25 we can have 4097 tokens but our chunk size is 1000.\n49:31 so that means we can kind of send four documents right because each document is\n49:39 a size of thousand so let's set that value to four okay so we'll be sending\n49:44 four relevant docs based on the query that the user made now I'll create another variable called docs page\n49:51 content and what we'll basically do is join those four docs that we'll be sending\n50:03 okay so we got those four docs and we are joining them to create one dock\n50:08 because the Toca limit is 4097 and here we'll almost have 4 000 tokens being\n50:15 sent to the text DaVinci 3 mod awesome now let's work with the llm right so\n50:23 pretty similar to what we did with the pet's name generator we'll initiate the llm to be open Ai and\n50:31 as I said the model that I'll be using is text DaVinci 3 so let me go to the\n50:37 open AIS documentation copy this model name come back here and paste it and\n50:42 there is some white space at the end so we'll get rid of that and the second thing we did with the pets name\n50:48 generator was prompt right so prompt templates is the is another main\n50:53 component of Lang chain so we'll use that and this is variable define what the prompt should be for the open AI llm\n51:02 so the first thing would be to specify the input variables right so the first\n51:08 one is question or query right so whatever the question is being asked by\n51:14 the user in Docs so docs is basically the similarity\n51:19 search we did there we go now the template that we'll be using is a prompt\n51:25 that I've created here so I'm gonna copy this really quick since it's a long prompt okay so I've copied the prompt\n51:32 basically it says you're a helpful YouTube assistant that can answer questions about videos based on the\n51:39 videos transcript right answer the following question and this is where the input variable goes\n51:46 whatever the question the user is asking by searching the following video transcript which is the docs right so\n51:53 docs is basically the similarity search we did only use factual information from the\n51:58 transcript to answer the question if you feel like you don't have enough information simply say I don't know\n52:04 right because we don't want the AI or the llm to hallucinate your answer should be needed so that is basically\n52:11 the prompt that we'll be using to answer questions and now we'll be using another\n52:17 main component which is chain within the Lang chain so let's create an llm chain\n52:23 where llm is equal to llm because we specified it here that will be using\n52:29 openai model text DaVinci 3 and prompt is equal to prompt which we specified\n52:36 here using prompt template okay now we just have to learn the response so\n52:43 I'll create a variable call response it will do chain dot run which will basically run our chain since we had\n52:49 question as the input variable here we'll say that question is equal to\n52:56 query because that's what we were referring to it on the previous function and\n53:03 Docs is equal to docs page underscore content\n53:09 remember because we joined all the four documents because K is set to 4 to\n53:17 be one doc because we can we have the ability to send four thousand tokens and\n53:22 then response is equal to response dot replace and this is just some\n53:29 formatting that we have to do because if you remember in the pet's name generated to the response we were\n53:35 getting was in one line and it included new line characters so we'll replace that with\n53:42 some white space and we'll return response okay so now we can test this\n53:50 out as it is in the console by hard coding the question and the URL which we\n53:56 already did so let's get ready for that but also build the interface because it'll be really quick with streamlit so\n54:03 coming over to our main dot Pi let's do some inputs on the top so pretty similar\n54:08 to what we did in our pets named generator so streamlit I'm importing it as St and the langchain helper where are\n54:17 all of the Lang chain code is and I'm also importing text wrap basically it\n54:22 gives you the ability to wrap text so that you're not you don't have to scroll the page the title of this page will be\n54:31 YouTube assistant right so YouTube assistant and now on the sidebar we can have those\n54:39 parameters that we need from the user with sidebar I want to create a farm so\n54:45 we have a submit button at the end so SD dot form is how you do that\n54:52 and you also have to specify a key so key is my form again this is all\n54:59 streamlit stuff and let me know in the comments if I should create a course on streamlit on how to build you know cool\n55:05 python interfaces I love this tool because I don't have to care about building a front end and the first\n55:12 parameter we had in our length chain helper was the YouTube url right so\n55:18 we'll save that as video URL so YouTube url is equal to SD dot sidebar text\n55:27 as we used in the pet's name and we'll just say that the label is what is the\n55:34 YouTube video URL and we'll give a Max to maximum character limit of 50 because I don't think a video URL can exceed 50\n55:42 characters uh the other parameter we had was the question that the user can ask and we'll save it as query here so St\n55:49 dot sidebar dot text underscore area right and then the label will be asked\n55:57 me about the video so again you can have a limit here right so maybe you can only\n56:05 ask questions that are not long enough so we'll set max characters 50 here too\n56:11 and also set the key to query here okay and at the last since I created this as\n56:18 a form we'll give it a submit button and the label here will be submit now\n56:25 so if Kiri which is the question the user can ask and YouTube url exist right\n56:32 what I want to do is basically run this function to give us the answer right so\n56:40 we'll be as we are already importing the link chain helper on the top as LS lch\n56:46 so that's what we'll be using here so DB which is the database will be equal to\n56:53 so remember we have to pass the video URL uh to the create Vector DB function\n56:59 to create a new Vector database based on the transcript that we got so DB is\n57:05 equal to lch which helps which is basically that we are accessing this python file and then the create Vector\n57:12 DB from YouTube url function and we'll pass the YouTube url as the parameter because remember we\n57:19 just need the video URL here response comma docs is equal to and now we'll get\n57:28 a response which we can do by running this function which is get response from\n57:33 query and remember the parameters that will be passing so lch dot getresponse\n57:40 from query the first one is DB which we just created right and query is the\n57:46 question that I will be asking so um right here whatever the user asks will be the query\n57:53 so I am missing a comma here as I'm going through my code so I'll add that and now we'll save that response in our\n58:02 interface with streamlit so let me create a sub header here which will say answer right and below that we'll have\n58:10 St dot text and we'll wrap that text\n58:15 and this is where the text wrap library is being used you'll you'll see this in the interface once I run it so text wrap\n58:22 dot fill and whatever the response we get from the length chain function\n58:30 you can also set the width of this text area to be 80 let's go with 80 and see\n58:36 how that looks and that is basically it so two parameters for necessary one is the\n58:42 YouTube video URL and the question that the user asks right and we are passing so if the both of those parameters exist\n58:49 first we are creating the database from the YouTube video URL and then we're getting the response based on the\n58:56 question that the user asked using the llm so now we can run our streamlit app\n59:02 after saving the file so if I scroll down to the bottom here for my terminal\n59:07 expand this and run stream lit run main.pi\n59:13 hit enter it should load our web interface for our\n59:18 streamlit app awesome on the left hand side you can see we need to provide a YouTube video URL so\n59:26 I'll just go ahead copy this interview video URL paste it here\n59:32 ask me about the video so let's say what did they talk about rent somewhere is\n59:42 what I want to know and hit submit okay so we have got some errors saying input variables let's go\n59:51 to our terminal and see if we have any logging okay so I found the error I was just\n59:59 missing S I thought I typed it right so instead of input variable it needs to\n1:00:05 be input variables and we'll Ctrl C to stop our streamlit app and do streamlit\n1:00:13 run run main.pi again so after adding the S hit enter and now\n1:00:20 we need the same exact information so copy this\n1:00:25 and copy the question so the YouTube video URL and what did they talk about\n1:00:31 ransomware hit submit there we go we got our answer so it says\n1:00:39 they discussed how ransomware is difficult to track due to zero day exploits and how Microsoft is making it\n1:00:45 a mission to help with secure cloud backup for Enterprises better tracking of zero day exploits and helping with\n1:00:52 enforcements they also discussed the importance of public-private Partnerships in order to prioritize\n1:00:57 cyber security and create new standards such as those for nist so\n1:01:02 remember our prompt I asked it to be as detailed as possible also say I don't know if it doesn't know\n1:01:09 what the answer is based on the transcript we provided and not to hallucinate so I think this is a pretty\n1:01:15 good answer um that we got out of this 52 minute\n1:01:20 video again you can pick a longer video and ask about anything specifically\n1:01:27 longer from podcasts right maybe the video is four to five hour Longs and you\n1:01:32 need to know a specific detail I think that's where this tool or the app we\n1:01:38 build can be really handy right but yeah so we learned a lot about\n1:01:44 Lang chain today specifically the main three main components which is llm so\n1:01:52 any of the large language models that you can use like open AI or hugging face prompt templates right\n1:01:59 and chains so how you can combine these components into chains to perform the\n1:02:05 required task and agents right remember in the pets generator we talked a little\n1:02:11 bit about agents and how they have reasoning behind the\n1:02:16 tasks that they perform because we try to calculate average age of a dog and\n1:02:22 also multiply it by three so it used Wikipedia and llm math to get those\n1:02:27 answers but also we learned a bit about indexing and Vector stores so how you\n1:02:33 can split large documents into smaller chunks and store it as Vector which is basically you know\n1:02:39 numerical representation of the documents that we created and then\n1:02:46 passing those on to the llm since there are certain limits of how much context\n1:02:52 you can send to the API but yeah one other thing I would like to mention is\n1:02:58 if you are planning to make these apps public remember we were storing our\n1:03:04 environment variables in dot EnV file and you might be wondering every ship I\n1:03:10 also created an openai API key like how much all of this is going to cost so\n1:03:16 I'll go into my dashboard in into billing to see how much did it cost me\n1:03:21 to you know basically kind of build this course out so you can see um\n1:03:28 10 cents and 30 cents so very close to\n1:03:33 less than a dollar like half of a Dollar close to 50 cents is what it costed me\n1:03:39 to make all of these queries to the openai llm the thing I was gonna\n1:03:45 recommend if you want to publish this app so that the public can use it is to have a field here uh you know with\n1:03:54 the sidebar saying open AI API key so that the users have to submit their\n1:04:00 openai API key with their app so you can have a text field here saying hey what\n1:04:06 is your open AI API key just so that you know you are not being charged and you can make that as a secret field so that\n1:04:14 the key is not displayed in the interface but you can use that key to make these queries you will just have to\n1:04:21 pass it in the Lang chain helper so whatever the variable name you decide\n1:04:27 maybe like open AI API key which you'll get the value from our streamlit\n1:04:34 interface you can pass that right here when you initiate the large language\n1:04:40 model so you'll specify openai API key as a\n1:04:45 parameter here and the value of that key which will be the variable you decide so\n1:04:51 yeah that's pretty much it for this course again we learned quite a bit about the langchin framework\n1:04:58 specifically in Python uh you know the models prompts indexes chains and agents\n1:05:03 or the five main Concepts within nag chain that I wanted to cover again I\n1:05:09 hope this helps you understand the framework itself and how you can utilize this information to build something\n1:05:16 really cool with the power of llms but if you would like to see a streamlit\n1:05:21 course again let me know in the comments but I hope you find this course helpful I'll see you in the next one peace